{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GiovanniPioDelvecchio/GCNs_on_text/blob/main/GloVe_LSTM_Baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bc3f51c",
      "metadata": {
        "id": "9bc3f51c"
      },
      "source": [
        "# NLP project work\n",
        "Summary: Casting text classification to Graph Classification for Sentiment Analysis of Tweets\n",
        "Members:\n",
        "\n",
        "- Dell'Olio Domenico\n",
        "- Delvecchio Giovanni Pio\n",
        "- Disabato Raffaele\n",
        "\n",
        "The project was developed in order to evaluate the effectiveness of Graph Neural network on a sentiment analysis task proposed in the challenge:\n",
        "https://www.kaggle.com/datasets/datatattle/covid-19-nlp-text-classification?resource=download\n",
        "\n",
        "We decided to implement and test various architectures, including commonly employed transformer-based architectures, in order to compare their performances.\n",
        "These architectures were either already present at the state of the art or were obtained as a result of experiments."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54723b0a",
      "metadata": {
        "id": "54723b0a"
      },
      "source": [
        "## This notebook contains the following:\n",
        "- Implementation and training of a GloVe + LSTM + linear model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4831e32b-2c8e-42bf-ad74-e9d8d7a0e27b",
      "metadata": {
        "id": "4831e32b-2c8e-42bf-ad74-e9d8d7a0e27b",
        "outputId": "28db8ac1-df27-420c-ed9f-49e611e4e67e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_2709/876356641.py:2: DeprecationWarning: \n",
            "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
            "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
            "but was not found to be installed on your system.\n",
            "If this would cause problems for you,\n",
            "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
            "        \n",
            "  import pandas as pd\n"
          ]
        }
      ],
      "source": [
        "# Imports for model implementation\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "\n",
        "from torchtext.vocab import GloVe\n",
        "from torchtext.data import get_tokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47e667e9-fb07-4651-a3ca-492e4856a3ab",
      "metadata": {
        "id": "47e667e9-fb07-4651-a3ca-492e4856a3ab",
        "outputId": "45a9bcb8-7822-4e87-a50b-9ca5144edb30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "Device name: Tesla V100-DGXS-32GB\n"
          ]
        }
      ],
      "source": [
        "# Check if cuda is available\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load and preprocess of dataset"
      ],
      "metadata": {
        "id": "jATGGPw0TuGg"
      },
      "id": "jATGGPw0TuGg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90bb6dbf-3d2a-4022-ac9f-e8d312bfd7fd",
      "metadata": {
        "id": "90bb6dbf-3d2a-4022-ac9f-e8d312bfd7fd",
        "outputId": "ba828328-f99f-4d1e-9623-54e1d8af8526"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of        UserName  ScreenName                      Location     TweetAt  \\\n",
              "0          3799       48751                        London  16-03-2020   \n",
              "1          3800       48752                            UK  16-03-2020   \n",
              "2          3801       48753                     Vagabonds  16-03-2020   \n",
              "3          3802       48754                           NaN  16-03-2020   \n",
              "4          3803       48755                           NaN  16-03-2020   \n",
              "...         ...         ...                           ...         ...   \n",
              "41152     44951       89903  Wellington City, New Zealand  14-04-2020   \n",
              "41153     44952       89904                           NaN  14-04-2020   \n",
              "41154     44953       89905                           NaN  14-04-2020   \n",
              "41155     44954       89906                           NaN  14-04-2020   \n",
              "41156     44955       89907  i love you so much || he/him  14-04-2020   \n",
              "\n",
              "                                           OriginalTweet           Sentiment  \n",
              "0      @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral  \n",
              "1      advice Talk to your neighbours family to excha...            Positive  \n",
              "2      Coronavirus Australia: Woolworths to give elde...            Positive  \n",
              "3      My food stock is not the only one which is emp...            Positive  \n",
              "4      Me, ready to go at supermarket during the #COV...  Extremely Negative  \n",
              "...                                                  ...                 ...  \n",
              "41152  Airline pilots offering to stock supermarket s...             Neutral  \n",
              "41153  Response to complaint not provided citing COVI...  Extremely Negative  \n",
              "41154  You know itÂs getting tough when @KameronWild...            Positive  \n",
              "41155  Is it wrong that the smell of hand sanitizer i...             Neutral  \n",
              "41156  @TartiiCat Well new/used Rift S are going for ...            Negative  \n",
              "\n",
              "[41157 rows x 6 columns]>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the train dataframe\n",
        "df = pd.read_csv(\"./Corona_NLP_train.csv\", encoding='latin1')\n",
        "df.head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46f522e1-11c1-41ea-bd00-b101599dc5e9",
      "metadata": {
        "id": "46f522e1-11c1-41ea-bd00-b101599dc5e9",
        "outputId": "694c3e8b-73fb-4f17-8df1-56b1faeb1c1a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OriginalTweet</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>advice Talk to your neighbours family to excha...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>My food stock is not the only one which is emp...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
              "      <td>Extremely Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41152</th>\n",
              "      <td>Airline pilots offering to stock supermarket s...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41153</th>\n",
              "      <td>Response to complaint not provided citing COVI...</td>\n",
              "      <td>Extremely Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41154</th>\n",
              "      <td>You know itÂs getting tough when @KameronWild...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41155</th>\n",
              "      <td>Is it wrong that the smell of hand sanitizer i...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41156</th>\n",
              "      <td>@TartiiCat Well new/used Rift S are going for ...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>41157 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           OriginalTweet           Sentiment\n",
              "0      @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral\n",
              "1      advice Talk to your neighbours family to excha...            Positive\n",
              "2      Coronavirus Australia: Woolworths to give elde...            Positive\n",
              "3      My food stock is not the only one which is emp...            Positive\n",
              "4      Me, ready to go at supermarket during the #COV...  Extremely Negative\n",
              "...                                                  ...                 ...\n",
              "41152  Airline pilots offering to stock supermarket s...             Neutral\n",
              "41153  Response to complaint not provided citing COVI...  Extremely Negative\n",
              "41154  You know itÂs getting tough when @KameronWild...            Positive\n",
              "41155  Is it wrong that the smell of hand sanitizer i...             Neutral\n",
              "41156  @TartiiCat Well new/used Rift S are going for ...            Negative\n",
              "\n",
              "[41157 rows x 2 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Drop not so useful columns\n",
        "df.drop(columns=['UserName','ScreenName','Location','TweetAt'], inplace=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "229eaa43-85a1-4f59-9222-9653f6e7fe81",
      "metadata": {
        "id": "229eaa43-85a1-4f59-9222-9653f6e7fe81"
      },
      "outputs": [],
      "source": [
        "# Filter tweets with a minmum length of 10\n",
        "def get_long_tweets(df, tweet_lengths):\n",
        "    to_return = df.loc[tweet_lengths >= 10]\n",
        "    return to_return\n",
        "\n",
        "tweet_lengths = df['OriginalTweet'].apply(lambda x: len(x.split()))\n",
        "df_lengthy = get_long_tweets(df, tweet_lengths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d10042fc-6c04-4da6-a5fb-d09bbf5c4292",
      "metadata": {
        "id": "d10042fc-6c04-4da6-a5fb-d09bbf5c4292",
        "outputId": "7a05aeb4-7cc1-4d39-d539-b824b3c38bb9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OriginalTweet</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>advice Talk to your neighbours family to excha...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>My food stock is not the only one which is emp...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
              "      <td>Extremely Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>As news of the regionÂs first confirmed COVID...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41152</th>\n",
              "      <td>Airline pilots offering to stock supermarket s...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41153</th>\n",
              "      <td>Response to complaint not provided citing COVI...</td>\n",
              "      <td>Extremely Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41154</th>\n",
              "      <td>You know itÂs getting tough when @KameronWild...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41155</th>\n",
              "      <td>Is it wrong that the smell of hand sanitizer i...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41156</th>\n",
              "      <td>@TartiiCat Well new/used Rift S are going for ...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>39899 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           OriginalTweet           Sentiment\n",
              "1      advice Talk to your neighbours family to excha...            Positive\n",
              "2      Coronavirus Australia: Woolworths to give elde...            Positive\n",
              "3      My food stock is not the only one which is emp...            Positive\n",
              "4      Me, ready to go at supermarket during the #COV...  Extremely Negative\n",
              "5      As news of the regionÂs first confirmed COVID...            Positive\n",
              "...                                                  ...                 ...\n",
              "41152  Airline pilots offering to stock supermarket s...             Neutral\n",
              "41153  Response to complaint not provided citing COVI...  Extremely Negative\n",
              "41154  You know itÂs getting tough when @KameronWild...            Positive\n",
              "41155  Is it wrong that the smell of hand sanitizer i...             Neutral\n",
              "41156  @TartiiCat Well new/used Rift S are going for ...            Negative\n",
              "\n",
              "[39899 rows x 2 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_lengthy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f4d37d7-dab2-45aa-9606-eaa3f825f93d",
      "metadata": {
        "id": "6f4d37d7-dab2-45aa-9606-eaa3f825f93d"
      },
      "outputs": [],
      "source": [
        "# Define preprocessing function\n",
        "def preprocessing(x):\n",
        "    def remove_hashtags(text): return re.sub(r'#', '' , text)\n",
        "    def remove_mentions(text): return re.sub(r'@', '' , text)\n",
        "    def remove_urls(text): return re.sub(r'https?://\\S+', ' ', text)\n",
        "    def change_apostrophe(text): return re.sub(r\"Â’\", \"\\'\", text)\n",
        "    def remove_special_chars(text): return re.sub(r\"[^\\w. ',-]\", ' ', text)\n",
        "    def remove_numbers(text): return re.sub(r'[\\d]', ' ', text)\n",
        "    def remove_formatting_symbols(text): return re.sub(r\"[\\r\\n]+\",'',text)\n",
        "    def remove_escape_characters(text): return re.sub(r\"\\\\\",'',text)\n",
        "    def remove_extra_spaces(text): return re.sub(r\"\\s{2,}\",' ',text)\n",
        "    def remove_space_before_period(text): return re.sub(r\"\\s\\.\", \".\", text)\n",
        "    def remove_strange_a(text): return \"\".join(c if ord(c)!=226 else \"a\" for c in text )\n",
        "    x=x.apply(remove_hashtags)\n",
        "    x=x.apply(remove_mentions)\n",
        "    x=x.apply(remove_urls)\n",
        "    x=x.apply(change_apostrophe)\n",
        "    x=x.apply(remove_special_chars)\n",
        "    x=x.apply(remove_numbers)\n",
        "    x=x.apply(remove_formatting_symbols)\n",
        "    x=x.apply(remove_escape_characters)\n",
        "    x=x.apply(remove_extra_spaces)\n",
        "    x=x.apply(remove_space_before_period)\n",
        "    x=x.str.lower()\n",
        "    x=x.apply(remove_strange_a)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "792bf4de-c36d-4689-b5c4-2514aa840c86",
      "metadata": {
        "id": "792bf4de-c36d-4689-b5c4-2514aa840c86",
        "outputId": "3cc51a3e-d316-4cee-f4e2-bd445ce2ec3f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_2709/1870583469.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_lengthy['OriginalTweet'] = preprocessing(df_lengthy['OriginalTweet'])\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OriginalTweet</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>advice talk to your neighbours family to excha...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>coronavirus australia woolworths to give elder...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>my food stock is not the only one which is emp...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>me, ready to go at supermarket during the covi...</td>\n",
              "      <td>Extremely Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>as news of the regiona s first confirmed covid...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41152</th>\n",
              "      <td>airline pilots offering to stock supermarket s...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41153</th>\n",
              "      <td>response to complaint not provided citing covi...</td>\n",
              "      <td>Extremely Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41154</th>\n",
              "      <td>you know ita s getting tough when kameronwilds...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41155</th>\n",
              "      <td>is it wrong that the smell of hand sanitizer i...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41156</th>\n",
              "      <td>tartiicat well new used rift s are going for. ...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>39899 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           OriginalTweet           Sentiment\n",
              "1      advice talk to your neighbours family to excha...            Positive\n",
              "2      coronavirus australia woolworths to give elder...            Positive\n",
              "3      my food stock is not the only one which is emp...            Positive\n",
              "4      me, ready to go at supermarket during the covi...  Extremely Negative\n",
              "5      as news of the regiona s first confirmed covid...            Positive\n",
              "...                                                  ...                 ...\n",
              "41152  airline pilots offering to stock supermarket s...             Neutral\n",
              "41153  response to complaint not provided citing covi...  Extremely Negative\n",
              "41154  you know ita s getting tough when kameronwilds...            Positive\n",
              "41155  is it wrong that the smell of hand sanitizer i...             Neutral\n",
              "41156  tartiicat well new used rift s are going for. ...            Negative\n",
              "\n",
              "[39899 rows x 2 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Apply preprocessing function to tweets\n",
        "df_lengthy['OriginalTweet'] = preprocessing(df_lengthy['OriginalTweet'])\n",
        "df_lengthy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b27e95f5-e422-4dcb-8e0b-cfd7ce8374d6",
      "metadata": {
        "id": "b27e95f5-e422-4dcb-8e0b-cfd7ce8374d6",
        "outputId": "b811d761-9625-481f-d5c5-b165998ea247"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_2709/2091456814.py:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_lengthy['Sentiment']=label_preprocessing(df_lengthy['Sentiment'])\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OriginalTweet</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>advice talk to your neighbours family to excha...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>coronavirus australia woolworths to give elder...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>my food stock is not the only one which is emp...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>me, ready to go at supermarket during the covi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>as news of the regiona s first confirmed covid...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41152</th>\n",
              "      <td>airline pilots offering to stock supermarket s...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41153</th>\n",
              "      <td>response to complaint not provided citing covi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41154</th>\n",
              "      <td>you know ita s getting tough when kameronwilds...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41155</th>\n",
              "      <td>is it wrong that the smell of hand sanitizer i...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41156</th>\n",
              "      <td>tartiicat well new used rift s are going for. ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>39899 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           OriginalTweet  Sentiment\n",
              "1      advice talk to your neighbours family to excha...          3\n",
              "2      coronavirus australia woolworths to give elder...          3\n",
              "3      my food stock is not the only one which is emp...          3\n",
              "4      me, ready to go at supermarket during the covi...          0\n",
              "5      as news of the regiona s first confirmed covid...          3\n",
              "...                                                  ...        ...\n",
              "41152  airline pilots offering to stock supermarket s...          2\n",
              "41153  response to complaint not provided citing covi...          0\n",
              "41154  you know ita s getting tough when kameronwilds...          3\n",
              "41155  is it wrong that the smell of hand sanitizer i...          2\n",
              "41156  tartiicat well new used rift s are going for. ...          1\n",
              "\n",
              "[39899 rows x 2 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define and application of preprocessing for the labels\n",
        "def label_preprocessing(labels):\n",
        "    lab_dict={\n",
        "        'Extremely Negative': 0,\n",
        "        'Negative': 1,\n",
        "        'Neutral': 2,\n",
        "        'Positive': 3,\n",
        "        'Extremely Positive': 4\n",
        "    }\n",
        "    labels=labels.map(lab_dict)\n",
        "\n",
        "    return labels\n",
        "\n",
        "df_lengthy['Sentiment']=label_preprocessing(df_lengthy['Sentiment'])\n",
        "df_lengthy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04ca8e49-cd2c-4482-ac1a-d5145901a58f",
      "metadata": {
        "id": "04ca8e49-cd2c-4482-ac1a-d5145901a58f",
        "outputId": "90a8b3df-afb7-440b-bd3d-df3056fc8d13"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OriginalTweet</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>advice talk to your neighbours family to excha...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>coronavirus australia woolworths to give elder...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>my food stock is not the only one which is emp...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>me, ready to go at supermarket during the covi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>as news of the regiona s first confirmed covid...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41152</th>\n",
              "      <td>airline pilots offering to stock supermarket s...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41153</th>\n",
              "      <td>response to complaint not provided citing covi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41154</th>\n",
              "      <td>you know ita s getting tough when kameronwilds...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41155</th>\n",
              "      <td>is it wrong that the smell of hand sanitizer i...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41156</th>\n",
              "      <td>tartiicat well new used rift s are going for. ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>39899 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           OriginalTweet  Sentiment\n",
              "1      advice talk to your neighbours family to excha...          3\n",
              "2      coronavirus australia woolworths to give elder...          3\n",
              "3      my food stock is not the only one which is emp...          3\n",
              "4      me, ready to go at supermarket during the covi...          0\n",
              "5      as news of the regiona s first confirmed covid...          3\n",
              "...                                                  ...        ...\n",
              "41152  airline pilots offering to stock supermarket s...          2\n",
              "41153  response to complaint not provided citing covi...          0\n",
              "41154  you know ita s getting tough when kameronwilds...          3\n",
              "41155  is it wrong that the smell of hand sanitizer i...          2\n",
              "41156  tartiicat well new used rift s are going for. ...          1\n",
              "\n",
              "[39899 rows x 2 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_to_use = df_lengthy\n",
        "df_to_use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "807527c3-383a-47d2-8d08-ffb640d3582e",
      "metadata": {
        "id": "807527c3-383a-47d2-8d08-ffb640d3582e",
        "outputId": "abaedbab-f069-42f5-d3de-6f355b79802e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OriginalTweet</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>advice talk to your neighbours family to excha...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>coronavirus australia woolworths to give elder...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>my food stock is not the only one which is emp...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>me, ready to go at supermarket during the covi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>as news of the regiona s first confirmed covid...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41152</th>\n",
              "      <td>airline pilots offering to stock supermarket s...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41153</th>\n",
              "      <td>response to complaint not provided citing covi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41154</th>\n",
              "      <td>you know ita s getting tough when kameronwilds...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41155</th>\n",
              "      <td>is it wrong that the smell of hand sanitizer i...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41156</th>\n",
              "      <td>tartiicat well new used rift s are going for. ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>39898 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           OriginalTweet  Sentiment\n",
              "1      advice talk to your neighbours family to excha...          3\n",
              "2      coronavirus australia woolworths to give elder...          3\n",
              "3      my food stock is not the only one which is emp...          3\n",
              "4      me, ready to go at supermarket during the covi...          0\n",
              "5      as news of the regiona s first confirmed covid...          3\n",
              "...                                                  ...        ...\n",
              "41152  airline pilots offering to stock supermarket s...          2\n",
              "41153  response to complaint not provided citing covi...          0\n",
              "41154  you know ita s getting tough when kameronwilds...          3\n",
              "41155  is it wrong that the smell of hand sanitizer i...          2\n",
              "41156  tartiicat well new used rift s are going for. ...          1\n",
              "\n",
              "[39898 rows x 2 columns]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Remove empty tweets from dataframe\n",
        "df_to_use = df_to_use[df_to_use[\"OriginalTweet\"] != \" \"]\n",
        "df_to_use"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split dataframe in train, test and validation sets. \\\n",
        "We split the dataframe following the 80/20 rule, 80% of the entire dataset is the trainset, 20% is the testset. \\\n",
        "Then the train set is splitted in 80% real train set and 20% is the validation set."
      ],
      "metadata": {
        "id": "cXpGkyKfUEbJ"
      },
      "id": "cXpGkyKfUEbJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e14f4292-cd45-4c9e-b6e1-31116e68fbc3",
      "metadata": {
        "id": "e14f4292-cd45-4c9e-b6e1-31116e68fbc3",
        "outputId": "b106f3ec-e9c9-45dc-d1d6-b38f2594aef6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train shape: (25534, 2), val shape:(6384, 2), test shape:(7980, 2)\n"
          ]
        }
      ],
      "source": [
        "# Splitting of the dataframe in train, val, test sets\n",
        "train_split, test_split = train_test_split(df_to_use, test_size = 0.2, random_state = 10,\n",
        "                                           stratify =  df_to_use[\"Sentiment\"])\n",
        "train_split, val_split = train_test_split(train_split, test_size = 0.2, random_state = 10,\n",
        "                                           stratify =  train_split[\"Sentiment\"])\n",
        "print(f\"train shape: {train_split.shape}, val shape:{val_split.shape}, test shape:{test_split.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "759636ea-cd6f-4ddb-9be0-3292244621ab",
      "metadata": {
        "id": "759636ea-cd6f-4ddb-9be0-3292244621ab"
      },
      "outputs": [],
      "source": [
        "# Load GloVe embedding for twitter\n",
        "global_vectors = GloVe(name='twitter.27B', dim = 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "866012d8-f5d8-4f44-a991-464453277922",
      "metadata": {
        "id": "866012d8-f5d8-4f44-a991-464453277922"
      },
      "outputs": [],
      "source": [
        "# Load basic english tokenizer\n",
        "tokenizer = get_tokenizer(\"basic_english\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c50a706a-066c-4418-8244-1b0cd629d1e1",
      "metadata": {
        "id": "c50a706a-066c-4418-8244-1b0cd629d1e1"
      },
      "outputs": [],
      "source": [
        "train_tweets = list(train_split.OriginalTweet.values)\n",
        "train_labels = list(train_split.Sentiment.values)\n",
        "val_tweets = list(val_split.OriginalTweet.values)\n",
        "val_labels = list(val_split.Sentiment.values)\n",
        "test_tweets = list(test_split.OriginalTweet.values)\n",
        "test_labels = list(test_split.Sentiment.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6e7fe64-73ad-446a-bee9-e71b8d4ae0bc",
      "metadata": {
        "id": "c6e7fe64-73ad-446a-bee9-e71b8d4ae0bc"
      },
      "outputs": [],
      "source": [
        "# Define the function for encode the tweets using GloVe embeddings\n",
        "def encode_split(tweet_list, max_words, embed_len=100):\n",
        "    X = [tokenizer(t) for t in tweet_list]\n",
        "    X = [tokens + [\"\"] * (max_words - len(tokens))  if len(tokens) < max_words else tokens[:max_words] for tokens in X]\n",
        "    X_tensor = torch.zeros(len(tweet_list), max_words, embed_len)\n",
        "    for i, tokens in enumerate(X):\n",
        "        X_tensor[i] = global_vectors.get_vecs_by_tokens(tokens)\n",
        "    return X_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c359d55-052c-4c3c-ae16-83f9544ba6ef",
      "metadata": {
        "id": "8c359d55-052c-4c3c-ae16-83f9544ba6ef",
        "outputId": "7c7dec8a-c945-499c-f863-7ba9b2482e1f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OriginalTweet</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2352</th>\n",
              "      <td>final thought - consider donating to a food pa...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37851</th>\n",
              "      <td>a the advice is to stock up on food and other ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15120</th>\n",
              "      <td>walking through the supermarket i stumbled upo...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6853</th>\n",
              "      <td>catfordmassive i've read an article saying the...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30269</th>\n",
              "      <td>as a measure against the spread of covid japan...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29747</th>\n",
              "      <td>there shouldn't be a tp shortage. mask shortag...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18059</th>\n",
              "      <td>sorry, millennials a coronavirus-induced reces...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36032</th>\n",
              "      <td>the april imon connections e-newsletter is now...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7010</th>\n",
              "      <td>all supermarket trollies and baskets need to b...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5399</th>\n",
              "      <td>this supermarket in australia opened its doors...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25534 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           OriginalTweet  Sentiment\n",
              "2352   final thought - consider donating to a food pa...          1\n",
              "37851  a the advice is to stock up on food and other ...          2\n",
              "15120  walking through the supermarket i stumbled upo...          4\n",
              "6853   catfordmassive i've read an article saying the...          1\n",
              "30269  as a measure against the spread of covid japan...          1\n",
              "...                                                  ...        ...\n",
              "29747  there shouldn't be a tp shortage. mask shortag...          1\n",
              "18059  sorry, millennials a coronavirus-induced reces...          3\n",
              "36032  the april imon connections e-newsletter is now...          4\n",
              "7010   all supermarket trollies and baskets need to b...          2\n",
              "5399   this supermarket in australia opened its doors...          4\n",
              "\n",
              "[25534 rows x 2 columns]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecf4736c-a720-4e70-94e6-998c707488e7",
      "metadata": {
        "id": "ecf4736c-a720-4e70-94e6-998c707488e7",
        "outputId": "6dfee6a1-0c7b-4259-9b1f-7be93969923b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OriginalTweet</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>19658</th>\n",
              "      <td>palladium gold regaining dma platinum silver u...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1974</th>\n",
              "      <td>if corona virus ever comes to uganda, some of ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11291</th>\n",
              "      <td>it is so bizarre to go to the grocery store wi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21894</th>\n",
              "      <td>don q rum to make hand sanitizer for puerto ri...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10295</th>\n",
              "      <td>you can feel the tension and stress in that su...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9509</th>\n",
              "      <td>how quickly the world changes. meanwhile actor...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3431</th>\n",
              "      <td>stay up to date on the latest in consumer fina...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34976</th>\n",
              "      <td>shopping during coronavirus higher prices aren...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29445</th>\n",
              "      <td>do you know two easy steps for homemade saniti...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40361</th>\n",
              "      <td>remember the trump campaign closing argument w...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6384 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           OriginalTweet  Sentiment\n",
              "19658  palladium gold regaining dma platinum silver u...          1\n",
              "1974   if corona virus ever comes to uganda, some of ...          0\n",
              "11291  it is so bizarre to go to the grocery store wi...          1\n",
              "21894  don q rum to make hand sanitizer for puerto ri...          3\n",
              "10295  you can feel the tension and stress in that su...          1\n",
              "...                                                  ...        ...\n",
              "9509   how quickly the world changes. meanwhile actor...          4\n",
              "3431   stay up to date on the latest in consumer fina...          2\n",
              "34976  shopping during coronavirus higher prices aren...          1\n",
              "29445  do you know two easy steps for homemade saniti...          3\n",
              "40361  remember the trump campaign closing argument w...          3\n",
              "\n",
              "[6384 rows x 2 columns]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We encode the train, val and test set using the function defined above, using 60 as <i>max_words</i>, because 60 is the value of the 90<sup>th</sup> percentile of the lenghts of the tweets in the training set."
      ],
      "metadata": {
        "id": "bIFhGYuAVNx5"
      },
      "id": "bIFhGYuAVNx5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74eefc6b-e8c7-477b-a69f-0a67592dee36",
      "metadata": {
        "id": "74eefc6b-e8c7-477b-a69f-0a67592dee36"
      },
      "outputs": [],
      "source": [
        "tok_train = encode_split(train_tweets, 60)\n",
        "tok_val = encode_split(val_tweets, 60)\n",
        "tok_test = encode_split(test_tweets, 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a847e8b-392c-4048-b399-48f099433839",
      "metadata": {
        "id": "6a847e8b-392c-4048-b399-48f099433839"
      },
      "outputs": [],
      "source": [
        "tok_train = tok_train.clone().detach()\n",
        "tok_test = tok_test.clone().detach()\n",
        "tok_val = tok_val.clone().detach()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f6b13d0-a62b-4d13-9ba7-a6d4814cfa8e",
      "metadata": {
        "id": "7f6b13d0-a62b-4d13-9ba7-a6d4814cfa8e"
      },
      "outputs": [],
      "source": [
        "# Convert other data types to torch.Tensor\n",
        "train_labels = torch.tensor(train_labels)\n",
        "val_labels = torch.tensor(val_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d5fe005-bc45-4b56-8e85-53c1fa7ae753",
      "metadata": {
        "id": "4d5fe005-bc45-4b56-8e85-53c1fa7ae753"
      },
      "outputs": [],
      "source": [
        "batch_size = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7233b06-ea7e-42c2-97b3-484825457b2e",
      "metadata": {
        "id": "f7233b06-ea7e-42c2-97b3-484825457b2e"
      },
      "outputs": [],
      "source": [
        "# Create the DataLoader for our training set\n",
        "train_data = TensorDataset(tok_train, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18047385-2c9a-4914-ade7-d3ec89e11b80",
      "metadata": {
        "id": "18047385-2c9a-4914-ade7-d3ec89e11b80"
      },
      "outputs": [],
      "source": [
        "# Create the DataLoader for our validation set\n",
        "val_data = TensorDataset(tok_val, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model utilizes pre-trained GloVe word embeddings as input and a fully connected layer for classification. \\\n",
        "This model is designed to establish baseline performance for our project work.\n"
      ],
      "metadata": {
        "id": "tfbf9DRFmEoe"
      },
      "id": "tfbf9DRFmEoe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f32fd235-35e4-4439-ae6d-87f84bffd20a",
      "metadata": {
        "id": "f32fd235-35e4-4439-ae6d-87f84bffd20a"
      },
      "outputs": [],
      "source": [
        "# Define the class of the model using a basic LSTM and a fully connected layer for classification\n",
        "class GloVeLSTM(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Attributes:\n",
        "      embedding_dim (int): Dimensionality of the GloVe word embeddings.\n",
        "      hidden_size (int): Number of hidden units in the LSTM layer.\n",
        "      num_layers (int): Number of stacked LSTM layers.\n",
        "      output_dim (int): Number of output classes (e.g., positive, negative, neutral).\n",
        "    \"\"\"\n",
        "    def __init__(self, embedding_dim, hidden_size, num_layers, output_dim):\n",
        "        super(GloVeLSTM, self).__init__()\n",
        "\n",
        "        self.lstm = torch.nn.LSTM(embedding_dim, hidden_size, batch_first=True, num_layers=num_layers, bidirectional=False)\n",
        "        self.fc = torch.nn.Linear(hidden_size * 2, output_dim)\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, (h, c) = self.lstm(x)\n",
        "        h = torch.cat((h[-2, :, :], h[-1, :, :]), dim=1)\n",
        "        out = self.fc(h.squeeze(0))\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55f8c1a0-0da7-49ac-84f6-2b9988467e03",
      "metadata": {
        "id": "55f8c1a0-0da7-49ac-84f6-2b9988467e03"
      },
      "outputs": [],
      "source": [
        "# Define hyperparameters for the GloVeLSTM model\n",
        "\n",
        "hidden_size = 256     # Number of hidden units in the LSTM layer\n",
        "output_dim = 5        # Number of output classes (Extremely negative, negative, ...)\n",
        "num_layers = 2        # Number of stacked LSTM layers\n",
        "embedding_dim = 100   # Dimensionality of the GloVe word embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfee5ad8-a137-40a0-9df3-a841c7a0147b",
      "metadata": {
        "id": "cfee5ad8-a137-40a0-9df3-a841c7a0147b"
      },
      "outputs": [],
      "source": [
        "model = GloVeLSTM(embedding_dim, hidden_size, num_layers, output_dim).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d28ff63c-a403-46d7-82c4-2e5cd9054300",
      "metadata": {
        "id": "d28ff63c-a403-46d7-82c4-2e5cd9054300"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, scheduler, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n",
        "    \"\"\"Train the GloveLSTM model.\n",
        "    \"\"\"\n",
        "    # Start training loop\n",
        "    print(\"Start training...\\n\")\n",
        "    loss_fn = torch.nn.CrossEntropyLoss()\n",
        "    for epoch_i in range(epochs):\n",
        "        # =======================================\n",
        "        #               Training\n",
        "        # =======================================\n",
        "        # Print the header of the result table\n",
        "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9}\")\n",
        "        print(\"-\"*70)\n",
        "\n",
        "        # Reset tracking variables at the beginning of each epoch\n",
        "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
        "\n",
        "        # Put the model into the training mode\n",
        "        model.train()\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            batch_counts +=1\n",
        "\n",
        "            # Load batch to GPU\n",
        "            b_input_ids, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "            # Zero out any previously calculated gradients\n",
        "            model.zero_grad()\n",
        "\n",
        "            # Perform a forward pass. This will return logits.\n",
        "            logits = model(b_input_ids)\n",
        "\n",
        "            # Compute loss and accumulate the loss values\n",
        "            loss = loss_fn(logits, b_labels)\n",
        "            batch_loss += loss.item()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate gradients\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and the learning rate\n",
        "            optimizer.step()\n",
        "            # scheduler.step()\n",
        "\n",
        "            # Print the loss values and time elapsed for every 20 batches\n",
        "            if (step % 100 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
        "                # Calculate time elapsed for 20 batches\n",
        "                # Print training results\n",
        "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9}\")\n",
        "                # Reset batch tracking variables\n",
        "                batch_loss, batch_counts = 0, 0\n",
        "                # Calculate the average loss over the entire training data\n",
        "                avg_train_loss = total_loss / len(train_dataloader)\n",
        "                print(\"-\"*70)\n",
        "\n",
        "        if evaluation == True:\n",
        "            # After the completion of each training epoch, measure the model's performance\n",
        "            # on our validation set.\n",
        "            val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
        "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "068f56d8-136c-4aa8-adcd-7505c2bc2552",
      "metadata": {
        "id": "068f56d8-136c-4aa8-adcd-7505c2bc2552"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, dataloader, return_preds=False):\n",
        "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
        "    on our validation set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "    loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    # Tracking variables\n",
        "    accuracies = []\n",
        "    losses = []\n",
        "\n",
        "    # For each batch in our validation set...\n",
        "    for batch in dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "\n",
        "            logits = model(b_input_ids)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = loss_fn(logits, b_labels)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            # Get the predictions\n",
        "            preds = torch.argmax(logits, dim=1).flatten()\n",
        "\n",
        "            if return_preds:\n",
        "                accuracies.append(preds)\n",
        "            else:\n",
        "                # Calculate the accuracy rate\n",
        "                acc = accuracy(preds, b_labels)\n",
        "                accuracies.append(acc)\n",
        "\n",
        "    # Compute the average accuracy and loss over the validation set.\n",
        "    loss = np.mean(losses)\n",
        "    acc = np.mean(accuracies)\n",
        "    return loss, acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab18ab59-0759-4d57-8c1e-57356fdc7047",
      "metadata": {
        "id": "ab18ab59-0759-4d57-8c1e-57356fdc7047"
      },
      "outputs": [],
      "source": [
        "def accuracy(pred_y, y):\n",
        "    \"\"\"Calculate accuracy.\"\"\"\n",
        "    return ((pred_y == y).sum() / len(y)).item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b07fe933-b78b-41ab-be32-d6811ed3ab19",
      "metadata": {
        "id": "b07fe933-b78b-41ab-be32-d6811ed3ab19",
        "outputId": "6c288cac-12da-442f-d10a-b271e339c798"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/fmg/v-giovanni/miniconda3/envs/gcns_text/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a basic recipe used for our baseline training run. \\\n",
        "It consists of 10 epochs, the Adam optimizer with a learning rate of 0.001, and no learning rate scheduler."
      ],
      "metadata": {
        "id": "E-C3EuPDpBFw"
      },
      "id": "E-C3EuPDpBFw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf72bf7e-9880-4752-b6e5-016b7e7d88a9",
      "metadata": {
        "id": "cf72bf7e-9880-4752-b6e5-016b7e7d88a9",
        "outputId": "fdedfab2-fc50-4059-eade-5d54c38ccc3e",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start training...\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc \n",
            "----------------------------------------------------------------------\n",
            "   1    |   100   |   1.563095   |     -      |     -    \n",
            "----------------------------------------------------------------------\n",
            "   1    |   200   |   1.539906   |     -      |     -    \n",
            "----------------------------------------------------------------------\n",
            "   1    |   300   |   1.501741   |     -      |     -    \n",
            "----------------------------------------------------------------------\n",
            "   1    |   398   |   1.468822   |     -      |     -    \n",
            "----------------------------------------------------------------------\n",
            "   1    |    -    |   1.518751   |  1.531048  |   0.28   \n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc \n",
            "----------------------------------------------------------------------\n",
            "   2    |   100   |   1.430154   |     -      |     -    \n",
            "----------------------------------------------------------------------\n",
            "   2    |   200   |   1.362270   |     -      |     -    \n",
            "----------------------------------------------------------------------\n",
            "   2    |   300   |   1.333682   |     -      |     -    \n",
            "----------------------------------------------------------------------\n",
            "   2    |   398   |   1.271219   |     -      |     -    \n",
            "----------------------------------------------------------------------\n",
            "   2    |    -    |   1.349925   |  1.196045  |   0.51   \n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc \n",
            "----------------------------------------------------------------------\n",
            "   3    |   100   |   1.185876   |     -      |     -    \n",
            "----------------------------------------------------------------------\n",
            "   3    |   200   |   1.152867   |     -      |     -    \n",
            "----------------------------------------------------------------------\n",
            "   3    |   300   |   1.130966   |     -      |     -    \n",
            "----------------------------------------------------------------------\n",
            "   3    |   398   |   1.114051   |     -      |     -    \n",
            "----------------------------------------------------------------------\n",
            "   3    |    -    |   1.146200   |  1.105032  |   0.55   \n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc \n",
            "----------------------------------------------------------------------\n",
            "   4    |   100   |   1.080150   |     -      |     -    \n",
            "----------------------------------------------------------------------\n",
            "   4    |   200   |   1.057458   |     -      |     -    \n",
            "----------------------------------------------------------------------\n",
            "   4    |   300   |   1.058748   |     -      |     -    \n",
            "----------------------------------------------------------------------\n",
            "   4    |   398   |   1.047249   |     -      |     -    \n",
            "----------------------------------------------------------------------\n",
            "   4    |    -    |   1.061018   |  1.058003  |   0.56   \n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc \n",
            "----------------------------------------------------------------------\n",
            "   5    |   100   |   1.018067   |     -      |     -    \n",
            "----------------------------------------------------------------------\n",
            "   5    |   200   |   0.978849   |     -      |     -    \n",
            "----------------------------------------------------------------------\n",
            "   5    |   300   |   0.996528   |     -      |     -    \n",
            "----------------------------------------------------------------------\n",
            "   5    |   398   |   0.983530   |     -      |     -    \n",
            "----------------------------------------------------------------------\n",
            "   5    |    -    |   0.994357   |  0.989218  |   0.60   \n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc \n",
            "----------------------------------------------------------------------\n",
            "   6    |   100   |   0.937687   |     -      |     -    \n",
            "----------------------------------------------------------------------\n",
            "   6    |   200   |   0.921133   |     -      |     -    \n",
            "----------------------------------------------------------------------\n",
            "   6    |   300   |   0.936910   |     -      |     -    \n",
            "----------------------------------------------------------------------\n",
            "   6    |   398   |   0.917210   |     -      |     -    \n",
            "----------------------------------------------------------------------\n",
            "   6    |    -    |   0.928314   |  0.948185  |   0.61   \n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc \n",
            "----------------------------------------------------------------------\n",
            "   7    |   100   |   0.871681   |     -      |     -    \n",
            "----------------------------------------------------------------------\n",
            "   7    |   200   |   0.858247   |     -      |     -    \n",
            "----------------------------------------------------------------------\n",
            "   7    |   300   |   0.852845   |     -      |     -    \n",
            "----------------------------------------------------------------------\n",
            "   7    |   398   |   0.842041   |     -      |     -    \n",
            "----------------------------------------------------------------------\n",
            "   7    |    -    |   0.856314   |  0.901022  |   0.64   \n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc \n",
            "----------------------------------------------------------------------\n",
            "   8    |   100   |   0.779164   |     -      |     -    \n",
            "----------------------------------------------------------------------\n",
            "   8    |   200   |   0.807912   |     -      |     -    \n",
            "----------------------------------------------------------------------\n",
            "   8    |   300   |   0.761934   |     -      |     -    \n",
            "----------------------------------------------------------------------\n",
            "   8    |   398   |   0.764251   |     -      |     -    \n",
            "----------------------------------------------------------------------\n",
            "   8    |    -    |   0.778388   |  0.885138  |   0.65   \n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc \n",
            "----------------------------------------------------------------------\n",
            "   9    |   100   |   0.699549   |     -      |     -    \n",
            "----------------------------------------------------------------------\n",
            "   9    |   200   |   0.722046   |     -      |     -    \n",
            "----------------------------------------------------------------------\n",
            "   9    |   300   |   0.706313   |     -      |     -    \n",
            "----------------------------------------------------------------------\n",
            "   9    |   398   |   0.696764   |     -      |     -    \n",
            "----------------------------------------------------------------------\n",
            "   9    |    -    |   0.706199   |  0.892802  |   0.66   \n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc \n",
            "----------------------------------------------------------------------\n",
            "  10    |   100   |   0.625415   |     -      |     -    \n",
            "----------------------------------------------------------------------\n",
            "  10    |   200   |   0.625235   |     -      |     -    \n",
            "----------------------------------------------------------------------\n",
            "  10    |   300   |   0.639929   |     -      |     -    \n",
            "----------------------------------------------------------------------\n",
            "  10    |   398   |   0.635937   |     -      |     -    \n",
            "----------------------------------------------------------------------\n",
            "  10    |    -    |   0.631592   |  0.882420  |   0.67   \n"
          ]
        }
      ],
      "source": [
        "train(model, optimizer, None, train_dataloader, val_dataloader, 10, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1e27cfd-0ff3-424c-8cfd-b1b722cfc8f6",
      "metadata": {
        "id": "a1e27cfd-0ff3-424c-8cfd-b1b722cfc8f6",
        "outputId": "c17ea74c-b85e-4cea-8b92-6ebeaa8baa4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy 0.6636022729873657\n"
          ]
        }
      ],
      "source": [
        "# Create the DataLoader for our validation set\n",
        "test_labels = torch.tensor(test_labels)\n",
        "test_data = TensorDataset(tok_test, test_labels)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n",
        "test_loss, test_acc = evaluate(model, test_dataloader)\n",
        "print(f\"Test accuracy {test_acc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our basic LSTM model achieved a validation accuracy of 67% and a test accuracy of 66%. These results serve as a valuable baseline for comparison with more complex models."
      ],
      "metadata": {
        "id": "YVNsVzMEsSPb"
      },
      "id": "YVNsVzMEsSPb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0b906cb-5b65-4998-8ae9-f5a98a60cf13",
      "metadata": {
        "id": "a0b906cb-5b65-4998-8ae9-f5a98a60cf13"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}