{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ddcd21a",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/GiovanniPioDelvecchio/GCNs_on_text/blob/issue%232/GNN_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "O65H_39pjzll",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O65H_39pjzll",
    "outputId": "cac82d35-5d38-424b-dbe8-757a1fcdea5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stanza\n",
      "  Downloading stanza-1.5.0-py3-none-any.whl (802 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.5/802.5 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting emoji (from stanza)\n",
      "  Downloading emoji-2.8.0-py2.py3-none-any.whl (358 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m358.9/358.9 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from stanza) (1.23.5)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from stanza) (3.20.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from stanza) (2.31.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from stanza) (1.16.0)\n",
      "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from stanza) (2.0.1+cu118)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stanza) (4.66.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (4.7.1)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.3.0->stanza) (3.27.2)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.3.0->stanza) (16.0.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3.0->stanza) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3.0->stanza) (1.3.0)\n",
      "Installing collected packages: emoji, stanza\n",
      "Successfully installed emoji-2.8.0 stanza-1.5.0\n",
      "Collecting torch-geometric\n",
      "  Downloading torch_geometric-2.3.1.tar.gz (661 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.6/661.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.23.5)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.10.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2023.7.22)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.2.0)\n",
      "Building wheels for collected packages: torch-geometric\n",
      "  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for torch-geometric: filename=torch_geometric-2.3.1-py3-none-any.whl size=910454 sha256=d707e3d353af0e32fa8c43e1335d5af34636d29bf364f0e59282919e75ba3b54\n",
      "  Stored in directory: /root/.cache/pip/wheels/ac/dc/30/e2874821ff308ee67dcd7a66dbde912411e19e35a1addda028\n",
      "Successfully built torch-geometric\n",
      "Installing collected packages: torch-geometric\n",
      "Successfully installed torch-geometric-2.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install stanza\n",
    "!pip install torch-geometric\n",
    "!pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6yqdrQQljb7U",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 741,
     "referenced_widgets": [
      "08a83cfdb3e14b7fa0d9550d5157757f",
      "bae4ff94e05b49f492940b780b06902b",
      "eebcdac8356643e287857bb64a437311",
      "f994056b677040abbe02b78d29657b13",
      "bf2b1d7e2fe1456983417b452916e6f7",
      "dca734e705be4e6baf26830734f19e5d",
      "3611d41b65524ac9be27926d32bcd8f8",
      "956e93be5fbd41eb91fd48aaf359d0db",
      "2153f77ceb624e61bf026fbff6401558",
      "8f4cf33b2e4f4c29805578124f31715c",
      "9b2ff8d09b494f80b0880abd06e901bc",
      "9ba649205fba4ab9b32117351252702e",
      "c35c428319ec49debec137185718f8df",
      "30a50f3a69674d528ffe4dd348d1bfc9",
      "54d11f0e363843b2b93aa46d91a75ecd",
      "af347f2a8e0a4544afba843f28c46de7",
      "dddd7fb1534c47baada9a154c17d54c2",
      "2d102cd39a9044db827334f508896608",
      "8bd326c21c804168af3b6d42027de27a",
      "31c64c73024e455ab0d46de7e501262b",
      "a2460b93db0e421981ed71e57e5afd14",
      "002b91e340bb4f67a661a75a18d70716",
      "e9341dbf06664cb1b3d0f337989b65b8",
      "4f8ce672c8784180bc7192caf85a1c9e",
      "0db679c436c2424d8ed70154a98c0d4f",
      "fbbcff1a383e46e1bce17a06a2a20d50",
      "f1c424dcc40645aa81f2f2df7c3e117c",
      "3c2686398da2437fa24952c53e7a8590",
      "e7a834ab5906438b890eca384580b00e",
      "fc138ff2b0c5475e9ed1ab89a3071208",
      "5cdc78a581c240929f68ff98ddf0855e",
      "831e50de14314050b9a568c248561039",
      "2566161e57eb40798dbca65324ae1d87"
     ]
    },
    "id": "6yqdrQQljb7U",
    "outputId": "8ec1688f-c13c-46b1-83a4-326668061bfd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-59a8933d-4a90-4978-b943-1e9f8b2a3c14\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-59a8933d-4a90-4978-b943-1e9f8b2a3c14\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving utils.py to utils.py\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08a83cfdb3e14b7fa0d9550d5157757f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:stanza:Downloading default packages for language: en (English) ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ba649205fba4ab9b32117351252702e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.5.0/models/default.zip:   0%|          | 0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:stanza:Finished downloading models and saved to /root/stanza_resources.\n",
      "INFO:stanza:Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9341dbf06664cb1b3d0f337989b65b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:stanza:Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "INFO:stanza:Using device: cuda\n",
      "INFO:stanza:Loading: tokenize\n",
      "INFO:stanza:Loading: pos\n",
      "INFO:stanza:Loading: lemma\n",
      "INFO:stanza:Loading: constituency\n",
      "INFO:stanza:Loading: depparse\n",
      "INFO:stanza:Loading: sentiment\n",
      "INFO:stanza:Loading: ner\n",
      "INFO:stanza:Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove path missing\n",
      "Utils have been correctly loaded\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "src = list(files.upload().values())[0]\n",
    "open('utils.py','wb').write(src)\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6820bb71",
   "metadata": {
    "id": "6820bb71"
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.023019790649414062,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json",
       "rate": null,
       "total": 30101,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c3f0ea2ab0f4a5880e65b4ba877e26b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-10 16:28:51 INFO: Downloading default packages for language: en (English) ...\n",
      "2023-09-10 16:28:55 INFO: File exists: C:\\Users\\giova\\stanza_resources\\en\\default.zip\n",
      "2023-09-10 16:29:01 INFO: Finished downloading models and saved to C:\\Users\\giova\\stanza_resources.\n",
      "2023-09-10 16:29:01 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.023020029067993164,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json",
       "rate": null,
       "total": 30101,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "875bcbe57f6047218514cb35ff65d60e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-10 16:29:03 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-09-10 16:29:03 INFO: Using device: cuda\n",
      "2023-09-10 16:29:03 INFO: Loading: tokenize\n",
      "2023-09-10 16:29:09 INFO: Loading: pos\n",
      "2023-09-10 16:29:10 INFO: Loading: lemma\n",
      "2023-09-10 16:29:10 INFO: Loading: constituency\n",
      "2023-09-10 16:29:11 INFO: Loading: depparse\n",
      "2023-09-10 16:29:12 INFO: Loading: sentiment\n",
      "2023-09-10 16:29:12 INFO: Loading: ner\n",
      "2023-09-10 16:29:14 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utils have been correctly loaded\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import save, load\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Dataset, InMemoryDataset\n",
    "from torch_geometric.utils import scatter\n",
    "from torch_geometric.data import download_url\n",
    "\n",
    "from torch_geometric.nn import GCNConv, GATv2Conv, global_mean_pool\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, Dropout\n",
    "\n",
    "from functools import partial\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.optim.lr_scheduler import PolynomialLR\n",
    "from torch_geometric.nn.pool import global_max_pool\n",
    "from torch.optim.lr_scheduler import OneCycleLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "K3zT6rr_jAhv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K3zT6rr_jAhv",
    "outputId": "b8cfbe6f-9ed1-40bd-a532-3bc2f25a6201"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00150981",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "00150981",
    "outputId": "c86fcd93-732a-42e4-9c3d-ba0548482445"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4463a9d3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4463a9d3",
    "outputId": "8c9d0a06-5a81-4cde-b8c3-929ab4a00856"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['content/processed_train//train.pt']\n",
      "['content/processed_val//val.pt']\n",
      "['content/processed_test//test.pt']\n",
      "Loaded training dataset:\n",
      "Dataset_from_sentences(25534)\n",
      "Loaded val dataset:\n",
      "Dataset_from_sentences(6384)\n",
      "Loaded test dataset:\n",
      "Dataset_from_sentences(7980)\n"
     ]
    }
   ],
   "source": [
    "tweet_list_train = []\n",
    "sentiment_list_train = []\n",
    "tweet_list_val = []\n",
    "sentiment_list_val = []\n",
    "tweet_list_test = []\n",
    "sentiment_list_test = []\n",
    "cv19_graph_data_train = utils.Dataset_from_sentences(\"train\", \"content/processed_train/\",\n",
    "                                                     \"content/drive/MyDrive/GraphDataset/train/\",\n",
    "                                                     tweet_list_train, sentiment_list_train)\n",
    "cv19_graph_data_val = utils.Dataset_from_sentences(\"val\", \"content/processed_val/\",\n",
    "                                                     \"content/drive/MyDrive/GraphDataset/val/\",\n",
    "                                                     tweet_list_train, sentiment_list_train)\n",
    "cv19_graph_data_test = utils.Dataset_from_sentences(\"test\", \"content/processed_test/\",\n",
    "                                                    \"content/drive/MyDrive/GraphDataset/test/\",\n",
    "                                                    tweet_list_test, sentiment_list_test)\n",
    "\n",
    "print(\"Loaded training dataset:\")\n",
    "print(cv19_graph_data_train)\n",
    "print(\"Loaded val dataset:\")\n",
    "print(cv19_graph_data_val)\n",
    "print(\"Loaded test dataset:\")\n",
    "print(cv19_graph_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f8e0549",
   "metadata": {
    "id": "3f8e0549"
   },
   "outputs": [],
   "source": [
    "# GCN definition\n",
    "class GCN(torch.nn.Module):\n",
    "  \"\"\"Graph Convolutional Network\"\"\"\n",
    "  def __init__(self, dim_in, n_filters, dim_out):\n",
    "    super().__init__()\n",
    "\n",
    "    self.first_linear = Linear(dim_in, dim_in)\n",
    "\n",
    "    self.gcn_list_1 = torch.nn.ModuleList([GCNConv(dim_in, dim_in, add_self_loops = True)\n",
    "                                         for i in range(0, n_filters)])\n",
    "    self.gcn_list_2 = torch.nn.ModuleList([GCNConv(dim_in, dim_in, add_self_loops = True)\n",
    "                                         for i in range(0, n_filters)])\n",
    "    self.gcn_list_3 = torch.nn.ModuleList([GCNConv(dim_in, dim_in, add_self_loops = True)\n",
    "                                         for i in range(0, n_filters)])\n",
    "\n",
    "    #self.gcn_1 = GCNConv(dim_in, dim_in, add_self_loops = True)\n",
    "    #self.gcn_2 = GCNConv(dim_in, dim_in, add_self_loops = True)\n",
    "    #self.gcn_3 = GCNConv(dim_in, dim_in, add_self_loops = True)\n",
    "    self.l_list = torch.nn.ModuleList([Linear(dim_in, 1)\n",
    "                                      for i in range(0, n_filters)])\n",
    "    self.classifier = Linear(n_filters, dim_out)\n",
    "    self.optimizer = torch.optim.Adam(self.parameters(),\n",
    "                                      lr=1e-3,\n",
    "                                      weight_decay=5e-5)\n",
    "\n",
    "  def forward(self, x, edge_index, batch, enable_log = False):\n",
    "    # the parameters of the forward correspond to data.x and data.edge_index\n",
    "    # where data is a Data object like those described above;\n",
    "    if enable_log:\n",
    "        utils.visualize_hidden_graph(x, edge_index)\n",
    "\n",
    "    #h = self.first_linear(x)\n",
    "\n",
    "    h_list = []\n",
    "    for i, gcn_l in enumerate(self.gcn_list_1):\n",
    "        h = x + gcn_l(x, edge_index)\n",
    "        h = h.tanh()\n",
    "        h = h + self.gcn_list_2[i](h, edge_index)\n",
    "        h = h.tanh()\n",
    "        h = h + self.gcn_list_3[i](h, edge_index)\n",
    "        if enable_log:\n",
    "            print(\"h shape: \" + str(h.shape))\n",
    "            utils.visualize_hidden_graph(h, edge_index)\n",
    "        h = global_mean_pool(h, batch)\n",
    "        h = self.l_list[i](h)\n",
    "        h_list.append(h)\n",
    "\n",
    "    h_layers = torch.hstack(h_list)\n",
    "    #print(h_layers.shape)\n",
    "    h_layers = self.classifier(h_layers)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    h = self.first_linear(x)\n",
    "    h = h + self.gcn_1(h, edge_index)\n",
    "    h = h + self.gcn_2(h, edge_index)\n",
    "    h = h + self.gcn_3(h, edge_index)\n",
    "    if enable_log:\n",
    "        visualize_hidden_graph(x, edge_index)\n",
    "    h = global_mean_pool(h, batch)\n",
    "    h = self.classifier(h)\n",
    "    \"\"\"\n",
    "\n",
    "    return h_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5faf4690",
   "metadata": {
    "id": "5faf4690"
   },
   "outputs": [],
   "source": [
    "# actual GAT class\n",
    "class GAT(torch.nn.Module):\n",
    "  \"\"\"Graph Attention Network\"\"\"\n",
    "  def __init__(self, dim_in, n_filters, dim_out, heads= 8):\n",
    "    super().__init__()\n",
    "    # dim_in is the number of node features, dim_h is the dimension\n",
    "    # of the hidden layer, dim_out is the dimension of the output\n",
    "    # feature vector\n",
    "    self.first_linear = Linear(dim_in, dim_in)\n",
    "\n",
    "    self.gat_list_1 = torch.nn.ModuleList([GATv2Conv(dim_in, dim_in // heads, heads = heads)\n",
    "                                         for i in range(0, n_filters)])\n",
    "    self.gat_list_2 = torch.nn.ModuleList([GATv2Conv(dim_in, dim_in // heads, heads = heads)\n",
    "                                         for i in range(0, n_filters)])\n",
    "    self.gat_list_3 = torch.nn.ModuleList([GATv2Conv(dim_in, dim_in // heads, heads = heads)\n",
    "                                         for i in range(0, n_filters)])\n",
    "\n",
    "    self.l_list = torch.nn.ModuleList([Linear(dim_in, 1)\n",
    "                                      for i in range(0, n_filters)])\n",
    "    self.classifier = Linear(n_filters, dim_out)\n",
    "    self.optimizer = torch.optim.Adam(self.parameters(),\n",
    "                                      lr=1e-3,\n",
    "                                      weight_decay=5e-5)\n",
    "\n",
    "  def forward(self, x, edge_index, batch, enable_log = False):\n",
    "    # the parameters of the forward correspond to data.x and data.edge_index\n",
    "    # where data is a Data object like those described above;\n",
    "    if enable_log:\n",
    "        utils.visualize_hidden_graph(x, edge_index)\n",
    "\n",
    "    #h = self.first_linear(x)\n",
    "\n",
    "    h_list = []\n",
    "    for i, gat_l in enumerate(self.gat_list_1):\n",
    "        #print(f\"shape of initial tensor x: {x.shape}\")\n",
    "        h = x + gat_l(x, edge_index)\n",
    "        #print(f\"shape of the first residual: {h.shape}\")\n",
    "        h = h.tanh()\n",
    "        h = h + self.gat_list_2[i](h, edge_index)\n",
    "        #print(f\"shape of the second residual: {h.shape}\")\n",
    "        h = h.tanh()\n",
    "        h = h + self.gat_list_3[i](h, edge_index)\n",
    "        #print(f\"shape of the third residual: {h.shape}\")\n",
    "        if enable_log:\n",
    "            print(\"h shape: \" + str(h.shape))\n",
    "            utils.visualize_hidden_graph(h, edge_index)\n",
    "        h = global_mean_pool(h, batch)\n",
    "        #print(f\"shape of the tensor after global mean pool: {h.shape}\")\n",
    "        h = self.l_list[i](h)\n",
    "        h_list.append(h)\n",
    "\n",
    "    h_layers = torch.hstack(h_list)\n",
    "    #print(h_layers.shape)\n",
    "    h_layers = self.classifier(h_layers)\n",
    "    return h_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec6fa11f",
   "metadata": {
    "id": "ec6fa11f"
   },
   "outputs": [],
   "source": [
    "class EarlyStopper:\n",
    "  def __init__(self, patience=1, min_delta=0):\n",
    "      self.patience = patience\n",
    "      self.min_delta = min_delta\n",
    "      self.counter = 0\n",
    "      self.min_validation_loss = np.inf\n",
    "\n",
    "  def early_stop(self, validation_loss):\n",
    "      if validation_loss < self.min_validation_loss:\n",
    "          self.min_validation_loss = validation_loss\n",
    "          self.counter = 0\n",
    "      elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "          self.counter += 1\n",
    "          if self.counter >= self.patience:\n",
    "              return True\n",
    "      return False\n",
    "\n",
    "def plot_losses(train_losses, val_losses):\n",
    "    \"\"\"\n",
    "    Plots the training and validation losses over the course of training.\n",
    "    Args:\n",
    "        train_losses: A list of training losses.\n",
    "        val_losses: A list of validation losses.\n",
    "    \"\"\"\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def accuracy(pred_y, y):\n",
    "    \"\"\"Calculate accuracy.\"\"\"\n",
    "    return ((pred_y == y).sum() / len(y)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f38b1c3",
   "metadata": {
    "id": "6f38b1c3"
   },
   "outputs": [],
   "source": [
    "def train(model, strat_train, strat_val, partial_scheduler, epochs = 30, batch_size = 30, print_every = 1, path='Model'):\n",
    "    \"\"\"Train a GNN model and return the trained model.\"\"\"\n",
    "    batch_size = batch_size\n",
    "    criterion = torch.nn.CrossEntropyLoss(label_smoothing = 0.01)\n",
    "    optimizer = model.optimizer\n",
    "    scheduler = partial_scheduler(optimizer)\n",
    "    print(type(scheduler))\n",
    "    loader_train =  DataLoader(strat_train.data_list, batch_size=batch_size, shuffle=True)\n",
    "    loader_val = DataLoader(strat_val.data_list, batch_size=batch_size, shuffle=True)\n",
    "    model.train()\n",
    "    early_stopper = EarlyStopper(patience=10, min_delta=0.2)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    best_model = []\n",
    "    best_acc_val = 0\n",
    "    epochs_to_return = 0\n",
    "\n",
    "    #scheduler.step()\n",
    "    for epoch in range(epochs+1):\n",
    "      mean_loss_train = 0\n",
    "      mean_acc_train = 0\n",
    "      for i, batch in enumerate(loader_train):\n",
    "        # Training\n",
    "\n",
    "        out = model(batch.x, batch.edge_index, batch.batch)\n",
    "        loss_train = criterion(out, batch.y.long())\n",
    "        mean_loss_train += loss_train.item()\n",
    "\n",
    "        acc_train = accuracy(out.argmax(dim=1), batch.y)\n",
    "        mean_acc_train += acc_train\n",
    "        loss_train.backward()\n",
    "        with torch.no_grad():\n",
    "            optimizer.step()\n",
    "            if type(scheduler) == OneCycleLR:\n",
    "                scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "      print(i)\n",
    "      mean_loss_train /= (i + 1)\n",
    "      mean_acc_train /= (i + 1)\n",
    "      train_losses.append(mean_loss_train)\n",
    "      if type(scheduler) != OneCycleLR:\n",
    "          scheduler.step()\n",
    "\n",
    "      mean_loss_val = 0\n",
    "      mean_acc_val = 0\n",
    "      #model.eval()\n",
    "      with torch.no_grad():\n",
    "          for i, batch in enumerate(loader_val):\n",
    "            out = model(batch.x, batch.edge_index, batch.batch)\n",
    "            loss_val = criterion(out, batch.y.long())\n",
    "            mean_loss_val += loss_val.item()\n",
    "            acc_val = accuracy(out.argmax(dim=1), batch.y)\n",
    "            mean_acc_val += acc_val\n",
    "            #visualize_embedding(embed, batch.y, epoch, loss_val)\n",
    "          mean_loss_val /= (i + 1)\n",
    "          mean_acc_val /= (i + 1)\n",
    "          val_losses.append(mean_loss_val)\n",
    "          if mean_acc_val > best_acc_val:\n",
    "                best_acc_val = mean_acc_val\n",
    "                best_model = copy.deepcopy(model)\n",
    "                epochs_to_return = epoch\n",
    "          if epoch % 15 == 0 and epoch > 0:\n",
    "            torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': model.optimizer.state_dict(),\n",
    "            'loss': mean_loss_train,\n",
    "            }, path + '_ckpt')\n",
    "       # model.train()\n",
    "\n",
    "      if(epoch % print_every == 0):\n",
    "        print(f'Epoch {epoch:>3} | Train Loss: {mean_loss_train:.3f} | Train Acc: '\n",
    "              f'{mean_acc_train*100:>6.2f}%')\n",
    "        print(f'Epoch {epoch:>3} | Val Loss: {mean_loss_val:.3f} | Val Acc: '\n",
    "              f'{mean_acc_val*100:>6.2f}%')\n",
    "        print(\"learning rate: \" + str(scheduler.get_last_lr()))\n",
    "      if early_stopper.early_stop(mean_loss_val):\n",
    "        print(\"early stopping was triggered, final loss:\" + str(mean_loss_val))\n",
    "        break\n",
    "    plot_losses(train_losses, val_losses)\n",
    "    return best_model, best_acc_val, epochs_to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a89b74e7",
   "metadata": {
    "id": "a89b74e7"
   },
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "def build_scheduler_list(epochs = 30, max_lr = 1e-3, num_batches = 1):\n",
    "    schedulers = []\n",
    "\n",
    "    #schedulers += [partial(PolynomialLR,\n",
    "    #                     total_iters = epochs, # The number of steps that the scheduler decays the learning rate.\n",
    "    #                     power = i) for i in range(2, 3)] # The power of the polynomial. # 2 to 1\n",
    "    #schedulers += [partial(StepLR,\n",
    "    #                              step_size=epochs//i, gamma=0.5) for i in range(3, 5)] # 4 to 3\n",
    "    schedulers += [partial(CosineAnnealingLR,\n",
    "                              T_max = epochs, # Maximum number of iterations.\n",
    "                              eta_min = min_lr) for min_lr in [1e-6, 1e-7, 1e-8]]# Minimum learning rate\n",
    "    #schedulers += [partial(OneCycleLR,\n",
    "    #                   max_lr = max_lr, # Upper learning rate boundaries in the cycle for each parameter group\n",
    "    #                   steps_per_epoch = num_batches, # The number of steps per epoch to train for.\n",
    "    #                   epochs = epochs, # The number of epochs to train for.\n",
    "    #                   anneal_strategy = 'cos')] # Specifies the annealing strategy\n",
    "    return schedulers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "941dee58",
   "metadata": {
    "id": "941dee58"
   },
   "outputs": [],
   "source": [
    "def hyperparameter_tuning(model, strat_train, strat_val, scheduler_list, batch_size = 30, epochs = 30):\n",
    "    print(f\"batch size: {batch_size}\")\n",
    "    best_valid_acc = 0\n",
    "    best_model = []\n",
    "    best_hyper_params = []\n",
    "    best_val_acc = 0\n",
    "    i = 1\n",
    "    for partial_scheduler in scheduler_list:\n",
    "        path = f'/content/drive/MyDrive/graphmod/{partial_scheduler.func.__name__}_{i}'\n",
    "        model_out, mean_acc_val, epoch = train(copy.deepcopy(model), strat_train, strat_val,\n",
    "                                               partial_scheduler, epochs, batch_size = batch_size, print_every=1, path=path)\n",
    "        torch.save(model_out,path)\n",
    "        if mean_acc_val > best_val_acc:\n",
    "            best_val_acc = mean_acc_val\n",
    "            best_model = model_out\n",
    "            best_hyper_params = [partial_scheduler, epoch]\n",
    "            print(f\"Improved result: acc {best_val_acc:.3f}, scheduler:\\n {partial_scheduler}\\nepoch: {epoch}\")\n",
    "        i = i + 1\n",
    "    return best_hyper_params, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7faa84c",
   "metadata": {
    "id": "a7faa84c"
   },
   "outputs": [],
   "source": [
    "cv19_graph_data_train = cv19_graph_data_train.to(device)\n",
    "cv19_graph_data_val = cv19_graph_data_val.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234a2ed8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "234a2ed8",
    "outputId": "bf797320-611a-474a-e4c1-e731044edcb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (first_linear): Linear(in_features=50, out_features=50, bias=True)\n",
      "  (gcn_list_1): ModuleList(\n",
      "    (0-9): 10 x GCNConv(50, 50)\n",
      "  )\n",
      "  (gcn_list_2): ModuleList(\n",
      "    (0-9): 10 x GCNConv(50, 50)\n",
      "  )\n",
      "  (gcn_list_3): ModuleList(\n",
      "    (0-9): 10 x GCNConv(50, 50)\n",
      "  )\n",
      "  (l_list): ModuleList(\n",
      "    (0-9): 10 x Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      "  (classifier): Linear(in_features=10, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_gcn = GCN(cv19_graph_data_train.num_node_features,\n",
    "                cv19_graph_data_train.num_classes*2,\n",
    "                cv19_graph_data_train.num_classes).to(device)\n",
    "print(model_gcn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "770d5afc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "id": "770d5afc",
    "outputId": "b877f254-7372-4cc7-c8fa-51228c4d30f6"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-e8c5de88b5d4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_gcn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mscheduler_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_scheduler_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscheduler_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_gcn' is not defined"
     ]
    }
   ],
   "source": [
    "print(get_lr(model_gcn.optimizer))\n",
    "scheduler_list = build_scheduler_list()\n",
    "print(scheduler_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804b3a57",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "804b3a57",
    "outputId": "1b62fbb4-991c-4a21-bb2d-989b1e67bb9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: 128\n",
      "<class 'torch.optim.lr_scheduler.PolynomialLR'>\n",
      "Epoch   0 | Train Loss: 1.474 | Train Acc:  33.77%\n",
      "Epoch   0 | Val Loss: 1.408 | Val Acc:  38.31%\n",
      "learning rate: [0.0009666666666666667]\n",
      "Epoch   1 | Train Loss: 1.401 | Train Acc:  38.34%\n",
      "Epoch   1 | Val Loss: 1.382 | Val Acc:  39.78%\n",
      "learning rate: [0.0009333333333333334]\n",
      "Epoch   2 | Train Loss: 1.386 | Train Acc:  39.53%\n",
      "Epoch   2 | Val Loss: 1.381 | Val Acc:  39.57%\n",
      "learning rate: [0.0009000000000000001]\n",
      "Epoch   3 | Train Loss: 1.376 | Train Acc:  40.00%\n",
      "Epoch   3 | Val Loss: 1.371 | Val Acc:  40.19%\n",
      "learning rate: [0.0008666666666666668]\n",
      "Epoch   4 | Train Loss: 1.368 | Train Acc:  40.52%\n",
      "Epoch   4 | Val Loss: 1.356 | Val Acc:  40.78%\n",
      "learning rate: [0.0008333333333333335]\n",
      "Epoch   5 | Train Loss: 1.360 | Train Acc:  40.90%\n",
      "Epoch   5 | Val Loss: 1.374 | Val Acc:  39.70%\n",
      "learning rate: [0.0008000000000000001]\n",
      "Epoch   6 | Train Loss: 1.354 | Train Acc:  41.15%\n",
      "Epoch   6 | Val Loss: 1.349 | Val Acc:  41.65%\n",
      "learning rate: [0.0007666666666666668]\n",
      "Epoch   7 | Train Loss: 1.345 | Train Acc:  41.72%\n",
      "Epoch   7 | Val Loss: 1.335 | Val Acc:  42.30%\n",
      "learning rate: [0.0007333333333333336]\n",
      "Epoch   8 | Train Loss: 1.339 | Train Acc:  42.07%\n",
      "Epoch   8 | Val Loss: 1.331 | Val Acc:  42.35%\n",
      "learning rate: [0.0007000000000000001]\n",
      "Epoch   9 | Train Loss: 1.333 | Train Acc:  42.06%\n",
      "Epoch   9 | Val Loss: 1.321 | Val Acc:  43.05%\n",
      "learning rate: [0.0006666666666666669]\n",
      "Epoch  10 | Train Loss: 1.325 | Train Acc:  42.76%\n",
      "Epoch  10 | Val Loss: 1.315 | Val Acc:  42.97%\n",
      "learning rate: [0.0006333333333333334]\n",
      "Epoch  11 | Train Loss: 1.321 | Train Acc:  42.99%\n",
      "Epoch  11 | Val Loss: 1.308 | Val Acc:  43.46%\n",
      "learning rate: [0.0006000000000000001]\n",
      "Epoch  12 | Train Loss: 1.312 | Train Acc:  43.44%\n",
      "Epoch  12 | Val Loss: 1.315 | Val Acc:  43.53%\n",
      "learning rate: [0.0005666666666666667]\n",
      "Epoch  13 | Train Loss: 1.308 | Train Acc:  43.58%\n",
      "Epoch  13 | Val Loss: 1.297 | Val Acc:  44.27%\n",
      "learning rate: [0.0005333333333333334]\n",
      "Epoch  14 | Train Loss: 1.303 | Train Acc:  43.87%\n",
      "Epoch  14 | Val Loss: 1.293 | Val Acc:  44.71%\n",
      "learning rate: [0.0005]\n",
      "Epoch  15 | Train Loss: 1.295 | Train Acc:  44.12%\n",
      "Epoch  15 | Val Loss: 1.288 | Val Acc:  44.38%\n",
      "learning rate: [0.00046666666666666666]\n",
      "Epoch  16 | Train Loss: 1.290 | Train Acc:  44.50%\n",
      "Epoch  16 | Val Loss: 1.284 | Val Acc:  44.62%\n",
      "learning rate: [0.00043333333333333337]\n",
      "Epoch  17 | Train Loss: 1.285 | Train Acc:  44.95%\n",
      "Epoch  17 | Val Loss: 1.273 | Val Acc:  45.71%\n",
      "learning rate: [0.0004000000000000001]\n",
      "Epoch  18 | Train Loss: 1.280 | Train Acc:  45.07%\n",
      "Epoch  18 | Val Loss: 1.271 | Val Acc:  45.72%\n",
      "learning rate: [0.0003666666666666668]\n",
      "Epoch  19 | Train Loss: 1.276 | Train Acc:  45.30%\n",
      "Epoch  19 | Val Loss: 1.268 | Val Acc:  45.86%\n",
      "learning rate: [0.0003333333333333335]\n",
      "Epoch  20 | Train Loss: 1.270 | Train Acc:  45.44%\n",
      "Epoch  20 | Val Loss: 1.265 | Val Acc:  46.23%\n",
      "learning rate: [0.00030000000000000014]\n",
      "Epoch  21 | Train Loss: 1.268 | Train Acc:  46.05%\n",
      "Epoch  21 | Val Loss: 1.261 | Val Acc:  46.39%\n",
      "learning rate: [0.0002666666666666668]\n",
      "Epoch  22 | Train Loss: 1.262 | Train Acc:  46.07%\n",
      "Epoch  22 | Val Loss: 1.260 | Val Acc:  46.24%\n",
      "learning rate: [0.00023333333333333336]\n",
      "Epoch  23 | Train Loss: 1.260 | Train Acc:  46.22%\n",
      "Epoch  23 | Val Loss: 1.251 | Val Acc:  46.62%\n",
      "learning rate: [0.0002]\n",
      "Epoch  24 | Train Loss: 1.256 | Train Acc:  46.47%\n",
      "Epoch  24 | Val Loss: 1.250 | Val Acc:  46.84%\n",
      "learning rate: [0.0001666666666666667]\n",
      "Epoch  25 | Train Loss: 1.251 | Train Acc:  46.77%\n",
      "Epoch  25 | Val Loss: 1.250 | Val Acc:  46.87%\n",
      "learning rate: [0.00013333333333333337]\n",
      "Epoch  26 | Train Loss: 1.250 | Train Acc:  46.81%\n",
      "Epoch  26 | Val Loss: 1.245 | Val Acc:  46.96%\n",
      "learning rate: [0.00010000000000000002]\n",
      "Epoch  27 | Train Loss: 1.246 | Train Acc:  46.90%\n",
      "Epoch  27 | Val Loss: 1.244 | Val Acc:  46.84%\n",
      "learning rate: [6.666666666666667e-05]\n",
      "Epoch  28 | Train Loss: 1.245 | Train Acc:  46.94%\n",
      "Epoch  28 | Val Loss: 1.243 | Val Acc:  46.96%\n",
      "learning rate: [3.3333333333333335e-05]\n",
      "Epoch  29 | Train Loss: 1.243 | Train Acc:  47.19%\n",
      "Epoch  29 | Val Loss: 1.242 | Val Acc:  47.01%\n",
      "learning rate: [0.0]\n",
      "Epoch  30 | Train Loss: 1.242 | Train Acc:  47.02%\n",
      "Epoch  30 | Val Loss: 1.242 | Val Acc:  47.02%\n",
      "learning rate: [0.0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved result: acc 0.470, scheduler:\n",
      " functools.partial(<class 'torch.optim.lr_scheduler.PolynomialLR'>, total_iters=30, power=1)\n",
      "epoch: 30\n",
      "<class 'torch.optim.lr_scheduler.PolynomialLR'>\n",
      "Epoch   0 | Train Loss: 1.480 | Train Acc:  33.53%\n",
      "Epoch   0 | Val Loss: 1.422 | Val Acc:  37.10%\n",
      "learning rate: [0.0009344444444444444]\n",
      "Epoch   1 | Train Loss: 1.403 | Train Acc:  38.18%\n",
      "Epoch   1 | Val Loss: 1.388 | Val Acc:  38.92%\n",
      "learning rate: [0.0008711111111111112]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-3f2017b8fd4a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrained_gcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhyperparameter_tuning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_gcn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrat_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrat_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-45-57ce15107480>\u001b[0m in \u001b[0;36mhyperparameter_tuning\u001b[0;34m(model, strat_train, strat_val, scheduler_list, batch_size, epochs)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mbest_val_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpartial_scheduler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscheduler_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         model_out, mean_acc_val, epoch = train(copy.deepcopy(model), strat_train, strat_val, \n\u001b[0m\u001b[1;32m      9\u001b[0m                                                partial_scheduler, epochs, batch_size = batch_size, print_every=1)\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmean_acc_val\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_val_acc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-42e113b44416>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, strat_train, strat_val, partial_scheduler, epochs, batch_size, print_every)\u001b[0m\n\u001b[1;32m     46\u001b[0m       \u001b[0mmean_acc_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/data/batch.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                 or (isinstance(idx, np.ndarray) and np.isscalar(idx))):\n\u001b[0;32m--> 154\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m         elif isinstance(idx, str) or (isinstance(idx, tuple)\n\u001b[1;32m    156\u001b[0m                                       and isinstance(idx[0], str)):\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/data/batch.py\u001b[0m in \u001b[0;36mget_example\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    101\u001b[0m                  \"'Batch' was not created via 'Batch.from_data_list()'\"))\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         data = separate(\n\u001b[0m\u001b[1;32m    104\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__bases__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/data/separate.py\u001b[0m in \u001b[0;36mseparate\u001b[0;34m(cls, batch, idx, slice_dict, inc_dict, decrement)\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mslices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mincs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minc_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdecrement\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             data_store[attr] = _separate(attr, batch_store[attr], idx, slices,\n\u001b[0m\u001b[1;32m     38\u001b[0m                                          incs, batch, batch_store, decrement)\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trained_gcn = hyperparameter_tuning(model_gcn, strat_train, strat_val, scheduler_list, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7dc5ee6a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7dc5ee6a",
    "outputId": "9e6ed414-29b5-4172-d3bc-b3f9802dd298"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAT(\n",
      "  (first_linear): Linear(in_features=50, out_features=50, bias=True)\n",
      "  (gat_list_1): ModuleList(\n",
      "    (0-9): 10 x GATv2Conv(50, 5, heads=10)\n",
      "  )\n",
      "  (gat_list_2): ModuleList(\n",
      "    (0-9): 10 x GATv2Conv(50, 5, heads=10)\n",
      "  )\n",
      "  (gat_list_3): ModuleList(\n",
      "    (0-9): 10 x GATv2Conv(50, 5, heads=10)\n",
      "  )\n",
      "  (l_list): ModuleList(\n",
      "    (0-9): 10 x Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      "  (classifier): Linear(in_features=10, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_gat = GAT(cv19_graph_data_train.num_node_features,\n",
    "                cv19_graph_data_train.num_classes*2,\n",
    "                cv19_graph_data_train.num_classes, heads = 10).to(device)\n",
    "print(model_gat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2iipfRCljZz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "e2iipfRCljZz",
    "outputId": "6146be3e-28c4-4c7d-b9ce-916767cdd2b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "[functools.partial(<class 'torch.optim.lr_scheduler.CosineAnnealingLR'>, T_max=300, eta_min=1e-06), functools.partial(<class 'torch.optim.lr_scheduler.CosineAnnealingLR'>, T_max=300, eta_min=1e-07), functools.partial(<class 'torch.optim.lr_scheduler.CosineAnnealingLR'>, T_max=300, eta_min=1e-08)]\n",
      "batch size: 256\n",
      "<class 'torch.optim.lr_scheduler.CosineAnnealingLR'>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m scheduler_list \u001b[38;5;241m=\u001b[39m build_scheduler_list(epochs\u001b[38;5;241m=\u001b[39mepochs, \n\u001b[0;32m      6\u001b[0m                                       num_batches\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mlen\u001b[39m(cv19_graph_data_train\u001b[38;5;241m.\u001b[39mdata_list)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m256\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(scheduler_list)\n\u001b[1;32m----> 8\u001b[0m trained_gat \u001b[38;5;241m=\u001b[39m \u001b[43mhyperparameter_tuning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_gat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv19_graph_data_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv19_graph_data_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36mhyperparameter_tuning\u001b[1;34m(model, strat_train, strat_val, scheduler_list, batch_size, epochs)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m partial_scheduler \u001b[38;5;129;01min\u001b[39;00m scheduler_list:\n\u001b[0;32m      9\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive/MyDrive/graphmod/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpartial_scheduler\u001b[38;5;241m.\u001b[39mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 10\u001b[0m     model_out, mean_acc_val, epoch \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrat_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrat_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mpartial_scheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(model_out,path)\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mean_acc_val \u001b[38;5;241m>\u001b[39m best_val_acc:\n",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, strat_train, strat_val, partial_scheduler, epochs, batch_size, print_every, path)\u001b[0m\n\u001b[0;32m     22\u001b[0m mean_loss_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     23\u001b[0m mean_acc_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loader_train):\n\u001b[0;32m     25\u001b[0m   \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[0;32m     27\u001b[0m   out \u001b[38;5;241m=\u001b[39m model(batch\u001b[38;5;241m.\u001b[39mx, batch\u001b[38;5;241m.\u001b[39medge_index, batch\u001b[38;5;241m.\u001b[39mbatch)\n\u001b[0;32m     28\u001b[0m   loss_train \u001b[38;5;241m=\u001b[39m criterion(out, batch\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39mlong())\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch_geometric\\data\\batch.py:154\u001b[0m, in \u001b[0;36mBatch.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx: Union[\u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39minteger, \u001b[38;5;28mstr\u001b[39m, IndexType]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, (\u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39minteger))\n\u001b[0;32m    152\u001b[0m             \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, Tensor) \u001b[38;5;129;01mand\u001b[39;00m idx\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    153\u001b[0m             \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(idx))):\n\u001b[1;32m--> 154\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mtuple\u001b[39m)\n\u001b[0;32m    156\u001b[0m                                   \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mstr\u001b[39m)):\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;66;03m# Accessing attributes or node/edge types:\u001b[39;00m\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(idx)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch_geometric\\data\\batch.py:103\u001b[0m, in \u001b[0;36mBatch.get_example\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_slice_dict\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    100\u001b[0m         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot reconstruct \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object from \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBatch\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m because \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    101\u001b[0m          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBatch\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m was not created via \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBatch.from_data_list()\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m--> 103\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mseparate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__bases__\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mslice_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_slice_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43minc_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inc_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecrement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch_geometric\\data\\separate.py:37\u001b[0m, in \u001b[0;36mseparate\u001b[1;34m(cls, batch, idx, slice_dict, inc_dict, decrement)\u001b[0m\n\u001b[0;32m     35\u001b[0m         slices \u001b[38;5;241m=\u001b[39m slice_dict[attr]\n\u001b[0;32m     36\u001b[0m         incs \u001b[38;5;241m=\u001b[39m inc_dict[attr] \u001b[38;5;28;01mif\u001b[39;00m decrement \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m     data_store[attr] \u001b[38;5;241m=\u001b[39m \u001b[43m_separate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_store\u001b[49m\u001b[43m[\u001b[49m\u001b[43mattr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mincs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_store\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecrement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# The `num_nodes` attribute needs special treatment, as we cannot infer\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# the real number of nodes from the total number of nodes alone:\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(batch_store, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_num_nodes\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch_geometric\\data\\separate.py:68\u001b[0m, in \u001b[0;36m_separate\u001b[1;34m(key, value, idx, slices, incs, batch, store, decrement)\u001b[0m\n\u001b[0;32m     66\u001b[0m     value \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m cat_dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m value\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m decrement \u001b[38;5;129;01mand\u001b[39;00m (incs\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mint\u001b[39m(incs[idx]) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m---> 68\u001b[0m         value \u001b[38;5;241m=\u001b[39m value \u001b[38;5;241m-\u001b[39m \u001b[43mincs\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, SparseTensor) \u001b[38;5;129;01mand\u001b[39;00m decrement:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;66;03m# Narrow a `SparseTensor` based on `slices`.\u001b[39;00m\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;66;03m# NOTE: `cat_dim` may return a tuple to allow for diagonal stacking.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 300\n",
    "# da rifare esperimenti col polinomial 2\n",
    "# training information from stepLR (2) to CosineAnnealing\n",
    "print(get_lr(model_gat.optimizer))\n",
    "scheduler_list = build_scheduler_list(epochs=epochs, \n",
    "                                      num_batches=(len(cv19_graph_data_train.data_list)//256) + 4)\n",
    "print(scheduler_list)\n",
    "trained_gat = hyperparameter_tuning(model_gat, cv19_graph_data_train, \n",
    "                                    cv19_graph_data_test, scheduler_list, \n",
    "                                    batch_size = 256, epochs = epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EcMlIpQjljLK",
   "metadata": {
    "id": "EcMlIpQjljLK"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "U-t1hntA7WC0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "U-t1hntA7WC0",
    "outputId": "8df9618a-e170-410f-8334-982f326471ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "[functools.partial(<class 'torch.optim.lr_scheduler.PolynomialLR'>, total_iters=300, power=1), functools.partial(<class 'torch.optim.lr_scheduler.PolynomialLR'>, total_iters=300, power=2), functools.partial(<class 'torch.optim.lr_scheduler.StepLR'>, step_size=100, gamma=0.5), functools.partial(<class 'torch.optim.lr_scheduler.StepLR'>, step_size=75, gamma=0.5), functools.partial(<class 'torch.optim.lr_scheduler.CosineAnnealingLR'>, T_max=300, eta_min=1e-06), functools.partial(<class 'torch.optim.lr_scheduler.CosineAnnealingLR'>, T_max=300, eta_min=1e-07), functools.partial(<class 'torch.optim.lr_scheduler.CosineAnnealingLR'>, T_max=300, eta_min=1e-08), functools.partial(<class 'torch.optim.lr_scheduler.OneCycleLR'>, max_lr=0.001, steps_per_epoch=10, epochs=300, anneal_strategy='cos'), functools.partial(<class 'torch.optim.lr_scheduler.OneCycleLR'>, max_lr=0.001, steps_per_epoch=50, epochs=300, anneal_strategy='cos'), functools.partial(<class 'torch.optim.lr_scheduler.OneCycleLR'>, max_lr=0.001, steps_per_epoch=100, epochs=300, anneal_strategy='cos')]\n",
      "batch size: 256\n",
      "<class 'torch.optim.lr_scheduler.PolynomialLR'>\n",
      "Epoch   0 | Train Loss: 1.471 | Train Acc:  33.63%\n",
      "Epoch   0 | Val Loss: 1.377 | Val Acc:  39.13%\n",
      "learning rate: [0.0009966666666666668]\n",
      "Epoch   1 | Train Loss: 1.351 | Train Acc:  40.45%\n",
      "Epoch   1 | Val Loss: 1.316 | Val Acc:  42.23%\n",
      "learning rate: [0.0009933333333333333]\n",
      "Epoch   2 | Train Loss: 1.305 | Train Acc:  42.70%\n",
      "Epoch   2 | Val Loss: 1.286 | Val Acc:  43.99%\n",
      "learning rate: [0.00099]\n",
      "Epoch   3 | Train Loss: 1.275 | Train Acc:  44.42%\n",
      "Epoch   3 | Val Loss: 1.255 | Val Acc:  45.86%\n",
      "learning rate: [0.0009866666666666667]\n",
      "Epoch   4 | Train Loss: 1.248 | Train Acc:  46.07%\n",
      "Epoch   4 | Val Loss: 1.255 | Val Acc:  45.40%\n",
      "learning rate: [0.0009833333333333332]\n",
      "Epoch   5 | Train Loss: 1.225 | Train Acc:  47.29%\n",
      "Epoch   5 | Val Loss: 1.210 | Val Acc:  48.00%\n",
      "learning rate: [0.00098]\n",
      "Epoch   6 | Train Loss: 1.204 | Train Acc:  48.36%\n",
      "Epoch   6 | Val Loss: 1.182 | Val Acc:  49.75%\n",
      "learning rate: [0.0009766666666666667]\n",
      "Epoch   7 | Train Loss: 1.186 | Train Acc:  49.18%\n",
      "Epoch   7 | Val Loss: 1.163 | Val Acc:  50.80%\n",
      "learning rate: [0.0009733333333333334]\n",
      "Epoch   8 | Train Loss: 1.161 | Train Acc:  50.64%\n",
      "Epoch   8 | Val Loss: 1.151 | Val Acc:  51.47%\n",
      "learning rate: [0.0009699999999999999]\n",
      "Epoch   9 | Train Loss: 1.144 | Train Acc:  51.31%\n",
      "Epoch   9 | Val Loss: 1.157 | Val Acc:  51.40%\n",
      "learning rate: [0.0009666666666666667]\n",
      "Epoch  10 | Train Loss: 1.139 | Train Acc:  51.95%\n",
      "Epoch  10 | Val Loss: 1.118 | Val Acc:  52.48%\n",
      "learning rate: [0.0009633333333333333]\n",
      "Epoch  11 | Train Loss: 1.120 | Train Acc:  53.11%\n",
      "Epoch  11 | Val Loss: 1.109 | Val Acc:  53.43%\n",
      "learning rate: [0.0009599999999999999]\n",
      "Epoch  12 | Train Loss: 1.103 | Train Acc:  53.87%\n",
      "Epoch  12 | Val Loss: 1.097 | Val Acc:  54.19%\n",
      "learning rate: [0.0009566666666666666]\n",
      "Epoch  13 | Train Loss: 1.092 | Train Acc:  54.29%\n",
      "Epoch  13 | Val Loss: 1.080 | Val Acc:  54.77%\n",
      "learning rate: [0.0009533333333333334]\n",
      "Epoch  14 | Train Loss: 1.082 | Train Acc:  55.02%\n",
      "Epoch  14 | Val Loss: 1.084 | Val Acc:  55.10%\n",
      "learning rate: [0.00095]\n",
      "Epoch  15 | Train Loss: 1.071 | Train Acc:  55.64%\n",
      "Epoch  15 | Val Loss: 1.075 | Val Acc:  55.75%\n",
      "learning rate: [0.0009466666666666666]\n",
      "Epoch  16 | Train Loss: 1.062 | Train Acc:  56.19%\n",
      "Epoch  16 | Val Loss: 1.049 | Val Acc:  56.74%\n",
      "learning rate: [0.0009433333333333332]\n",
      "Epoch  17 | Train Loss: 1.050 | Train Acc:  56.61%\n",
      "Epoch  17 | Val Loss: 1.066 | Val Acc:  55.06%\n",
      "learning rate: [0.0009399999999999998]\n",
      "Epoch  18 | Train Loss: 1.044 | Train Acc:  56.98%\n",
      "Epoch  18 | Val Loss: 1.090 | Val Acc:  55.22%\n",
      "learning rate: [0.0009366666666666665]\n",
      "Epoch  19 | Train Loss: 1.049 | Train Acc:  57.10%\n",
      "Epoch  19 | Val Loss: 1.024 | Val Acc:  57.79%\n",
      "learning rate: [0.0009333333333333332]\n",
      "Epoch  20 | Train Loss: 1.027 | Train Acc:  58.12%\n",
      "Epoch  20 | Val Loss: 1.005 | Val Acc:  59.56%\n",
      "learning rate: [0.0009299999999999998]\n",
      "Epoch  21 | Train Loss: 1.014 | Train Acc:  58.69%\n",
      "Epoch  21 | Val Loss: 1.003 | Val Acc:  59.30%\n",
      "learning rate: [0.0009266666666666666]\n",
      "Epoch  22 | Train Loss: 1.011 | Train Acc:  58.88%\n",
      "Epoch  22 | Val Loss: 1.019 | Val Acc:  58.89%\n",
      "learning rate: [0.0009233333333333333]\n",
      "Epoch  23 | Train Loss: 1.000 | Train Acc:  59.33%\n",
      "Epoch  23 | Val Loss: 0.998 | Val Acc:  58.77%\n",
      "learning rate: [0.00092]\n",
      "Epoch  24 | Train Loss: 0.994 | Train Acc:  59.87%\n",
      "Epoch  24 | Val Loss: 0.977 | Val Acc:  60.91%\n",
      "learning rate: [0.0009166666666666665]\n",
      "Epoch  25 | Train Loss: 0.987 | Train Acc:  60.09%\n",
      "Epoch  25 | Val Loss: 0.962 | Val Acc:  61.40%\n",
      "learning rate: [0.0009133333333333333]\n",
      "Epoch  26 | Train Loss: 0.980 | Train Acc:  60.46%\n",
      "Epoch  26 | Val Loss: 1.014 | Val Acc:  58.95%\n",
      "learning rate: [0.00091]\n",
      "Epoch  27 | Train Loss: 0.973 | Train Acc:  60.73%\n",
      "Epoch  27 | Val Loss: 0.949 | Val Acc:  62.37%\n",
      "learning rate: [0.0009066666666666666]\n",
      "Epoch  28 | Train Loss: 0.966 | Train Acc:  61.37%\n",
      "Epoch  28 | Val Loss: 0.959 | Val Acc:  62.20%\n",
      "learning rate: [0.0009033333333333334]\n",
      "Epoch  29 | Train Loss: 0.952 | Train Acc:  62.32%\n",
      "Epoch  29 | Val Loss: 0.932 | Val Acc:  63.13%\n",
      "learning rate: [0.0009000000000000001]\n",
      "Epoch  30 | Train Loss: 0.952 | Train Acc:  61.63%\n",
      "Epoch  30 | Val Loss: 0.933 | Val Acc:  63.01%\n",
      "learning rate: [0.0008966666666666668]\n",
      "Epoch  31 | Train Loss: 0.937 | Train Acc:  62.85%\n",
      "Epoch  31 | Val Loss: 0.937 | Val Acc:  61.98%\n",
      "learning rate: [0.0008933333333333333]\n",
      "Epoch  32 | Train Loss: 0.939 | Train Acc:  62.53%\n",
      "Epoch  32 | Val Loss: 0.912 | Val Acc:  63.89%\n",
      "learning rate: [0.0008900000000000001]\n",
      "Epoch  33 | Train Loss: 0.924 | Train Acc:  63.18%\n",
      "Epoch  33 | Val Loss: 0.901 | Val Acc:  64.71%\n",
      "learning rate: [0.0008866666666666667]\n",
      "Epoch  34 | Train Loss: 0.922 | Train Acc:  63.30%\n",
      "Epoch  34 | Val Loss: 0.915 | Val Acc:  64.17%\n",
      "learning rate: [0.0008833333333333332]\n",
      "Epoch  35 | Train Loss: 0.912 | Train Acc:  63.95%\n",
      "Epoch  35 | Val Loss: 0.895 | Val Acc:  64.92%\n",
      "learning rate: [0.0008799999999999998]\n",
      "Epoch  36 | Train Loss: 0.903 | Train Acc:  64.31%\n",
      "Epoch  36 | Val Loss: 0.882 | Val Acc:  65.62%\n",
      "learning rate: [0.0008766666666666664]\n",
      "Epoch  37 | Train Loss: 0.900 | Train Acc:  64.65%\n",
      "Epoch  37 | Val Loss: 0.871 | Val Acc:  66.32%\n",
      "learning rate: [0.0008733333333333331]\n",
      "Epoch  38 | Train Loss: 0.903 | Train Acc:  64.30%\n",
      "Epoch  38 | Val Loss: 0.869 | Val Acc:  66.36%\n",
      "learning rate: [0.0008699999999999998]\n",
      "Epoch  39 | Train Loss: 0.887 | Train Acc:  65.03%\n",
      "Epoch  39 | Val Loss: 0.880 | Val Acc:  64.87%\n",
      "learning rate: [0.0008666666666666665]\n",
      "Epoch  40 | Train Loss: 0.877 | Train Acc:  65.60%\n",
      "Epoch  40 | Val Loss: 0.857 | Val Acc:  66.41%\n",
      "learning rate: [0.0008633333333333331]\n",
      "Epoch  41 | Train Loss: 0.872 | Train Acc:  65.74%\n",
      "Epoch  41 | Val Loss: 0.851 | Val Acc:  66.55%\n",
      "learning rate: [0.0008599999999999998]\n",
      "Epoch  42 | Train Loss: 0.866 | Train Acc:  65.85%\n",
      "Epoch  42 | Val Loss: 0.851 | Val Acc:  66.65%\n",
      "learning rate: [0.0008566666666666664]\n",
      "Epoch  43 | Train Loss: 0.857 | Train Acc:  66.47%\n",
      "Epoch  43 | Val Loss: 0.884 | Val Acc:  64.13%\n",
      "learning rate: [0.000853333333333333]\n",
      "Epoch  44 | Train Loss: 0.864 | Train Acc:  66.02%\n",
      "Epoch  44 | Val Loss: 0.871 | Val Acc:  65.71%\n",
      "learning rate: [0.0008499999999999996]\n",
      "Epoch  45 | Train Loss: 0.851 | Train Acc:  66.66%\n",
      "Epoch  45 | Val Loss: 0.829 | Val Acc:  68.11%\n",
      "learning rate: [0.0008466666666666664]\n",
      "Epoch  46 | Train Loss: 0.831 | Train Acc:  67.65%\n",
      "Epoch  46 | Val Loss: 0.817 | Val Acc:  68.21%\n",
      "learning rate: [0.000843333333333333]\n",
      "Epoch  47 | Train Loss: 0.834 | Train Acc:  67.67%\n",
      "Epoch  47 | Val Loss: 0.817 | Val Acc:  68.19%\n",
      "learning rate: [0.0008399999999999997]\n",
      "Epoch  48 | Train Loss: 0.830 | Train Acc:  67.70%\n",
      "Epoch  48 | Val Loss: 0.803 | Val Acc:  69.10%\n",
      "learning rate: [0.0008366666666666664]\n",
      "Epoch  49 | Train Loss: 0.826 | Train Acc:  67.93%\n",
      "Epoch  49 | Val Loss: 0.801 | Val Acc:  68.89%\n",
      "learning rate: [0.0008333333333333331]\n",
      "Epoch  50 | Train Loss: 0.811 | Train Acc:  68.53%\n",
      "Epoch  50 | Val Loss: 0.791 | Val Acc:  69.49%\n",
      "learning rate: [0.0008299999999999997]\n",
      "Epoch  51 | Train Loss: 0.807 | Train Acc:  68.62%\n",
      "Epoch  51 | Val Loss: 0.797 | Val Acc:  69.10%\n",
      "learning rate: [0.0008266666666666664]\n",
      "Epoch  52 | Train Loss: 0.800 | Train Acc:  69.12%\n",
      "Epoch  52 | Val Loss: 0.773 | Val Acc:  70.70%\n",
      "learning rate: [0.000823333333333333]\n",
      "Epoch  53 | Train Loss: 0.798 | Train Acc:  69.22%\n",
      "Epoch  53 | Val Loss: 0.786 | Val Acc:  70.35%\n",
      "learning rate: [0.0008199999999999998]\n",
      "Epoch  54 | Train Loss: 0.790 | Train Acc:  69.60%\n",
      "Epoch  54 | Val Loss: 0.782 | Val Acc:  70.10%\n",
      "learning rate: [0.0008166666666666664]\n",
      "Epoch  55 | Train Loss: 0.792 | Train Acc:  69.60%\n",
      "Epoch  55 | Val Loss: 0.761 | Val Acc:  71.41%\n",
      "learning rate: [0.0008133333333333331]\n",
      "Epoch  56 | Train Loss: 0.774 | Train Acc:  70.39%\n",
      "Epoch  56 | Val Loss: 0.766 | Val Acc:  70.65%\n",
      "learning rate: [0.0008099999999999998]\n",
      "Epoch  57 | Train Loss: 0.766 | Train Acc:  70.57%\n",
      "Epoch  57 | Val Loss: 0.842 | Val Acc:  66.20%\n",
      "learning rate: [0.0008066666666666665]\n",
      "Epoch  58 | Train Loss: 0.770 | Train Acc:  70.39%\n",
      "Epoch  58 | Val Loss: 0.872 | Val Acc:  64.87%\n",
      "learning rate: [0.0008033333333333332]\n",
      "Epoch  59 | Train Loss: 0.760 | Train Acc:  70.94%\n",
      "Epoch  59 | Val Loss: 0.729 | Val Acc:  72.91%\n",
      "learning rate: [0.0007999999999999999]\n",
      "Epoch  60 | Train Loss: 0.768 | Train Acc:  70.56%\n",
      "Epoch  60 | Val Loss: 0.725 | Val Acc:  73.41%\n",
      "learning rate: [0.0007966666666666666]\n",
      "Epoch  61 | Train Loss: 0.742 | Train Acc:  71.97%\n",
      "Epoch  61 | Val Loss: 0.742 | Val Acc:  71.98%\n",
      "learning rate: [0.0007933333333333333]\n",
      "Epoch  62 | Train Loss: 0.748 | Train Acc:  71.68%\n",
      "Epoch  62 | Val Loss: 0.724 | Val Acc:  72.96%\n",
      "learning rate: [0.00079]\n",
      "Epoch  63 | Train Loss: 0.740 | Train Acc:  71.92%\n",
      "Epoch  63 | Val Loss: 0.725 | Val Acc:  72.84%\n",
      "learning rate: [0.0007866666666666666]\n",
      "Epoch  64 | Train Loss: 0.729 | Train Acc:  72.64%\n",
      "Epoch  64 | Val Loss: 0.713 | Val Acc:  73.71%\n",
      "learning rate: [0.0007833333333333333]\n",
      "Epoch  65 | Train Loss: 0.722 | Train Acc:  72.80%\n",
      "Epoch  65 | Val Loss: 0.704 | Val Acc:  73.76%\n",
      "learning rate: [0.0007799999999999999]\n",
      "Epoch  66 | Train Loss: 0.712 | Train Acc:  73.55%\n",
      "Epoch  66 | Val Loss: 0.696 | Val Acc:  74.50%\n",
      "learning rate: [0.0007766666666666665]\n",
      "Epoch  67 | Train Loss: 0.715 | Train Acc:  73.29%\n",
      "Epoch  67 | Val Loss: 0.691 | Val Acc:  74.55%\n",
      "learning rate: [0.0007733333333333332]\n",
      "Epoch  68 | Train Loss: 0.706 | Train Acc:  73.77%\n",
      "Epoch  68 | Val Loss: 0.678 | Val Acc:  75.36%\n",
      "learning rate: [0.00077]\n",
      "Epoch  69 | Train Loss: 0.712 | Train Acc:  73.42%\n",
      "Epoch  69 | Val Loss: 0.704 | Val Acc:  73.59%\n",
      "learning rate: [0.0007666666666666666]\n",
      "Epoch  70 | Train Loss: 0.698 | Train Acc:  74.23%\n",
      "Epoch  70 | Val Loss: 0.683 | Val Acc:  74.88%\n",
      "learning rate: [0.0007633333333333333]\n",
      "Epoch  71 | Train Loss: 0.699 | Train Acc:  74.08%\n",
      "Epoch  71 | Val Loss: 0.663 | Val Acc:  76.23%\n",
      "learning rate: [0.0007599999999999999]\n",
      "Epoch  72 | Train Loss: 0.686 | Train Acc:  74.83%\n",
      "Epoch  72 | Val Loss: 0.661 | Val Acc:  76.35%\n",
      "learning rate: [0.0007566666666666666]\n",
      "Epoch  73 | Train Loss: 0.684 | Train Acc:  74.93%\n",
      "Epoch  73 | Val Loss: 0.652 | Val Acc:  76.57%\n",
      "learning rate: [0.0007533333333333333]\n",
      "Epoch  74 | Train Loss: 0.670 | Train Acc:  75.67%\n",
      "Epoch  74 | Val Loss: 0.653 | Val Acc:  76.21%\n",
      "learning rate: [0.0007499999999999999]\n",
      "Epoch  75 | Train Loss: 0.664 | Train Acc:  75.87%\n",
      "Epoch  75 | Val Loss: 0.689 | Val Acc:  73.92%\n",
      "learning rate: [0.0007466666666666664]\n",
      "Epoch  76 | Train Loss: 0.660 | Train Acc:  76.07%\n",
      "Epoch  76 | Val Loss: 0.634 | Val Acc:  77.45%\n",
      "learning rate: [0.0007433333333333333]\n",
      "Epoch  77 | Train Loss: 0.651 | Train Acc:  76.27%\n",
      "Epoch  77 | Val Loss: 0.667 | Val Acc:  75.25%\n",
      "learning rate: [0.0007399999999999999]\n",
      "Epoch  78 | Train Loss: 0.655 | Train Acc:  75.75%\n",
      "Epoch  78 | Val Loss: 0.641 | Val Acc:  76.85%\n",
      "learning rate: [0.0007366666666666666]\n",
      "Epoch  79 | Train Loss: 0.641 | Train Acc:  76.90%\n",
      "Epoch  79 | Val Loss: 0.631 | Val Acc:  77.26%\n",
      "learning rate: [0.0007333333333333333]\n",
      "Epoch  80 | Train Loss: 0.631 | Train Acc:  77.64%\n",
      "Epoch  80 | Val Loss: 0.621 | Val Acc:  78.07%\n",
      "learning rate: [0.00073]\n",
      "Epoch  81 | Train Loss: 0.652 | Train Acc:  76.22%\n",
      "Epoch  81 | Val Loss: 0.609 | Val Acc:  78.37%\n",
      "learning rate: [0.0007266666666666667]\n",
      "Epoch  82 | Train Loss: 0.629 | Train Acc:  77.49%\n",
      "Epoch  82 | Val Loss: 0.608 | Val Acc:  78.77%\n",
      "learning rate: [0.0007233333333333334]\n",
      "Epoch  83 | Train Loss: 0.618 | Train Acc:  77.97%\n",
      "Epoch  83 | Val Loss: 0.614 | Val Acc:  78.11%\n",
      "learning rate: [0.00072]\n",
      "Epoch  84 | Train Loss: 0.618 | Train Acc:  77.99%\n",
      "Epoch  84 | Val Loss: 0.625 | Val Acc:  77.44%\n",
      "learning rate: [0.0007166666666666668]\n",
      "Epoch  85 | Train Loss: 0.609 | Train Acc:  78.38%\n",
      "Epoch  85 | Val Loss: 0.594 | Val Acc:  79.73%\n",
      "learning rate: [0.0007133333333333335]\n",
      "Epoch  86 | Train Loss: 0.607 | Train Acc:  78.71%\n",
      "Epoch  86 | Val Loss: 0.587 | Val Acc:  79.85%\n",
      "learning rate: [0.0007100000000000001]\n",
      "Epoch  87 | Train Loss: 0.604 | Train Acc:  78.66%\n",
      "Epoch  87 | Val Loss: 0.584 | Val Acc:  79.83%\n",
      "learning rate: [0.0007066666666666669]\n",
      "Epoch  88 | Train Loss: 0.599 | Train Acc:  78.91%\n",
      "Epoch  88 | Val Loss: 0.568 | Val Acc:  80.98%\n",
      "learning rate: [0.0007033333333333336]\n",
      "Epoch  89 | Train Loss: 0.592 | Train Acc:  79.54%\n",
      "Epoch  89 | Val Loss: 0.562 | Val Acc:  81.43%\n",
      "learning rate: [0.0007000000000000001]\n",
      "Epoch  90 | Train Loss: 0.586 | Train Acc:  79.33%\n",
      "Epoch  90 | Val Loss: 0.568 | Val Acc:  80.61%\n",
      "learning rate: [0.0006966666666666668]\n",
      "Epoch  91 | Train Loss: 0.585 | Train Acc:  79.71%\n",
      "Epoch  91 | Val Loss: 0.612 | Val Acc:  77.63%\n",
      "learning rate: [0.0006933333333333336]\n",
      "Epoch  92 | Train Loss: 0.584 | Train Acc:  79.90%\n",
      "Epoch  92 | Val Loss: 0.550 | Val Acc:  81.66%\n",
      "learning rate: [0.0006900000000000002]\n",
      "Epoch  93 | Train Loss: 0.567 | Train Acc:  80.61%\n",
      "Epoch  93 | Val Loss: 0.537 | Val Acc:  82.51%\n",
      "learning rate: [0.0006866666666666669]\n",
      "Epoch  94 | Train Loss: 0.568 | Train Acc:  80.47%\n",
      "Epoch  94 | Val Loss: 0.603 | Val Acc:  78.41%\n",
      "learning rate: [0.0006833333333333335]\n",
      "Epoch  95 | Train Loss: 0.570 | Train Acc:  80.10%\n",
      "Epoch  95 | Val Loss: 0.645 | Val Acc:  75.21%\n",
      "learning rate: [0.0006800000000000002]\n",
      "Epoch  96 | Train Loss: 0.559 | Train Acc:  80.89%\n",
      "Epoch  96 | Val Loss: 0.525 | Val Acc:  83.20%\n",
      "learning rate: [0.000676666666666667]\n",
      "Epoch  97 | Train Loss: 0.543 | Train Acc:  81.99%\n",
      "Epoch  97 | Val Loss: 0.522 | Val Acc:  83.46%\n",
      "learning rate: [0.0006733333333333336]\n",
      "Epoch  98 | Train Loss: 0.547 | Train Acc:  81.57%\n",
      "Epoch  98 | Val Loss: 0.518 | Val Acc:  83.68%\n",
      "learning rate: [0.0006700000000000002]\n",
      "Epoch  99 | Train Loss: 0.541 | Train Acc:  81.73%\n",
      "Epoch  99 | Val Loss: 0.558 | Val Acc:  80.69%\n",
      "learning rate: [0.0006666666666666671]\n",
      "Epoch 100 | Train Loss: 0.541 | Train Acc:  81.83%\n",
      "Epoch 100 | Val Loss: 0.527 | Val Acc:  82.64%\n",
      "learning rate: [0.0006633333333333337]\n",
      "Epoch 101 | Train Loss: 0.533 | Train Acc:  82.24%\n",
      "Epoch 101 | Val Loss: 0.517 | Val Acc:  82.87%\n",
      "learning rate: [0.0006600000000000003]\n",
      "Epoch 102 | Train Loss: 0.528 | Train Acc:  82.57%\n",
      "Epoch 102 | Val Loss: 0.512 | Val Acc:  83.04%\n",
      "learning rate: [0.0006566666666666672]\n",
      "Epoch 103 | Train Loss: 0.521 | Train Acc:  82.97%\n",
      "Epoch 103 | Val Loss: 0.507 | Val Acc:  84.00%\n",
      "learning rate: [0.0006533333333333338]\n",
      "Epoch 104 | Train Loss: 0.515 | Train Acc:  83.19%\n",
      "Epoch 104 | Val Loss: 0.494 | Val Acc:  84.44%\n",
      "learning rate: [0.0006500000000000005]\n",
      "Epoch 105 | Train Loss: 0.512 | Train Acc:  83.47%\n",
      "Epoch 105 | Val Loss: 0.515 | Val Acc:  82.70%\n",
      "learning rate: [0.0006466666666666671]\n",
      "Epoch 106 | Train Loss: 0.505 | Train Acc:  83.97%\n",
      "Epoch 106 | Val Loss: 0.515 | Val Acc:  83.17%\n",
      "learning rate: [0.0006433333333333338]\n",
      "Epoch 107 | Train Loss: 0.514 | Train Acc:  82.88%\n",
      "Epoch 107 | Val Loss: 0.475 | Val Acc:  85.54%\n",
      "learning rate: [0.0006400000000000005]\n",
      "Epoch 108 | Train Loss: 0.497 | Train Acc:  84.14%\n",
      "Epoch 108 | Val Loss: 0.475 | Val Acc:  85.65%\n",
      "learning rate: [0.0006366666666666672]\n",
      "Epoch 109 | Train Loss: 0.485 | Train Acc:  84.75%\n",
      "Epoch 109 | Val Loss: 0.480 | Val Acc:  84.75%\n",
      "learning rate: [0.0006333333333333337]\n",
      "Epoch 110 | Train Loss: 0.489 | Train Acc:  84.42%\n",
      "Epoch 110 | Val Loss: 0.504 | Val Acc:  83.15%\n",
      "learning rate: [0.0006300000000000005]\n",
      "Epoch 111 | Train Loss: 0.495 | Train Acc:  83.97%\n",
      "Epoch 111 | Val Loss: 0.461 | Val Acc:  86.23%\n",
      "learning rate: [0.0006266666666666672]\n",
      "Epoch 112 | Train Loss: 0.475 | Train Acc:  85.11%\n",
      "Epoch 112 | Val Loss: 0.461 | Val Acc:  85.95%\n",
      "learning rate: [0.0006233333333333338]\n",
      "Epoch 113 | Train Loss: 0.473 | Train Acc:  85.15%\n",
      "Epoch 113 | Val Loss: 0.447 | Val Acc:  87.07%\n",
      "learning rate: [0.0006200000000000005]\n",
      "Epoch 114 | Train Loss: 0.473 | Train Acc:  85.25%\n",
      "Epoch 114 | Val Loss: 0.475 | Val Acc:  85.15%\n",
      "learning rate: [0.0006166666666666672]\n",
      "Epoch 115 | Train Loss: 0.477 | Train Acc:  84.92%\n",
      "Epoch 115 | Val Loss: 0.500 | Val Acc:  83.03%\n",
      "learning rate: [0.0006133333333333337]\n",
      "Epoch 116 | Train Loss: 0.462 | Train Acc:  86.03%\n",
      "Epoch 116 | Val Loss: 0.431 | Val Acc:  87.89%\n",
      "learning rate: [0.0006100000000000004]\n",
      "Epoch 117 | Train Loss: 0.458 | Train Acc:  86.04%\n",
      "Epoch 117 | Val Loss: 0.434 | Val Acc:  87.62%\n",
      "learning rate: [0.0006066666666666671]\n",
      "Epoch 118 | Train Loss: 0.459 | Train Acc:  86.09%\n",
      "Epoch 118 | Val Loss: 0.446 | Val Acc:  86.71%\n",
      "learning rate: [0.0006033333333333338]\n",
      "Epoch 119 | Train Loss: 0.454 | Train Acc:  86.46%\n",
      "Epoch 119 | Val Loss: 0.555 | Val Acc:  79.58%\n",
      "learning rate: [0.0006000000000000004]\n",
      "Epoch 120 | Train Loss: 0.445 | Train Acc:  86.91%\n",
      "Epoch 120 | Val Loss: 0.418 | Val Acc:  88.50%\n",
      "learning rate: [0.0005966666666666671]\n",
      "Epoch 121 | Train Loss: 0.437 | Train Acc:  87.26%\n",
      "Epoch 121 | Val Loss: 0.415 | Val Acc:  88.76%\n",
      "learning rate: [0.0005933333333333337]\n",
      "Epoch 122 | Train Loss: 0.437 | Train Acc:  87.24%\n",
      "Epoch 122 | Val Loss: 0.427 | Val Acc:  87.81%\n",
      "learning rate: [0.0005900000000000006]\n",
      "Epoch 123 | Train Loss: 0.434 | Train Acc:  87.01%\n",
      "Epoch 123 | Val Loss: 0.439 | Val Acc:  86.94%\n",
      "learning rate: [0.0005866666666666671]\n",
      "Epoch 124 | Train Loss: 0.427 | Train Acc:  87.62%\n",
      "Epoch 124 | Val Loss: 0.403 | Val Acc:  89.16%\n",
      "learning rate: [0.0005833333333333337]\n",
      "Epoch 125 | Train Loss: 0.424 | Train Acc:  87.90%\n",
      "Epoch 125 | Val Loss: 0.416 | Val Acc:  88.32%\n",
      "learning rate: [0.0005800000000000005]\n",
      "Epoch 126 | Train Loss: 0.418 | Train Acc:  88.19%\n",
      "Epoch 126 | Val Loss: 0.401 | Val Acc:  89.29%\n",
      "learning rate: [0.0005766666666666672]\n",
      "Epoch 127 | Train Loss: 0.413 | Train Acc:  88.47%\n",
      "Epoch 127 | Val Loss: 0.414 | Val Acc:  87.80%\n",
      "learning rate: [0.0005733333333333338]\n",
      "Epoch 128 | Train Loss: 0.415 | Train Acc:  88.51%\n",
      "Epoch 128 | Val Loss: 0.388 | Val Acc:  90.06%\n",
      "learning rate: [0.0005700000000000006]\n",
      "Epoch 129 | Train Loss: 0.408 | Train Acc:  88.59%\n",
      "Epoch 129 | Val Loss: 0.403 | Val Acc:  88.75%\n",
      "learning rate: [0.0005666666666666672]\n",
      "Epoch 130 | Train Loss: 0.402 | Train Acc:  89.13%\n",
      "Epoch 130 | Val Loss: 0.381 | Val Acc:  90.40%\n",
      "learning rate: [0.0005633333333333339]\n",
      "Epoch 131 | Train Loss: 0.395 | Train Acc:  89.55%\n",
      "Epoch 131 | Val Loss: 0.378 | Val Acc:  90.60%\n",
      "learning rate: [0.0005600000000000006]\n",
      "Epoch 132 | Train Loss: 0.398 | Train Acc:  89.21%\n",
      "Epoch 132 | Val Loss: 0.406 | Val Acc:  88.30%\n",
      "learning rate: [0.0005566666666666672]\n",
      "Epoch 133 | Train Loss: 0.388 | Train Acc:  89.82%\n",
      "Epoch 133 | Val Loss: 0.371 | Val Acc:  90.85%\n",
      "learning rate: [0.000553333333333334]\n",
      "Epoch 134 | Train Loss: 0.393 | Train Acc:  89.44%\n",
      "Epoch 134 | Val Loss: 0.475 | Val Acc:  83.46%\n",
      "learning rate: [0.0005500000000000007]\n",
      "Epoch 135 | Train Loss: 0.402 | Train Acc:  88.70%\n",
      "Epoch 135 | Val Loss: 0.369 | Val Acc:  90.92%\n",
      "learning rate: [0.0005466666666666673]\n",
      "Epoch 136 | Train Loss: 0.376 | Train Acc:  90.63%\n",
      "Epoch 136 | Val Loss: 0.355 | Val Acc:  92.12%\n",
      "learning rate: [0.000543333333333334]\n",
      "Epoch 137 | Train Loss: 0.372 | Train Acc:  90.78%\n",
      "Epoch 137 | Val Loss: 0.352 | Val Acc:  92.21%\n",
      "learning rate: [0.0005400000000000008]\n",
      "Epoch 138 | Train Loss: 0.372 | Train Acc:  90.51%\n",
      "Epoch 138 | Val Loss: 0.347 | Val Acc:  92.21%\n",
      "learning rate: [0.0005366666666666674]\n",
      "Epoch 139 | Train Loss: 0.368 | Train Acc:  90.90%\n",
      "Epoch 139 | Val Loss: 0.378 | Val Acc:  89.96%\n",
      "learning rate: [0.0005333333333333341]\n",
      "Epoch 140 | Train Loss: 0.370 | Train Acc:  90.68%\n",
      "Epoch 140 | Val Loss: 0.377 | Val Acc:  89.92%\n",
      "learning rate: [0.0005300000000000007]\n",
      "Epoch 141 | Train Loss: 0.370 | Train Acc:  90.55%\n",
      "Epoch 141 | Val Loss: 0.349 | Val Acc:  92.06%\n",
      "learning rate: [0.0005266666666666674]\n",
      "Epoch 142 | Train Loss: 0.358 | Train Acc:  91.48%\n",
      "Epoch 142 | Val Loss: 0.346 | Val Acc:  92.20%\n",
      "learning rate: [0.0005233333333333341]\n",
      "Epoch 143 | Train Loss: 0.360 | Train Acc:  91.17%\n",
      "Epoch 143 | Val Loss: 0.329 | Val Acc:  93.45%\n",
      "learning rate: [0.0005200000000000008]\n",
      "Epoch 144 | Train Loss: 0.352 | Train Acc:  91.77%\n",
      "Epoch 144 | Val Loss: 0.366 | Val Acc:  90.26%\n",
      "learning rate: [0.0005166666666666673]\n",
      "Epoch 145 | Train Loss: 0.361 | Train Acc:  90.83%\n",
      "Epoch 145 | Val Loss: 0.329 | Val Acc:  93.51%\n",
      "learning rate: [0.0005133333333333341]\n",
      "Epoch 146 | Train Loss: 0.345 | Train Acc:  91.88%\n",
      "Epoch 146 | Val Loss: 0.328 | Val Acc:  93.35%\n",
      "learning rate: [0.0005100000000000008]\n",
      "Epoch 147 | Train Loss: 0.339 | Train Acc:  92.59%\n",
      "Epoch 147 | Val Loss: 0.322 | Val Acc:  93.60%\n",
      "learning rate: [0.0005066666666666673]\n",
      "Epoch 148 | Train Loss: 0.343 | Train Acc:  92.04%\n",
      "Epoch 148 | Val Loss: 0.318 | Val Acc:  94.07%\n",
      "learning rate: [0.0005033333333333341]\n",
      "Epoch 149 | Train Loss: 0.330 | Train Acc:  93.28%\n",
      "Epoch 149 | Val Loss: 0.316 | Val Acc:  93.91%\n",
      "learning rate: [0.0005000000000000008]\n",
      "Epoch 150 | Train Loss: 0.330 | Train Acc:  92.94%\n",
      "Epoch 150 | Val Loss: 0.311 | Val Acc:  94.33%\n",
      "learning rate: [0.0004966666666666675]\n",
      "Epoch 151 | Train Loss: 0.327 | Train Acc:  93.25%\n",
      "Epoch 151 | Val Loss: 0.310 | Val Acc:  94.38%\n",
      "learning rate: [0.0004933333333333341]\n",
      "Epoch 152 | Train Loss: 0.325 | Train Acc:  93.11%\n",
      "Epoch 152 | Val Loss: 0.308 | Val Acc:  94.08%\n",
      "learning rate: [0.0004900000000000009]\n",
      "Epoch 153 | Train Loss: 0.319 | Train Acc:  93.63%\n",
      "Epoch 153 | Val Loss: 0.304 | Val Acc:  94.31%\n",
      "learning rate: [0.0004866666666666676]\n",
      "Epoch 154 | Train Loss: 0.326 | Train Acc:  93.14%\n",
      "Epoch 154 | Val Loss: 0.299 | Val Acc:  94.97%\n",
      "learning rate: [0.00048333333333333415]\n",
      "Epoch 155 | Train Loss: 0.317 | Train Acc:  93.60%\n",
      "Epoch 155 | Val Loss: 0.320 | Val Acc:  93.18%\n",
      "learning rate: [0.0004800000000000009]\n",
      "Epoch 156 | Train Loss: 0.312 | Train Acc:  93.99%\n",
      "Epoch 156 | Val Loss: 0.314 | Val Acc:  93.38%\n",
      "learning rate: [0.00047666666666666756]\n",
      "Epoch 157 | Train Loss: 0.314 | Train Acc:  93.66%\n",
      "Epoch 157 | Val Loss: 0.290 | Val Acc:  95.56%\n",
      "learning rate: [0.0004733333333333343]\n",
      "Epoch 158 | Train Loss: 0.315 | Train Acc:  93.37%\n",
      "Epoch 158 | Val Loss: 0.296 | Val Acc:  94.86%\n",
      "learning rate: [0.00047000000000000085]\n",
      "Epoch 159 | Train Loss: 0.317 | Train Acc:  93.35%\n",
      "Epoch 159 | Val Loss: 0.341 | Val Acc:  91.28%\n",
      "learning rate: [0.0004666666666666676]\n",
      "Epoch 160 | Train Loss: 0.301 | Train Acc:  94.51%\n",
      "Epoch 160 | Val Loss: 0.291 | Val Acc:  95.18%\n",
      "learning rate: [0.00046333333333333426]\n",
      "Epoch 161 | Train Loss: 0.299 | Train Acc:  94.62%\n",
      "Epoch 161 | Val Loss: 0.279 | Val Acc:  96.00%\n",
      "learning rate: [0.0004600000000000008]\n",
      "Epoch 162 | Train Loss: 0.296 | Train Acc:  94.86%\n",
      "Epoch 162 | Val Loss: 0.295 | Val Acc:  94.93%\n",
      "learning rate: [0.0004566666666666675]\n",
      "Epoch 163 | Train Loss: 0.292 | Train Acc:  95.05%\n",
      "Epoch 163 | Val Loss: 0.276 | Val Acc:  96.13%\n",
      "learning rate: [0.00045333333333333423]\n",
      "Epoch 164 | Train Loss: 0.291 | Train Acc:  95.10%\n",
      "Epoch 164 | Val Loss: 0.285 | Val Acc:  95.06%\n",
      "learning rate: [0.0004500000000000008]\n",
      "Epoch 165 | Train Loss: 0.291 | Train Acc:  94.96%\n",
      "Epoch 165 | Val Loss: 0.298 | Val Acc:  94.50%\n",
      "learning rate: [0.00044666666666666753]\n",
      "Epoch 166 | Train Loss: 0.288 | Train Acc:  95.24%\n",
      "Epoch 166 | Val Loss: 0.358 | Val Acc:  89.57%\n",
      "learning rate: [0.0004433333333333342]\n",
      "Epoch 167 | Train Loss: 0.291 | Train Acc:  94.98%\n",
      "Epoch 167 | Val Loss: 0.264 | Val Acc:  96.77%\n",
      "learning rate: [0.0004400000000000008]\n",
      "Epoch 168 | Train Loss: 0.285 | Train Acc:  95.35%\n",
      "Epoch 168 | Val Loss: 0.266 | Val Acc:  96.54%\n",
      "learning rate: [0.0004366666666666675]\n",
      "Epoch 169 | Train Loss: 0.284 | Train Acc:  95.25%\n",
      "Epoch 169 | Val Loss: 0.291 | Val Acc:  94.55%\n",
      "learning rate: [0.00043333333333333424]\n",
      "Epoch 170 | Train Loss: 0.276 | Train Acc:  95.82%\n",
      "Epoch 170 | Val Loss: 0.258 | Val Acc:  97.15%\n",
      "learning rate: [0.0004300000000000009]\n",
      "Epoch 171 | Train Loss: 0.274 | Train Acc:  95.99%\n",
      "Epoch 171 | Val Loss: 0.281 | Val Acc:  95.14%\n",
      "learning rate: [0.00042666666666666753]\n",
      "Epoch 172 | Train Loss: 0.279 | Train Acc:  95.50%\n",
      "Epoch 172 | Val Loss: 0.271 | Val Acc:  95.97%\n",
      "learning rate: [0.00042333333333333426]\n",
      "Epoch 173 | Train Loss: 0.274 | Train Acc:  95.92%\n",
      "Epoch 173 | Val Loss: 0.265 | Val Acc:  96.46%\n",
      "learning rate: [0.000420000000000001]\n",
      "Epoch 174 | Train Loss: 0.269 | Train Acc:  96.20%\n",
      "Epoch 174 | Val Loss: 0.255 | Val Acc:  97.04%\n",
      "learning rate: [0.00041666666666666756]\n",
      "Epoch 175 | Train Loss: 0.269 | Train Acc:  96.23%\n",
      "Epoch 175 | Val Loss: 0.252 | Val Acc:  97.29%\n",
      "learning rate: [0.00041333333333333424]\n",
      "Epoch 176 | Train Loss: 0.263 | Train Acc:  96.56%\n",
      "Epoch 176 | Val Loss: 0.247 | Val Acc:  97.62%\n",
      "learning rate: [0.00041000000000000097]\n",
      "Epoch 177 | Train Loss: 0.268 | Train Acc:  96.07%\n",
      "Epoch 177 | Val Loss: 0.254 | Val Acc:  97.02%\n",
      "learning rate: [0.0004066666666666676]\n",
      "Epoch 178 | Train Loss: 0.256 | Train Acc:  96.97%\n",
      "Epoch 178 | Val Loss: 0.272 | Val Acc:  95.74%\n",
      "learning rate: [0.00040333333333333426]\n",
      "Epoch 179 | Train Loss: 0.258 | Train Acc:  96.77%\n",
      "Epoch 179 | Val Loss: 0.279 | Val Acc:  94.95%\n",
      "learning rate: [0.000400000000000001]\n",
      "Epoch 180 | Train Loss: 0.256 | Train Acc:  96.92%\n",
      "Epoch 180 | Val Loss: 0.257 | Val Acc:  96.79%\n",
      "learning rate: [0.00039666666666666756]\n",
      "Epoch 181 | Train Loss: 0.255 | Train Acc:  96.94%\n",
      "Epoch 181 | Val Loss: 0.241 | Val Acc:  97.69%\n",
      "learning rate: [0.00039333333333333424]\n",
      "Epoch 182 | Train Loss: 0.253 | Train Acc:  96.86%\n",
      "Epoch 182 | Val Loss: 0.241 | Val Acc:  97.70%\n",
      "learning rate: [0.00039000000000000097]\n",
      "Epoch 183 | Train Loss: 0.251 | Train Acc:  97.22%\n",
      "Epoch 183 | Val Loss: 0.272 | Val Acc:  95.38%\n",
      "learning rate: [0.0003866666666666677]\n",
      "Epoch 184 | Train Loss: 0.251 | Train Acc:  97.16%\n",
      "Epoch 184 | Val Loss: 0.237 | Val Acc:  98.04%\n",
      "learning rate: [0.00038333333333333427]\n",
      "Epoch 185 | Train Loss: 0.243 | Train Acc:  97.67%\n",
      "Epoch 185 | Val Loss: 0.248 | Val Acc:  97.18%\n",
      "learning rate: [0.00038000000000000094]\n",
      "Epoch 186 | Train Loss: 0.243 | Train Acc:  97.67%\n",
      "Epoch 186 | Val Loss: 0.241 | Val Acc:  97.75%\n",
      "learning rate: [0.0003766666666666676]\n",
      "Epoch 187 | Train Loss: 0.240 | Train Acc:  97.74%\n",
      "Epoch 187 | Val Loss: 0.233 | Val Acc:  98.13%\n",
      "learning rate: [0.0003733333333333342]\n",
      "Epoch 188 | Train Loss: 0.238 | Train Acc:  97.78%\n",
      "Epoch 188 | Val Loss: 0.228 | Val Acc:  98.47%\n",
      "learning rate: [0.0003700000000000009]\n",
      "Epoch 189 | Train Loss: 0.239 | Train Acc:  97.81%\n",
      "Epoch 189 | Val Loss: 0.236 | Val Acc:  97.75%\n",
      "learning rate: [0.0003666666666666676]\n",
      "Epoch 190 | Train Loss: 0.238 | Train Acc:  97.92%\n",
      "Epoch 190 | Val Loss: 0.231 | Val Acc:  98.26%\n",
      "learning rate: [0.0003633333333333342]\n",
      "Epoch 191 | Train Loss: 0.236 | Train Acc:  97.99%\n",
      "Epoch 191 | Val Loss: 0.223 | Val Acc:  98.64%\n",
      "learning rate: [0.0003600000000000009]\n",
      "Epoch 192 | Train Loss: 0.233 | Train Acc:  98.15%\n",
      "Epoch 192 | Val Loss: 0.234 | Val Acc:  98.15%\n",
      "learning rate: [0.00035666666666666757]\n",
      "Epoch 193 | Train Loss: 0.235 | Train Acc:  97.98%\n",
      "Epoch 193 | Val Loss: 0.220 | Val Acc:  98.76%\n",
      "learning rate: [0.00035333333333333424]\n",
      "Epoch 194 | Train Loss: 0.230 | Train Acc:  98.24%\n",
      "Epoch 194 | Val Loss: 0.219 | Val Acc:  98.80%\n",
      "learning rate: [0.0003500000000000008]\n",
      "Epoch 195 | Train Loss: 0.231 | Train Acc:  98.24%\n",
      "Epoch 195 | Val Loss: 0.226 | Val Acc:  98.39%\n",
      "learning rate: [0.00034666666666666754]\n",
      "Epoch 196 | Train Loss: 0.233 | Train Acc:  97.97%\n",
      "Epoch 196 | Val Loss: 0.223 | Val Acc:  98.62%\n",
      "learning rate: [0.00034333333333333427]\n",
      "Epoch 197 | Train Loss: 0.230 | Train Acc:  98.16%\n",
      "Epoch 197 | Val Loss: 0.222 | Val Acc:  98.46%\n",
      "learning rate: [0.00034000000000000084]\n",
      "Epoch 198 | Train Loss: 0.225 | Train Acc:  98.50%\n",
      "Epoch 198 | Val Loss: 0.215 | Val Acc:  99.03%\n",
      "learning rate: [0.00033666666666666757]\n",
      "Epoch 199 | Train Loss: 0.223 | Train Acc:  98.62%\n",
      "Epoch 199 | Val Loss: 0.214 | Val Acc:  98.90%\n",
      "learning rate: [0.00033333333333333424]\n",
      "Epoch 200 | Train Loss: 0.226 | Train Acc:  98.29%\n",
      "Epoch 200 | Val Loss: 0.218 | Val Acc:  98.67%\n",
      "learning rate: [0.0003300000000000008]\n",
      "Epoch 201 | Train Loss: 0.222 | Train Acc:  98.63%\n",
      "Epoch 201 | Val Loss: 0.220 | Val Acc:  98.52%\n",
      "learning rate: [0.00032666666666666754]\n",
      "Epoch 202 | Train Loss: 0.220 | Train Acc:  98.75%\n",
      "Epoch 202 | Val Loss: 0.214 | Val Acc:  99.02%\n",
      "learning rate: [0.0003233333333333342]\n",
      "Epoch 203 | Train Loss: 0.219 | Train Acc:  98.71%\n",
      "Epoch 203 | Val Loss: 0.218 | Val Acc:  98.78%\n",
      "learning rate: [0.00032000000000000084]\n",
      "Epoch 204 | Train Loss: 0.217 | Train Acc:  98.85%\n",
      "Epoch 204 | Val Loss: 0.208 | Val Acc:  99.20%\n",
      "learning rate: [0.00031666666666666757]\n",
      "Epoch 205 | Train Loss: 0.219 | Train Acc:  98.65%\n",
      "Epoch 205 | Val Loss: 0.208 | Val Acc:  99.26%\n",
      "learning rate: [0.00031333333333333425]\n",
      "Epoch 206 | Train Loss: 0.218 | Train Acc:  98.68%\n",
      "Epoch 206 | Val Loss: 0.209 | Val Acc:  99.12%\n",
      "learning rate: [0.000310000000000001]\n",
      "Epoch 207 | Train Loss: 0.214 | Train Acc:  98.89%\n",
      "Epoch 207 | Val Loss: 0.210 | Val Acc:  99.04%\n",
      "learning rate: [0.00030666666666666754]\n",
      "Epoch 208 | Train Loss: 0.210 | Train Acc:  99.14%\n",
      "Epoch 208 | Val Loss: 0.204 | Val Acc:  99.33%\n",
      "learning rate: [0.0003033333333333342]\n",
      "Epoch 209 | Train Loss: 0.209 | Train Acc:  99.18%\n",
      "Epoch 209 | Val Loss: 0.203 | Val Acc:  99.30%\n",
      "learning rate: [0.0003000000000000009]\n",
      "Epoch 210 | Train Loss: 0.212 | Train Acc:  98.98%\n",
      "Epoch 210 | Val Loss: 0.211 | Val Acc:  98.84%\n",
      "learning rate: [0.00029666666666666746]\n",
      "Epoch 211 | Train Loss: 0.212 | Train Acc:  99.02%\n",
      "Epoch 211 | Val Loss: 0.209 | Val Acc:  99.06%\n",
      "learning rate: [0.00029333333333333414]\n",
      "Epoch 212 | Train Loss: 0.212 | Train Acc:  98.96%\n",
      "Epoch 212 | Val Loss: 0.214 | Val Acc:  98.84%\n",
      "learning rate: [0.0002900000000000008]\n",
      "Epoch 213 | Train Loss: 0.208 | Train Acc:  99.05%\n",
      "Epoch 213 | Val Loss: 0.202 | Val Acc:  99.33%\n",
      "learning rate: [0.0002866666666666674]\n",
      "Epoch 214 | Train Loss: 0.210 | Train Acc:  99.01%\n",
      "Epoch 214 | Val Loss: 0.201 | Val Acc:  99.39%\n",
      "learning rate: [0.00028333333333333406]\n",
      "Epoch 215 | Train Loss: 0.206 | Train Acc:  99.25%\n",
      "Epoch 215 | Val Loss: 0.208 | Val Acc:  99.00%\n",
      "learning rate: [0.00028000000000000073]\n",
      "Epoch 216 | Train Loss: 0.206 | Train Acc:  99.22%\n",
      "Epoch 216 | Val Loss: 0.208 | Val Acc:  99.07%\n",
      "learning rate: [0.0002766666666666673]\n",
      "Epoch 217 | Train Loss: 0.204 | Train Acc:  99.30%\n",
      "Epoch 217 | Val Loss: 0.204 | Val Acc:  99.28%\n",
      "learning rate: [0.000273333333333334]\n",
      "Epoch 218 | Train Loss: 0.201 | Train Acc:  99.42%\n",
      "Epoch 218 | Val Loss: 0.206 | Val Acc:  99.30%\n",
      "learning rate: [0.00027000000000000065]\n",
      "Epoch 219 | Train Loss: 0.206 | Train Acc:  99.27%\n",
      "Epoch 219 | Val Loss: 0.196 | Val Acc:  99.52%\n",
      "learning rate: [0.0002666666666666674]\n",
      "Epoch 220 | Train Loss: 0.206 | Train Acc:  99.22%\n",
      "Epoch 220 | Val Loss: 0.196 | Val Acc:  99.57%\n",
      "learning rate: [0.00026333333333333395]\n",
      "Epoch 221 | Train Loss: 0.200 | Train Acc:  99.43%\n",
      "Epoch 221 | Val Loss: 0.196 | Val Acc:  99.56%\n",
      "learning rate: [0.00026000000000000063]\n",
      "Epoch 222 | Train Loss: 0.200 | Train Acc:  99.41%\n",
      "Epoch 222 | Val Loss: 0.200 | Val Acc:  99.45%\n",
      "learning rate: [0.0002566666666666673]\n",
      "Epoch 223 | Train Loss: 0.198 | Train Acc:  99.49%\n",
      "Epoch 223 | Val Loss: 0.196 | Val Acc:  99.61%\n",
      "learning rate: [0.00025333333333333387]\n",
      "Epoch 224 | Train Loss: 0.199 | Train Acc:  99.42%\n",
      "Epoch 224 | Val Loss: 0.206 | Val Acc:  99.14%\n",
      "learning rate: [0.0002500000000000006]\n",
      "Epoch 225 | Train Loss: 0.196 | Train Acc:  99.59%\n",
      "Epoch 225 | Val Loss: 0.198 | Val Acc:  99.55%\n",
      "learning rate: [0.0002466666666666673]\n",
      "Epoch 226 | Train Loss: 0.197 | Train Acc:  99.55%\n",
      "Epoch 226 | Val Loss: 0.203 | Val Acc:  99.28%\n",
      "learning rate: [0.00024333333333333387]\n",
      "Epoch 227 | Train Loss: 0.199 | Train Acc:  99.45%\n",
      "Epoch 227 | Val Loss: 0.191 | Val Acc:  99.61%\n",
      "learning rate: [0.00024000000000000058]\n",
      "Epoch 228 | Train Loss: 0.194 | Train Acc:  99.58%\n",
      "Epoch 228 | Val Loss: 0.192 | Val Acc:  99.66%\n",
      "learning rate: [0.00023666666666666728]\n",
      "Epoch 229 | Train Loss: 0.195 | Train Acc:  99.60%\n",
      "Epoch 229 | Val Loss: 0.188 | Val Acc:  99.73%\n",
      "learning rate: [0.00023333333333333387]\n",
      "Epoch 230 | Train Loss: 0.194 | Train Acc:  99.59%\n",
      "Epoch 230 | Val Loss: 0.193 | Val Acc:  99.64%\n",
      "learning rate: [0.00023000000000000058]\n",
      "Epoch 231 | Train Loss: 0.194 | Train Acc:  99.62%\n",
      "Epoch 231 | Val Loss: 0.200 | Val Acc:  99.31%\n",
      "learning rate: [0.00022666666666666728]\n",
      "Epoch 232 | Train Loss: 0.194 | Train Acc:  99.61%\n",
      "Epoch 232 | Val Loss: 0.188 | Val Acc:  99.69%\n",
      "learning rate: [0.00022333333333333398]\n",
      "Epoch 233 | Train Loss: 0.192 | Train Acc:  99.65%\n",
      "Epoch 233 | Val Loss: 0.188 | Val Acc:  99.72%\n",
      "learning rate: [0.00022000000000000055]\n",
      "Epoch 234 | Train Loss: 0.191 | Train Acc:  99.67%\n",
      "Epoch 234 | Val Loss: 0.194 | Val Acc:  99.60%\n",
      "learning rate: [0.00021666666666666723]\n",
      "Epoch 235 | Train Loss: 0.191 | Train Acc:  99.66%\n",
      "Epoch 235 | Val Loss: 0.188 | Val Acc:  99.69%\n",
      "learning rate: [0.00021333333333333393]\n",
      "Epoch 236 | Train Loss: 0.189 | Train Acc:  99.70%\n",
      "Epoch 236 | Val Loss: 0.186 | Val Acc:  99.77%\n",
      "learning rate: [0.00021000000000000052]\n",
      "Epoch 237 | Train Loss: 0.192 | Train Acc:  99.64%\n",
      "Epoch 237 | Val Loss: 0.188 | Val Acc:  99.74%\n",
      "learning rate: [0.00020666666666666723]\n",
      "Epoch 238 | Train Loss: 0.190 | Train Acc:  99.68%\n",
      "Epoch 238 | Val Loss: 0.187 | Val Acc:  99.76%\n",
      "learning rate: [0.0002033333333333339]\n",
      "Epoch 239 | Train Loss: 0.188 | Train Acc:  99.69%\n",
      "Epoch 239 | Val Loss: 0.192 | Val Acc:  99.71%\n",
      "learning rate: [0.0002000000000000005]\n",
      "Epoch 240 | Train Loss: 0.188 | Train Acc:  99.75%\n",
      "Epoch 240 | Val Loss: 0.186 | Val Acc:  99.77%\n",
      "learning rate: [0.0001966666666666672]\n",
      "Epoch 241 | Train Loss: 0.188 | Train Acc:  99.72%\n",
      "Epoch 241 | Val Loss: 0.194 | Val Acc:  99.55%\n",
      "learning rate: [0.00019333333333333388]\n",
      "Epoch 242 | Train Loss: 0.190 | Train Acc:  99.65%\n",
      "Epoch 242 | Val Loss: 0.187 | Val Acc:  99.72%\n",
      "learning rate: [0.00019000000000000047]\n",
      "Epoch 243 | Train Loss: 0.186 | Train Acc:  99.77%\n",
      "Epoch 243 | Val Loss: 0.185 | Val Acc:  99.76%\n",
      "learning rate: [0.00018666666666666717]\n",
      "Epoch 244 | Train Loss: 0.185 | Train Acc:  99.79%\n",
      "Epoch 244 | Val Loss: 0.181 | Val Acc:  99.82%\n",
      "learning rate: [0.00018333333333333388]\n",
      "Epoch 245 | Train Loss: 0.186 | Train Acc:  99.77%\n",
      "Epoch 245 | Val Loss: 0.186 | Val Acc:  99.81%\n",
      "learning rate: [0.00018000000000000058]\n",
      "Epoch 246 | Train Loss: 0.188 | Train Acc:  99.71%\n",
      "Epoch 246 | Val Loss: 0.183 | Val Acc:  99.86%\n",
      "learning rate: [0.00017666666666666718]\n",
      "Epoch 247 | Train Loss: 0.186 | Train Acc:  99.79%\n",
      "Epoch 247 | Val Loss: 0.185 | Val Acc:  99.84%\n",
      "learning rate: [0.00017333333333333388]\n",
      "Epoch 248 | Train Loss: 0.185 | Train Acc:  99.83%\n",
      "Epoch 248 | Val Loss: 0.181 | Val Acc:  99.85%\n",
      "learning rate: [0.00017000000000000055]\n",
      "Epoch 249 | Train Loss: 0.184 | Train Acc:  99.81%\n",
      "Epoch 249 | Val Loss: 0.181 | Val Acc:  99.87%\n",
      "learning rate: [0.00016666666666666712]\n",
      "Epoch 250 | Train Loss: 0.184 | Train Acc:  99.79%\n",
      "Epoch 250 | Val Loss: 0.183 | Val Acc:  99.83%\n",
      "learning rate: [0.00016333333333333382]\n",
      "Epoch 251 | Train Loss: 0.186 | Train Acc:  99.76%\n",
      "Epoch 251 | Val Loss: 0.186 | Val Acc:  99.82%\n",
      "learning rate: [0.0001600000000000005]\n",
      "Epoch 252 | Train Loss: 0.183 | Train Acc:  99.81%\n",
      "Epoch 252 | Val Loss: 0.181 | Val Acc:  99.86%\n",
      "learning rate: [0.00015666666666666707]\n",
      "Epoch 253 | Train Loss: 0.182 | Train Acc:  99.84%\n",
      "Epoch 253 | Val Loss: 0.186 | Val Acc:  99.85%\n",
      "learning rate: [0.00015333333333333374]\n",
      "Epoch 254 | Train Loss: 0.182 | Train Acc:  99.84%\n",
      "Epoch 254 | Val Loss: 0.181 | Val Acc:  99.89%\n",
      "learning rate: [0.00015000000000000045]\n",
      "Epoch 255 | Train Loss: 0.181 | Train Acc:  99.85%\n",
      "Epoch 255 | Val Loss: 0.178 | Val Acc:  99.86%\n",
      "learning rate: [0.00014666666666666704]\n",
      "Epoch 256 | Train Loss: 0.181 | Train Acc:  99.86%\n",
      "Epoch 256 | Val Loss: 0.182 | Val Acc:  99.90%\n",
      "learning rate: [0.00014333333333333375]\n",
      "Epoch 257 | Train Loss: 0.181 | Train Acc:  99.82%\n",
      "Epoch 257 | Val Loss: 0.182 | Val Acc:  99.79%\n",
      "learning rate: [0.00014000000000000042]\n",
      "Epoch 258 | Train Loss: 0.181 | Train Acc:  99.84%\n",
      "Epoch 258 | Val Loss: 0.178 | Val Acc:  99.90%\n",
      "learning rate: [0.0001366666666666671]\n",
      "Epoch 259 | Train Loss: 0.182 | Train Acc:  99.85%\n",
      "Epoch 259 | Val Loss: 0.177 | Val Acc:  99.90%\n",
      "learning rate: [0.00013333333333333366]\n",
      "Epoch 260 | Train Loss: 0.180 | Train Acc:  99.88%\n",
      "Epoch 260 | Val Loss: 0.179 | Val Acc:  99.91%\n",
      "learning rate: [0.00013000000000000034]\n",
      "Epoch 261 | Train Loss: 0.181 | Train Acc:  99.86%\n",
      "Epoch 261 | Val Loss: 0.178 | Val Acc:  99.87%\n",
      "learning rate: [0.00012666666666666704]\n",
      "Epoch 262 | Train Loss: 0.180 | Train Acc:  99.90%\n",
      "Epoch 262 | Val Loss: 0.176 | Val Acc:  99.92%\n",
      "learning rate: [0.0001233333333333336]\n",
      "Epoch 263 | Train Loss: 0.180 | Train Acc:  99.87%\n",
      "Epoch 263 | Val Loss: 0.176 | Val Acc:  99.93%\n",
      "learning rate: [0.0001200000000000003]\n",
      "Epoch 264 | Train Loss: 0.178 | Train Acc:  99.89%\n",
      "Epoch 264 | Val Loss: 0.177 | Val Acc:  99.93%\n",
      "learning rate: [0.000116666666666667]\n",
      "Epoch 265 | Train Loss: 0.179 | Train Acc:  99.90%\n",
      "Epoch 265 | Val Loss: 0.177 | Val Acc:  99.88%\n",
      "learning rate: [0.00011333333333333359]\n",
      "Epoch 266 | Train Loss: 0.179 | Train Acc:  99.89%\n",
      "Epoch 266 | Val Loss: 0.176 | Val Acc:  99.89%\n",
      "learning rate: [0.00011000000000000027]\n",
      "Epoch 267 | Train Loss: 0.177 | Train Acc:  99.90%\n",
      "Epoch 267 | Val Loss: 0.176 | Val Acc:  99.92%\n",
      "learning rate: [0.00010666666666666698]\n",
      "Epoch 268 | Train Loss: 0.178 | Train Acc:  99.89%\n",
      "Epoch 268 | Val Loss: 0.174 | Val Acc:  99.93%\n",
      "learning rate: [0.00010333333333333367]\n",
      "Epoch 269 | Train Loss: 0.177 | Train Acc:  99.91%\n",
      "Epoch 269 | Val Loss: 0.174 | Val Acc:  99.92%\n",
      "learning rate: [0.00010000000000000025]\n",
      "Epoch 270 | Train Loss: 0.177 | Train Acc:  99.91%\n",
      "Epoch 270 | Val Loss: 0.177 | Val Acc:  99.93%\n",
      "learning rate: [9.666666666666694e-05]\n",
      "Epoch 271 | Train Loss: 0.176 | Train Acc:  99.93%\n",
      "Epoch 271 | Val Loss: 0.175 | Val Acc:  99.93%\n",
      "learning rate: [9.333333333333363e-05]\n",
      "Epoch 272 | Train Loss: 0.176 | Train Acc:  99.91%\n",
      "Epoch 272 | Val Loss: 0.177 | Val Acc:  99.90%\n",
      "learning rate: [9.000000000000021e-05]\n",
      "Epoch 273 | Train Loss: 0.176 | Train Acc:  99.92%\n",
      "Epoch 273 | Val Loss: 0.176 | Val Acc:  99.93%\n",
      "learning rate: [8.66666666666669e-05]\n",
      "Epoch 274 | Train Loss: 0.176 | Train Acc:  99.91%\n",
      "Epoch 274 | Val Loss: 0.173 | Val Acc:  99.94%\n",
      "learning rate: [8.333333333333359e-05]\n",
      "Epoch 275 | Train Loss: 0.176 | Train Acc:  99.91%\n",
      "Epoch 275 | Val Loss: 0.173 | Val Acc:  99.95%\n",
      "learning rate: [8.000000000000017e-05]\n",
      "Epoch 276 | Train Loss: 0.175 | Train Acc:  99.93%\n",
      "Epoch 276 | Val Loss: 0.175 | Val Acc:  99.93%\n",
      "learning rate: [7.666666666666686e-05]\n",
      "Epoch 277 | Train Loss: 0.176 | Train Acc:  99.92%\n",
      "Epoch 277 | Val Loss: 0.175 | Val Acc:  99.93%\n",
      "learning rate: [7.333333333333355e-05]\n",
      "Epoch 278 | Train Loss: 0.175 | Train Acc:  99.92%\n",
      "Epoch 278 | Val Loss: 0.174 | Val Acc:  99.93%\n",
      "learning rate: [7.000000000000013e-05]\n",
      "Epoch 279 | Train Loss: 0.175 | Train Acc:  99.95%\n",
      "Epoch 279 | Val Loss: 0.174 | Val Acc:  99.94%\n",
      "learning rate: [6.666666666666682e-05]\n",
      "Epoch 280 | Train Loss: 0.175 | Train Acc:  99.94%\n",
      "Epoch 280 | Val Loss: 0.173 | Val Acc:  99.95%\n",
      "learning rate: [6.333333333333351e-05]\n",
      "Epoch 281 | Train Loss: 0.175 | Train Acc:  99.93%\n",
      "Epoch 281 | Val Loss: 0.175 | Val Acc:  99.93%\n",
      "learning rate: [6.00000000000002e-05]\n",
      "Epoch 282 | Train Loss: 0.174 | Train Acc:  99.93%\n",
      "Epoch 282 | Val Loss: 0.173 | Val Acc:  99.95%\n",
      "learning rate: [5.666666666666678e-05]\n",
      "Epoch 283 | Train Loss: 0.174 | Train Acc:  99.93%\n",
      "Epoch 283 | Val Loss: 0.173 | Val Acc:  99.93%\n",
      "learning rate: [5.333333333333347e-05]\n",
      "Epoch 284 | Train Loss: 0.174 | Train Acc:  99.94%\n",
      "Epoch 284 | Val Loss: 0.173 | Val Acc:  99.94%\n",
      "learning rate: [5.0000000000000165e-05]\n",
      "Epoch 285 | Train Loss: 0.173 | Train Acc:  99.95%\n",
      "Epoch 285 | Val Loss: 0.173 | Val Acc:  99.95%\n",
      "learning rate: [4.6666666666666746e-05]\n",
      "Epoch 286 | Train Loss: 0.173 | Train Acc:  99.95%\n",
      "Epoch 286 | Val Loss: 0.173 | Val Acc:  99.96%\n",
      "learning rate: [4.333333333333344e-05]\n",
      "Epoch 287 | Train Loss: 0.173 | Train Acc:  99.95%\n",
      "Epoch 287 | Val Loss: 0.172 | Val Acc:  99.95%\n",
      "learning rate: [4.000000000000014e-05]\n",
      "Epoch 288 | Train Loss: 0.173 | Train Acc:  99.93%\n",
      "Epoch 288 | Val Loss: 0.173 | Val Acc:  99.94%\n",
      "learning rate: [3.666666666666672e-05]\n",
      "Epoch 289 | Train Loss: 0.173 | Train Acc:  99.95%\n",
      "Epoch 289 | Val Loss: 0.172 | Val Acc:  99.96%\n",
      "learning rate: [3.3333333333333416e-05]\n",
      "Epoch 290 | Train Loss: 0.173 | Train Acc:  99.96%\n",
      "Epoch 290 | Val Loss: 0.172 | Val Acc:  99.93%\n",
      "learning rate: [3.000000000000011e-05]\n",
      "Epoch 291 | Train Loss: 0.173 | Train Acc:  99.95%\n",
      "Epoch 291 | Val Loss: 0.172 | Val Acc:  99.95%\n",
      "learning rate: [2.666666666666669e-05]\n",
      "Epoch 292 | Train Loss: 0.172 | Train Acc:  99.95%\n",
      "Epoch 292 | Val Loss: 0.172 | Val Acc:  99.97%\n",
      "learning rate: [2.333333333333338e-05]\n",
      "Epoch 293 | Train Loss: 0.172 | Train Acc:  99.95%\n",
      "Epoch 293 | Val Loss: 0.171 | Val Acc:  99.96%\n",
      "learning rate: [2.0000000000000073e-05]\n",
      "Epoch 294 | Train Loss: 0.172 | Train Acc:  99.95%\n",
      "Epoch 294 | Val Loss: 0.172 | Val Acc:  99.96%\n",
      "learning rate: [1.6666666666666762e-05]\n",
      "Epoch 295 | Train Loss: 0.172 | Train Acc:  99.97%\n",
      "Epoch 295 | Val Loss: 0.171 | Val Acc:  99.97%\n",
      "learning rate: [1.3333333333333343e-05]\n",
      "Epoch 296 | Train Loss: 0.172 | Train Acc:  99.96%\n",
      "Epoch 296 | Val Loss: 0.172 | Val Acc:  99.94%\n",
      "learning rate: [1.0000000000000036e-05]\n",
      "Epoch 297 | Train Loss: 0.172 | Train Acc:  99.95%\n",
      "Epoch 297 | Val Loss: 0.171 | Val Acc:  99.96%\n",
      "learning rate: [6.6666666666667285e-06]\n",
      "Epoch 298 | Train Loss: 0.171 | Train Acc:  99.96%\n",
      "Epoch 298 | Val Loss: 0.171 | Val Acc:  99.97%\n",
      "learning rate: [3.3333333333333088e-06]\n",
      "Epoch 299 | Train Loss: 0.171 | Train Acc:  99.95%\n",
      "Epoch 299 | Val Loss: 0.171 | Val Acc:  99.96%\n",
      "learning rate: [0.0]\n",
      "Epoch 300 | Train Loss: 0.171 | Train Acc:  99.96%\n",
      "Epoch 300 | Val Loss: 0.171 | Val Acc:  99.96%\n",
      "learning rate: [0.0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved result: acc 1.000, scheduler:\n",
      " functools.partial(<class 'torch.optim.lr_scheduler.PolynomialLR'>, total_iters=300, power=1)\n",
      "epoch: 292\n",
      "<class 'torch.optim.lr_scheduler.PolynomialLR'>\n",
      "Epoch   0 | Train Loss: 1.478 | Train Acc:  33.35%\n",
      "Epoch   0 | Val Loss: 1.384 | Val Acc:  38.78%\n",
      "learning rate: [0.0009933444444444445]\n",
      "Epoch   1 | Train Loss: 1.357 | Train Acc:  39.65%\n",
      "Epoch   1 | Val Loss: 1.322 | Val Acc:  42.11%\n",
      "learning rate: [0.0009867111111111111]\n",
      "Epoch   2 | Train Loss: 1.308 | Train Acc:  42.70%\n",
      "Epoch   2 | Val Loss: 1.288 | Val Acc:  43.89%\n",
      "learning rate: [0.0009801000000000002]\n",
      "Epoch   3 | Train Loss: 1.274 | Train Acc:  44.38%\n",
      "Epoch   3 | Val Loss: 1.251 | Val Acc:  45.90%\n",
      "learning rate: [0.0009735111111111113]\n",
      "Epoch   4 | Train Loss: 1.250 | Train Acc:  45.90%\n",
      "Epoch   4 | Val Loss: 1.233 | Val Acc:  47.17%\n",
      "learning rate: [0.0009669444444444444]\n",
      "Epoch   5 | Train Loss: 1.226 | Train Acc:  47.36%\n",
      "Epoch   5 | Val Loss: 1.206 | Val Acc:  48.38%\n",
      "learning rate: [0.0009604]\n",
      "Epoch   6 | Train Loss: 1.205 | Train Acc:  48.13%\n",
      "Epoch   6 | Val Loss: 1.206 | Val Acc:  47.55%\n",
      "learning rate: [0.0009538777777777777]\n",
      "Epoch   7 | Train Loss: 1.184 | Train Acc:  49.22%\n",
      "Epoch   7 | Val Loss: 1.163 | Val Acc:  50.64%\n",
      "learning rate: [0.0009473777777777778]\n",
      "Epoch   8 | Train Loss: 1.164 | Train Acc:  50.61%\n",
      "Epoch   8 | Val Loss: 1.154 | Val Acc:  50.66%\n",
      "learning rate: [0.0009408999999999998]\n",
      "Epoch   9 | Train Loss: 1.147 | Train Acc:  51.24%\n",
      "Epoch   9 | Val Loss: 1.146 | Val Acc:  51.97%\n",
      "learning rate: [0.0009344444444444443]\n",
      "Epoch  10 | Train Loss: 1.134 | Train Acc:  52.37%\n",
      "Epoch  10 | Val Loss: 1.112 | Val Acc:  53.37%\n",
      "learning rate: [0.000928011111111111]\n",
      "Epoch  11 | Train Loss: 1.122 | Train Acc:  52.82%\n",
      "Epoch  11 | Val Loss: 1.108 | Val Acc:  53.63%\n",
      "learning rate: [0.0009215999999999998]\n",
      "Epoch  12 | Train Loss: 1.106 | Train Acc:  53.63%\n",
      "Epoch  12 | Val Loss: 1.087 | Val Acc:  54.61%\n",
      "learning rate: [0.000915211111111111]\n",
      "Epoch  13 | Train Loss: 1.094 | Train Acc:  54.33%\n",
      "Epoch  13 | Val Loss: 1.077 | Val Acc:  55.44%\n",
      "learning rate: [0.0009088444444444444]\n",
      "Epoch  14 | Train Loss: 1.087 | Train Acc:  54.70%\n",
      "Epoch  14 | Val Loss: 1.079 | Val Acc:  55.41%\n",
      "learning rate: [0.0009024999999999999]\n",
      "Epoch  15 | Train Loss: 1.079 | Train Acc:  54.99%\n",
      "Epoch  15 | Val Loss: 1.057 | Val Acc:  56.64%\n",
      "learning rate: [0.0008961777777777777]\n",
      "Epoch  16 | Train Loss: 1.061 | Train Acc:  55.93%\n",
      "Epoch  16 | Val Loss: 1.056 | Val Acc:  55.94%\n",
      "learning rate: [0.0008898777777777777]\n",
      "Epoch  17 | Train Loss: 1.060 | Train Acc:  55.88%\n",
      "Epoch  17 | Val Loss: 1.037 | Val Acc:  57.94%\n",
      "learning rate: [0.0008835999999999996]\n",
      "Epoch  18 | Train Loss: 1.049 | Train Acc:  56.70%\n",
      "Epoch  18 | Val Loss: 1.038 | Val Acc:  57.87%\n",
      "learning rate: [0.0008773444444444441]\n",
      "Epoch  19 | Train Loss: 1.034 | Train Acc:  57.60%\n",
      "Epoch  19 | Val Loss: 1.025 | Val Acc:  57.80%\n",
      "learning rate: [0.0008711111111111107]\n",
      "Epoch  20 | Train Loss: 1.033 | Train Acc:  57.55%\n",
      "Epoch  20 | Val Loss: 1.013 | Val Acc:  58.87%\n",
      "learning rate: [0.0008648999999999994]\n",
      "Epoch  21 | Train Loss: 1.026 | Train Acc:  58.19%\n",
      "Epoch  21 | Val Loss: 1.004 | Val Acc:  59.13%\n",
      "learning rate: [0.0008587111111111106]\n",
      "Epoch  22 | Train Loss: 1.016 | Train Acc:  58.25%\n",
      "Epoch  22 | Val Loss: 1.010 | Val Acc:  58.47%\n",
      "learning rate: [0.000852544444444444]\n",
      "Epoch  23 | Train Loss: 1.006 | Train Acc:  59.18%\n",
      "Epoch  23 | Val Loss: 0.991 | Val Acc:  59.71%\n",
      "learning rate: [0.0008463999999999996]\n",
      "Epoch  24 | Train Loss: 1.004 | Train Acc:  59.42%\n",
      "Epoch  24 | Val Loss: 0.991 | Val Acc:  59.63%\n",
      "learning rate: [0.0008402777777777772]\n",
      "Epoch  25 | Train Loss: 0.995 | Train Acc:  59.91%\n",
      "Epoch  25 | Val Loss: 0.984 | Val Acc:  60.64%\n",
      "learning rate: [0.0008341777777777775]\n",
      "Epoch  26 | Train Loss: 0.993 | Train Acc:  59.80%\n",
      "Epoch  26 | Val Loss: 0.992 | Val Acc:  60.48%\n",
      "learning rate: [0.0008280999999999998]\n",
      "Epoch  27 | Train Loss: 0.980 | Train Acc:  60.28%\n",
      "Epoch  27 | Val Loss: 0.960 | Val Acc:  62.16%\n",
      "learning rate: [0.0008220444444444441]\n",
      "Epoch  28 | Train Loss: 0.972 | Train Acc:  60.88%\n",
      "Epoch  28 | Val Loss: 0.993 | Val Acc:  58.95%\n",
      "learning rate: [0.0008160111111111107]\n",
      "Epoch  29 | Train Loss: 0.966 | Train Acc:  61.08%\n",
      "Epoch  29 | Val Loss: 0.965 | Val Acc:  60.62%\n",
      "learning rate: [0.0008099999999999997]\n",
      "Epoch  30 | Train Loss: 0.959 | Train Acc:  61.54%\n",
      "Epoch  30 | Val Loss: 0.937 | Val Acc:  62.98%\n",
      "learning rate: [0.000804011111111111]\n",
      "Epoch  31 | Train Loss: 0.950 | Train Acc:  62.05%\n",
      "Epoch  31 | Val Loss: 0.942 | Val Acc:  62.85%\n",
      "learning rate: [0.0007980444444444441]\n",
      "Epoch  32 | Train Loss: 0.941 | Train Acc:  62.50%\n",
      "Epoch  32 | Val Loss: 0.930 | Val Acc:  63.01%\n",
      "learning rate: [0.0007920999999999997]\n",
      "Epoch  33 | Train Loss: 0.936 | Train Acc:  62.57%\n",
      "Epoch  33 | Val Loss: 0.933 | Val Acc:  62.51%\n",
      "learning rate: [0.0007861777777777774]\n",
      "Epoch  34 | Train Loss: 0.930 | Train Acc:  63.03%\n",
      "Epoch  34 | Val Loss: 0.911 | Val Acc:  64.20%\n",
      "learning rate: [0.0007802777777777772]\n",
      "Epoch  35 | Train Loss: 0.924 | Train Acc:  63.35%\n",
      "Epoch  35 | Val Loss: 0.984 | Val Acc:  58.99%\n",
      "learning rate: [0.0007743999999999994]\n",
      "Epoch  36 | Train Loss: 0.925 | Train Acc:  63.41%\n",
      "Epoch  36 | Val Loss: 0.897 | Val Acc:  64.89%\n",
      "learning rate: [0.0007685444444444438]\n",
      "Epoch  37 | Train Loss: 0.909 | Train Acc:  64.14%\n",
      "Epoch  37 | Val Loss: 0.899 | Val Acc:  64.56%\n",
      "learning rate: [0.0007627111111111104]\n",
      "Epoch  38 | Train Loss: 0.909 | Train Acc:  64.37%\n",
      "Epoch  38 | Val Loss: 0.884 | Val Acc:  65.75%\n",
      "learning rate: [0.0007568999999999994]\n",
      "Epoch  39 | Train Loss: 0.905 | Train Acc:  64.30%\n",
      "Epoch  39 | Val Loss: 0.880 | Val Acc:  66.17%\n",
      "learning rate: [0.0007511111111111106]\n",
      "Epoch  40 | Train Loss: 0.891 | Train Acc:  65.12%\n",
      "Epoch  40 | Val Loss: 0.912 | Val Acc:  63.38%\n",
      "learning rate: [0.0007453444444444438]\n",
      "Epoch  41 | Train Loss: 0.889 | Train Acc:  65.40%\n",
      "Epoch  41 | Val Loss: 0.885 | Val Acc:  65.46%\n",
      "learning rate: [0.0007395999999999993]\n",
      "Epoch  42 | Train Loss: 0.887 | Train Acc:  64.91%\n",
      "Epoch  42 | Val Loss: 0.880 | Val Acc:  65.34%\n",
      "learning rate: [0.000733877777777777]\n",
      "Epoch  43 | Train Loss: 0.876 | Train Acc:  65.82%\n",
      "Epoch  43 | Val Loss: 0.856 | Val Acc:  67.00%\n",
      "learning rate: [0.0007281777777777769]\n",
      "Epoch  44 | Train Loss: 0.866 | Train Acc:  66.42%\n",
      "Epoch  44 | Val Loss: 0.876 | Val Acc:  65.25%\n",
      "learning rate: [0.0007224999999999991]\n",
      "Epoch  45 | Train Loss: 0.868 | Train Acc:  66.02%\n",
      "Epoch  45 | Val Loss: 0.860 | Val Acc:  66.09%\n",
      "learning rate: [0.0007168444444444436]\n",
      "Epoch  46 | Train Loss: 0.858 | Train Acc:  66.48%\n",
      "Epoch  46 | Val Loss: 0.854 | Val Acc:  66.38%\n",
      "learning rate: [0.0007112111111111101]\n",
      "Epoch  47 | Train Loss: 0.853 | Train Acc:  66.55%\n",
      "Epoch  47 | Val Loss: 0.831 | Val Acc:  68.19%\n",
      "learning rate: [0.000705599999999999]\n",
      "Epoch  48 | Train Loss: 0.847 | Train Acc:  67.28%\n",
      "Epoch  48 | Val Loss: 0.825 | Val Acc:  68.35%\n",
      "learning rate: [0.0007000111111111102]\n",
      "Epoch  49 | Train Loss: 0.841 | Train Acc:  67.54%\n",
      "Epoch  49 | Val Loss: 0.824 | Val Acc:  68.16%\n",
      "learning rate: [0.0006944444444444435]\n",
      "Epoch  50 | Train Loss: 0.836 | Train Acc:  67.44%\n",
      "Epoch  50 | Val Loss: 0.817 | Val Acc:  68.76%\n",
      "learning rate: [0.0006888999999999989]\n",
      "Epoch  51 | Train Loss: 0.826 | Train Acc:  68.24%\n",
      "Epoch  51 | Val Loss: 0.808 | Val Acc:  69.28%\n",
      "learning rate: [0.0006833777777777767]\n",
      "Epoch  52 | Train Loss: 0.819 | Train Acc:  68.49%\n",
      "Epoch  52 | Val Loss: 0.810 | Val Acc:  68.65%\n",
      "learning rate: [0.0006778777777777768]\n",
      "Epoch  53 | Train Loss: 0.819 | Train Acc:  68.52%\n",
      "Epoch  53 | Val Loss: 0.792 | Val Acc:  70.22%\n",
      "learning rate: [0.0006723999999999991]\n",
      "Epoch  54 | Train Loss: 0.814 | Train Acc:  68.40%\n",
      "Epoch  54 | Val Loss: 0.803 | Val Acc:  69.30%\n",
      "learning rate: [0.0006669444444444435]\n",
      "Epoch  55 | Train Loss: 0.813 | Train Acc:  68.55%\n",
      "Epoch  55 | Val Loss: 0.782 | Val Acc:  70.27%\n",
      "learning rate: [0.0006615111111111103]\n",
      "Epoch  56 | Train Loss: 0.799 | Train Acc:  69.39%\n",
      "Epoch  56 | Val Loss: 0.780 | Val Acc:  70.49%\n",
      "learning rate: [0.0006560999999999992]\n",
      "Epoch  57 | Train Loss: 0.799 | Train Acc:  69.37%\n",
      "Epoch  57 | Val Loss: 0.780 | Val Acc:  70.08%\n",
      "learning rate: [0.0006507111111111102]\n",
      "Epoch  58 | Train Loss: 0.788 | Train Acc:  70.00%\n",
      "Epoch  58 | Val Loss: 0.766 | Val Acc:  71.27%\n",
      "learning rate: [0.0006453444444444437]\n",
      "Epoch  59 | Train Loss: 0.781 | Train Acc:  70.30%\n",
      "Epoch  59 | Val Loss: 0.767 | Val Acc:  71.30%\n",
      "learning rate: [0.0006399999999999993]\n",
      "Epoch  60 | Train Loss: 0.788 | Train Acc:  69.71%\n",
      "Epoch  60 | Val Loss: 0.756 | Val Acc:  71.95%\n",
      "learning rate: [0.0006346777777777769]\n",
      "Epoch  61 | Train Loss: 0.775 | Train Acc:  70.66%\n",
      "Epoch  61 | Val Loss: 0.758 | Val Acc:  71.07%\n",
      "learning rate: [0.0006293777777777769]\n",
      "Epoch  62 | Train Loss: 0.766 | Train Acc:  70.88%\n",
      "Epoch  62 | Val Loss: 0.750 | Val Acc:  72.08%\n",
      "learning rate: [0.0006240999999999992]\n",
      "Epoch  63 | Train Loss: 0.768 | Train Acc:  70.46%\n",
      "Epoch  63 | Val Loss: 0.744 | Val Acc:  72.29%\n",
      "learning rate: [0.0006188444444444435]\n",
      "Epoch  64 | Train Loss: 0.755 | Train Acc:  71.43%\n",
      "Epoch  64 | Val Loss: 0.733 | Val Acc:  72.81%\n",
      "learning rate: [0.0006136111111111102]\n",
      "Epoch  65 | Train Loss: 0.753 | Train Acc:  71.68%\n",
      "Epoch  65 | Val Loss: 0.730 | Val Acc:  72.70%\n",
      "learning rate: [0.0006083999999999991]\n",
      "Epoch  66 | Train Loss: 0.747 | Train Acc:  71.75%\n",
      "Epoch  66 | Val Loss: 0.737 | Val Acc:  72.34%\n",
      "learning rate: [0.0006032111111111101]\n",
      "Epoch  67 | Train Loss: 0.741 | Train Acc:  72.21%\n",
      "Epoch  67 | Val Loss: 0.725 | Val Acc:  72.94%\n",
      "learning rate: [0.0005980444444444435]\n",
      "Epoch  68 | Train Loss: 0.739 | Train Acc:  72.26%\n",
      "Epoch  68 | Val Loss: 0.714 | Val Acc:  73.56%\n",
      "learning rate: [0.0005928999999999991]\n",
      "Epoch  69 | Train Loss: 0.729 | Train Acc:  72.56%\n",
      "Epoch  69 | Val Loss: 0.719 | Val Acc:  73.21%\n",
      "learning rate: [0.0005877777777777768]\n",
      "Epoch  70 | Train Loss: 0.732 | Train Acc:  72.58%\n",
      "Epoch  70 | Val Loss: 0.714 | Val Acc:  73.58%\n",
      "learning rate: [0.0005826777777777768]\n",
      "Epoch  71 | Train Loss: 0.722 | Train Acc:  72.88%\n",
      "Epoch  71 | Val Loss: 0.706 | Val Acc:  73.95%\n",
      "learning rate: [0.0005775999999999991]\n",
      "Epoch  72 | Train Loss: 0.728 | Train Acc:  72.56%\n",
      "Epoch  72 | Val Loss: 0.698 | Val Acc:  74.28%\n",
      "learning rate: [0.0005725444444444434]\n",
      "Epoch  73 | Train Loss: 0.711 | Train Acc:  73.40%\n",
      "Epoch  73 | Val Loss: 0.691 | Val Acc:  74.70%\n",
      "learning rate: [0.0005675111111111101]\n",
      "Epoch  74 | Train Loss: 0.711 | Train Acc:  73.31%\n",
      "Epoch  74 | Val Loss: 0.726 | Val Acc:  72.38%\n",
      "learning rate: [0.0005624999999999991]\n",
      "Epoch  75 | Train Loss: 0.703 | Train Acc:  73.91%\n",
      "Epoch  75 | Val Loss: 0.722 | Val Acc:  72.64%\n",
      "learning rate: [0.00055751111111111]\n",
      "Epoch  76 | Train Loss: 0.699 | Train Acc:  73.86%\n",
      "Epoch  76 | Val Loss: 0.685 | Val Acc:  74.87%\n",
      "learning rate: [0.0005525444444444436]\n",
      "Epoch  77 | Train Loss: 0.697 | Train Acc:  74.03%\n",
      "Epoch  77 | Val Loss: 0.678 | Val Acc:  75.29%\n",
      "learning rate: [0.000547599999999999]\n",
      "Epoch  78 | Train Loss: 0.701 | Train Acc:  73.70%\n",
      "Epoch  78 | Val Loss: 0.682 | Val Acc:  74.85%\n",
      "learning rate: [0.0005426777777777768]\n",
      "Epoch  79 | Train Loss: 0.691 | Train Acc:  74.35%\n",
      "Epoch  79 | Val Loss: 0.672 | Val Acc:  75.55%\n",
      "learning rate: [0.0005377777777777769]\n",
      "Epoch  80 | Train Loss: 0.675 | Train Acc:  75.36%\n",
      "Epoch  80 | Val Loss: 0.655 | Val Acc:  76.51%\n",
      "learning rate: [0.000532899999999999]\n",
      "Epoch  81 | Train Loss: 0.674 | Train Acc:  75.29%\n",
      "Epoch  81 | Val Loss: 0.679 | Val Acc:  75.10%\n",
      "learning rate: [0.0005280444444444436]\n",
      "Epoch  82 | Train Loss: 0.682 | Train Acc:  74.51%\n",
      "Epoch  82 | Val Loss: 0.654 | Val Acc:  76.73%\n",
      "learning rate: [0.0005232111111111103]\n",
      "Epoch  83 | Train Loss: 0.666 | Train Acc:  75.53%\n",
      "Epoch  83 | Val Loss: 0.684 | Val Acc:  74.44%\n",
      "learning rate: [0.000518399999999999]\n",
      "Epoch  84 | Train Loss: 0.671 | Train Acc:  75.24%\n",
      "Epoch  84 | Val Loss: 0.664 | Val Acc:  75.52%\n",
      "learning rate: [0.0005136111111111103]\n",
      "Epoch  85 | Train Loss: 0.655 | Train Acc:  76.27%\n",
      "Epoch  85 | Val Loss: 0.735 | Val Acc:  71.12%\n",
      "learning rate: [0.0005088444444444436]\n",
      "Epoch  86 | Train Loss: 0.665 | Train Acc:  75.60%\n",
      "Epoch  86 | Val Loss: 0.667 | Val Acc:  75.16%\n",
      "learning rate: [0.0005040999999999992]\n",
      "Epoch  87 | Train Loss: 0.648 | Train Acc:  76.41%\n",
      "Epoch  87 | Val Loss: 0.627 | Val Acc:  77.78%\n",
      "learning rate: [0.000499377777777777]\n",
      "Epoch  88 | Train Loss: 0.648 | Train Acc:  76.37%\n",
      "Epoch  88 | Val Loss: 0.653 | Val Acc:  75.86%\n",
      "learning rate: [0.0004946777777777771]\n",
      "Epoch  89 | Train Loss: 0.644 | Train Acc:  76.77%\n",
      "Epoch  89 | Val Loss: 0.634 | Val Acc:  77.43%\n",
      "learning rate: [0.0004899999999999991]\n",
      "Epoch  90 | Train Loss: 0.648 | Train Acc:  76.64%\n",
      "Epoch  90 | Val Loss: 0.645 | Val Acc:  76.55%\n",
      "learning rate: [0.0004853444444444436]\n",
      "Epoch  91 | Train Loss: 0.633 | Train Acc:  77.32%\n",
      "Epoch  91 | Val Loss: 0.615 | Val Acc:  78.16%\n",
      "learning rate: [0.00048071111111111037]\n",
      "Epoch  92 | Train Loss: 0.627 | Train Acc:  77.64%\n",
      "Epoch  92 | Val Loss: 0.612 | Val Acc:  78.25%\n",
      "learning rate: [0.00047609999999999916]\n",
      "Epoch  93 | Train Loss: 0.628 | Train Acc:  77.44%\n",
      "Epoch  93 | Val Loss: 0.630 | Val Acc:  77.03%\n",
      "learning rate: [0.00047151111111111036]\n",
      "Epoch  94 | Train Loss: 0.623 | Train Acc:  77.77%\n",
      "Epoch  94 | Val Loss: 0.618 | Val Acc:  77.98%\n",
      "learning rate: [0.0004669444444444437]\n",
      "Epoch  95 | Train Loss: 0.618 | Train Acc:  78.07%\n",
      "Epoch  95 | Val Loss: 0.597 | Val Acc:  79.27%\n",
      "learning rate: [0.00046239999999999915]\n",
      "Epoch  96 | Train Loss: 0.613 | Train Acc:  78.26%\n",
      "Epoch  96 | Val Loss: 0.592 | Val Acc:  79.64%\n",
      "learning rate: [0.00045787777777777717]\n",
      "Epoch  97 | Train Loss: 0.611 | Train Acc:  78.56%\n",
      "Epoch  97 | Val Loss: 0.604 | Val Acc:  79.10%\n",
      "learning rate: [0.0004533777777777771]\n",
      "Epoch  98 | Train Loss: 0.615 | Train Acc:  78.15%\n",
      "Epoch  98 | Val Loss: 0.640 | Val Acc:  76.20%\n",
      "learning rate: [0.00044889999999999926]\n",
      "Epoch  99 | Train Loss: 0.609 | Train Acc:  78.47%\n",
      "Epoch  99 | Val Loss: 0.615 | Val Acc:  77.46%\n",
      "learning rate: [0.0004444444444444439]\n",
      "Epoch 100 | Train Loss: 0.597 | Train Acc:  78.99%\n",
      "Epoch 100 | Val Loss: 0.584 | Val Acc:  79.68%\n",
      "learning rate: [0.0004400111111111105]\n",
      "Epoch 101 | Train Loss: 0.596 | Train Acc:  79.19%\n",
      "Epoch 101 | Val Loss: 0.573 | Val Acc:  80.44%\n",
      "learning rate: [0.0004355999999999993]\n",
      "Epoch 102 | Train Loss: 0.589 | Train Acc:  79.50%\n",
      "Epoch 102 | Val Loss: 0.570 | Val Acc:  80.78%\n",
      "learning rate: [0.0004312111111111106]\n",
      "Epoch 103 | Train Loss: 0.589 | Train Acc:  79.49%\n",
      "Epoch 103 | Val Loss: 0.644 | Val Acc:  75.68%\n",
      "learning rate: [0.0004268444444444438]\n",
      "Epoch 104 | Train Loss: 0.586 | Train Acc:  79.54%\n",
      "Epoch 104 | Val Loss: 0.568 | Val Acc:  80.42%\n",
      "learning rate: [0.00042249999999999943]\n",
      "Epoch 105 | Train Loss: 0.579 | Train Acc:  80.12%\n",
      "Epoch 105 | Val Loss: 0.564 | Val Acc:  80.86%\n",
      "learning rate: [0.00041817777777777723]\n",
      "Epoch 106 | Train Loss: 0.575 | Train Acc:  80.19%\n",
      "Epoch 106 | Val Loss: 0.557 | Val Acc:  81.31%\n",
      "learning rate: [0.00041387777777777713]\n",
      "Epoch 107 | Train Loss: 0.576 | Train Acc:  80.16%\n",
      "Epoch 107 | Val Loss: 0.609 | Val Acc:  78.18%\n",
      "learning rate: [0.00040959999999999944]\n",
      "Epoch 108 | Train Loss: 0.574 | Train Acc:  80.06%\n",
      "Epoch 108 | Val Loss: 0.551 | Val Acc:  81.52%\n",
      "learning rate: [0.00040534444444444395]\n",
      "Epoch 109 | Train Loss: 0.561 | Train Acc:  80.83%\n",
      "Epoch 109 | Val Loss: 0.568 | Val Acc:  80.44%\n",
      "learning rate: [0.0004011111111111105]\n",
      "Epoch 110 | Train Loss: 0.571 | Train Acc:  80.33%\n",
      "Epoch 110 | Val Loss: 0.548 | Val Acc:  81.61%\n",
      "learning rate: [0.00039689999999999946]\n",
      "Epoch 111 | Train Loss: 0.561 | Train Acc:  80.88%\n",
      "Epoch 111 | Val Loss: 0.541 | Val Acc:  82.25%\n",
      "learning rate: [0.0003927111111111106]\n",
      "Epoch 112 | Train Loss: 0.558 | Train Acc:  80.89%\n",
      "Epoch 112 | Val Loss: 0.560 | Val Acc:  80.69%\n",
      "learning rate: [0.00038854444444444387]\n",
      "Epoch 113 | Train Loss: 0.561 | Train Acc:  80.74%\n",
      "Epoch 113 | Val Loss: 0.559 | Val Acc:  80.86%\n",
      "learning rate: [0.0003843999999999995]\n",
      "Epoch 114 | Train Loss: 0.546 | Train Acc:  81.70%\n",
      "Epoch 114 | Val Loss: 0.548 | Val Acc:  81.29%\n",
      "learning rate: [0.00038027777777777723]\n",
      "Epoch 115 | Train Loss: 0.544 | Train Acc:  81.85%\n",
      "Epoch 115 | Val Loss: 0.553 | Val Acc:  81.04%\n",
      "learning rate: [0.00037617777777777713]\n",
      "Epoch 116 | Train Loss: 0.551 | Train Acc:  81.11%\n",
      "Epoch 116 | Val Loss: 0.525 | Val Acc:  82.92%\n",
      "learning rate: [0.00037209999999999945]\n",
      "Epoch 117 | Train Loss: 0.543 | Train Acc:  81.72%\n",
      "Epoch 117 | Val Loss: 0.534 | Val Acc:  82.65%\n",
      "learning rate: [0.00036804444444444396]\n",
      "Epoch 118 | Train Loss: 0.537 | Train Acc:  82.00%\n",
      "Epoch 118 | Val Loss: 0.519 | Val Acc:  83.03%\n",
      "learning rate: [0.00036401111111111057]\n",
      "Epoch 119 | Train Loss: 0.532 | Train Acc:  82.36%\n",
      "Epoch 119 | Val Loss: 0.515 | Val Acc:  83.56%\n",
      "learning rate: [0.0003599999999999995]\n",
      "Epoch 120 | Train Loss: 0.537 | Train Acc:  82.08%\n",
      "Epoch 120 | Val Loss: 0.516 | Val Acc:  83.54%\n",
      "learning rate: [0.0003560111111111106]\n",
      "Epoch 121 | Train Loss: 0.525 | Train Acc:  82.84%\n",
      "Epoch 121 | Val Loss: 0.514 | Val Acc:  83.41%\n",
      "learning rate: [0.0003520444444444438]\n",
      "Epoch 122 | Train Loss: 0.523 | Train Acc:  82.95%\n",
      "Epoch 122 | Val Loss: 0.520 | Val Acc:  82.60%\n",
      "learning rate: [0.00034809999999999946]\n",
      "Epoch 123 | Train Loss: 0.521 | Train Acc:  83.08%\n",
      "Epoch 123 | Val Loss: 0.584 | Val Acc:  78.27%\n",
      "learning rate: [0.0003441777777777771]\n",
      "Epoch 124 | Train Loss: 0.523 | Train Acc:  82.82%\n",
      "Epoch 124 | Val Loss: 0.505 | Val Acc:  84.13%\n",
      "learning rate: [0.000340277777777777]\n",
      "Epoch 125 | Train Loss: 0.515 | Train Acc:  83.37%\n",
      "Epoch 125 | Val Loss: 0.508 | Val Acc:  83.67%\n",
      "learning rate: [0.0003363999999999994]\n",
      "Epoch 126 | Train Loss: 0.519 | Train Acc:  82.98%\n",
      "Epoch 126 | Val Loss: 0.523 | Val Acc:  82.72%\n",
      "learning rate: [0.00033254444444444375]\n",
      "Epoch 127 | Train Loss: 0.513 | Train Acc:  83.30%\n",
      "Epoch 127 | Val Loss: 0.493 | Val Acc:  84.68%\n",
      "learning rate: [0.0003287111111111103]\n",
      "Epoch 128 | Train Loss: 0.506 | Train Acc:  83.79%\n",
      "Epoch 128 | Val Loss: 0.506 | Val Acc:  83.61%\n",
      "learning rate: [0.00032489999999999933]\n",
      "Epoch 129 | Train Loss: 0.509 | Train Acc:  83.48%\n",
      "Epoch 129 | Val Loss: 0.489 | Val Acc:  84.84%\n",
      "learning rate: [0.00032111111111111034]\n",
      "Epoch 130 | Train Loss: 0.501 | Train Acc:  84.06%\n",
      "Epoch 130 | Val Loss: 0.496 | Val Acc:  84.29%\n",
      "learning rate: [0.0003173444444444437]\n",
      "Epoch 131 | Train Loss: 0.500 | Train Acc:  84.09%\n",
      "Epoch 131 | Val Loss: 0.537 | Val Acc:  81.50%\n",
      "learning rate: [0.00031359999999999933]\n",
      "Epoch 132 | Train Loss: 0.501 | Train Acc:  83.80%\n",
      "Epoch 132 | Val Loss: 0.498 | Val Acc:  83.82%\n",
      "learning rate: [0.00030987777777777704]\n",
      "Epoch 133 | Train Loss: 0.497 | Train Acc:  84.32%\n",
      "Epoch 133 | Val Loss: 0.487 | Val Acc:  84.59%\n",
      "learning rate: [0.0003061777777777771]\n",
      "Epoch 134 | Train Loss: 0.492 | Train Acc:  84.34%\n",
      "Epoch 134 | Val Loss: 0.490 | Val Acc:  84.52%\n",
      "learning rate: [0.0003024999999999994]\n",
      "Epoch 135 | Train Loss: 0.495 | Train Acc:  84.04%\n",
      "Epoch 135 | Val Loss: 0.475 | Val Acc:  85.41%\n",
      "learning rate: [0.00029884444444444375]\n",
      "Epoch 136 | Train Loss: 0.485 | Train Acc:  84.89%\n",
      "Epoch 136 | Val Loss: 0.471 | Val Acc:  85.79%\n",
      "learning rate: [0.0002952111111111105]\n",
      "Epoch 137 | Train Loss: 0.492 | Train Acc:  84.31%\n",
      "Epoch 137 | Val Loss: 0.472 | Val Acc:  85.78%\n",
      "learning rate: [0.00029159999999999944]\n",
      "Epoch 138 | Train Loss: 0.479 | Train Acc:  85.06%\n",
      "Epoch 138 | Val Loss: 0.473 | Val Acc:  85.76%\n",
      "learning rate: [0.0002880111111111105]\n",
      "Epoch 139 | Train Loss: 0.478 | Train Acc:  85.24%\n",
      "Epoch 139 | Val Loss: 0.463 | Val Acc:  86.10%\n",
      "learning rate: [0.0002844444444444439]\n",
      "Epoch 140 | Train Loss: 0.480 | Train Acc:  85.21%\n",
      "Epoch 140 | Val Loss: 0.463 | Val Acc:  85.95%\n",
      "learning rate: [0.00028089999999999946]\n",
      "Epoch 141 | Train Loss: 0.474 | Train Acc:  85.54%\n",
      "Epoch 141 | Val Loss: 0.477 | Val Acc:  84.95%\n",
      "learning rate: [0.00027737777777777717]\n",
      "Epoch 142 | Train Loss: 0.472 | Train Acc:  85.50%\n",
      "Epoch 142 | Val Loss: 0.457 | Val Acc:  86.55%\n",
      "learning rate: [0.0002738777777777772]\n",
      "Epoch 143 | Train Loss: 0.473 | Train Acc:  85.44%\n",
      "Epoch 143 | Val Loss: 0.464 | Val Acc:  86.06%\n",
      "learning rate: [0.00027039999999999947]\n",
      "Epoch 144 | Train Loss: 0.467 | Train Acc:  85.83%\n",
      "Epoch 144 | Val Loss: 0.463 | Val Acc:  86.34%\n",
      "learning rate: [0.00026694444444444384]\n",
      "Epoch 145 | Train Loss: 0.466 | Train Acc:  85.87%\n",
      "Epoch 145 | Val Loss: 0.483 | Val Acc:  84.08%\n",
      "learning rate: [0.00026351111111111057]\n",
      "Epoch 146 | Train Loss: 0.466 | Train Acc:  85.84%\n",
      "Epoch 146 | Val Loss: 0.450 | Val Acc:  86.95%\n",
      "learning rate: [0.0002600999999999995]\n",
      "Epoch 147 | Train Loss: 0.460 | Train Acc:  86.22%\n",
      "Epoch 147 | Val Loss: 0.455 | Val Acc:  86.47%\n",
      "learning rate: [0.0002567111111111105]\n",
      "Epoch 148 | Train Loss: 0.460 | Train Acc:  86.29%\n",
      "Epoch 148 | Val Loss: 0.443 | Val Acc:  87.63%\n",
      "learning rate: [0.000253344444444444]\n",
      "Epoch 149 | Train Loss: 0.453 | Train Acc:  86.65%\n",
      "Epoch 149 | Val Loss: 0.443 | Val Acc:  87.56%\n",
      "learning rate: [0.0002499999999999995]\n",
      "Epoch 150 | Train Loss: 0.452 | Train Acc:  86.50%\n",
      "Epoch 150 | Val Loss: 0.441 | Val Acc:  87.38%\n",
      "learning rate: [0.00024667777777777735]\n",
      "Epoch 151 | Train Loss: 0.456 | Train Acc:  86.37%\n",
      "Epoch 151 | Val Loss: 0.441 | Val Acc:  87.26%\n",
      "learning rate: [0.0002433777777777773]\n",
      "Epoch 152 | Train Loss: 0.448 | Train Acc:  86.92%\n",
      "Epoch 152 | Val Loss: 0.437 | Val Acc:  87.69%\n",
      "learning rate: [0.00024009999999999955]\n",
      "Epoch 153 | Train Loss: 0.447 | Train Acc:  86.89%\n",
      "Epoch 153 | Val Loss: 0.435 | Val Acc:  87.56%\n",
      "learning rate: [0.00023684444444444403]\n",
      "Epoch 154 | Train Loss: 0.442 | Train Acc:  87.27%\n",
      "Epoch 154 | Val Loss: 0.428 | Val Acc:  88.28%\n",
      "learning rate: [0.00023361111111111065]\n",
      "Epoch 155 | Train Loss: 0.439 | Train Acc:  87.31%\n",
      "Epoch 155 | Val Loss: 0.437 | Val Acc:  87.62%\n",
      "learning rate: [0.00023039999999999958]\n",
      "Epoch 156 | Train Loss: 0.441 | Train Acc:  87.17%\n",
      "Epoch 156 | Val Loss: 0.433 | Val Acc:  88.05%\n",
      "learning rate: [0.0002272111111111107]\n",
      "Epoch 157 | Train Loss: 0.440 | Train Acc:  87.30%\n",
      "Epoch 157 | Val Loss: 0.435 | Val Acc:  87.36%\n",
      "learning rate: [0.0002240444444444441]\n",
      "Epoch 158 | Train Loss: 0.441 | Train Acc:  87.12%\n",
      "Epoch 158 | Val Loss: 0.422 | Val Acc:  88.52%\n",
      "learning rate: [0.00022089999999999957]\n",
      "Epoch 159 | Train Loss: 0.433 | Train Acc:  87.67%\n",
      "Epoch 159 | Val Loss: 0.431 | Val Acc:  87.73%\n",
      "learning rate: [0.0002177777777777774]\n",
      "Epoch 160 | Train Loss: 0.432 | Train Acc:  87.58%\n",
      "Epoch 160 | Val Loss: 0.424 | Val Acc:  88.24%\n",
      "learning rate: [0.00021467777777777744]\n",
      "Epoch 161 | Train Loss: 0.430 | Train Acc:  87.76%\n",
      "Epoch 161 | Val Loss: 0.427 | Val Acc:  88.10%\n",
      "learning rate: [0.0002115999999999996]\n",
      "Epoch 162 | Train Loss: 0.434 | Train Acc:  87.64%\n",
      "Epoch 162 | Val Loss: 0.422 | Val Acc:  88.48%\n",
      "learning rate: [0.00020854444444444407]\n",
      "Epoch 163 | Train Loss: 0.427 | Train Acc:  88.00%\n",
      "Epoch 163 | Val Loss: 0.422 | Val Acc:  88.32%\n",
      "learning rate: [0.00020551111111111078]\n",
      "Epoch 164 | Train Loss: 0.426 | Train Acc:  88.18%\n",
      "Epoch 164 | Val Loss: 0.425 | Val Acc:  88.08%\n",
      "learning rate: [0.00020249999999999958]\n",
      "Epoch 165 | Train Loss: 0.425 | Train Acc:  88.14%\n",
      "Epoch 165 | Val Loss: 0.422 | Val Acc:  88.21%\n",
      "learning rate: [0.00019951111111111074]\n",
      "Epoch 166 | Train Loss: 0.421 | Train Acc:  88.35%\n",
      "Epoch 166 | Val Loss: 0.411 | Val Acc:  89.19%\n",
      "learning rate: [0.00019654444444444413]\n",
      "Epoch 167 | Train Loss: 0.419 | Train Acc:  88.52%\n",
      "Epoch 167 | Val Loss: 0.411 | Val Acc:  89.35%\n",
      "learning rate: [0.0001935999999999996]\n",
      "Epoch 168 | Train Loss: 0.416 | Train Acc:  88.63%\n",
      "Epoch 168 | Val Loss: 0.407 | Val Acc:  89.28%\n",
      "learning rate: [0.00019067777777777742]\n",
      "Epoch 169 | Train Loss: 0.414 | Train Acc:  88.96%\n",
      "Epoch 169 | Val Loss: 0.408 | Val Acc:  89.12%\n",
      "learning rate: [0.00018777777777777746]\n",
      "Epoch 170 | Train Loss: 0.414 | Train Acc:  88.83%\n",
      "Epoch 170 | Val Loss: 0.402 | Val Acc:  89.57%\n",
      "learning rate: [0.0001848999999999997]\n",
      "Epoch 171 | Train Loss: 0.421 | Train Acc:  88.18%\n",
      "Epoch 171 | Val Loss: 0.410 | Val Acc:  88.74%\n",
      "learning rate: [0.0001820444444444441]\n",
      "Epoch 172 | Train Loss: 0.411 | Train Acc:  88.83%\n",
      "Epoch 172 | Val Loss: 0.414 | Val Acc:  88.61%\n",
      "learning rate: [0.00017921111111111082]\n",
      "Epoch 173 | Train Loss: 0.409 | Train Acc:  89.04%\n",
      "Epoch 173 | Val Loss: 0.397 | Val Acc:  89.97%\n",
      "learning rate: [0.00017639999999999976]\n",
      "Epoch 174 | Train Loss: 0.408 | Train Acc:  89.35%\n",
      "Epoch 174 | Val Loss: 0.399 | Val Acc:  89.68%\n",
      "learning rate: [0.00017361111111111082]\n",
      "Epoch 175 | Train Loss: 0.409 | Train Acc:  88.88%\n",
      "Epoch 175 | Val Loss: 0.398 | Val Acc:  90.10%\n",
      "learning rate: [0.00017084444444444419]\n",
      "Epoch 176 | Train Loss: 0.407 | Train Acc:  89.23%\n",
      "Epoch 176 | Val Loss: 0.397 | Val Acc:  89.66%\n",
      "learning rate: [0.0001680999999999998]\n",
      "Epoch 177 | Train Loss: 0.400 | Train Acc:  89.62%\n",
      "Epoch 177 | Val Loss: 0.394 | Val Acc:  90.06%\n",
      "learning rate: [0.00016537777777777754]\n",
      "Epoch 178 | Train Loss: 0.404 | Train Acc:  89.24%\n",
      "Epoch 178 | Val Loss: 0.395 | Val Acc:  89.75%\n",
      "learning rate: [0.00016267777777777758]\n",
      "Epoch 179 | Train Loss: 0.400 | Train Acc:  89.54%\n",
      "Epoch 179 | Val Loss: 0.393 | Val Acc:  90.25%\n",
      "learning rate: [0.00015999999999999985]\n",
      "Epoch 180 | Train Loss: 0.400 | Train Acc:  89.63%\n",
      "Epoch 180 | Val Loss: 0.387 | Val Acc:  90.49%\n",
      "learning rate: [0.00015734444444444424]\n",
      "Epoch 181 | Train Loss: 0.398 | Train Acc:  89.78%\n",
      "Epoch 181 | Val Loss: 0.387 | Val Acc:  90.39%\n",
      "learning rate: [0.00015471111111111093]\n",
      "Epoch 182 | Train Loss: 0.395 | Train Acc:  89.99%\n",
      "Epoch 182 | Val Loss: 0.385 | Val Acc:  90.61%\n",
      "learning rate: [0.00015209999999999985]\n",
      "Epoch 183 | Train Loss: 0.394 | Train Acc:  89.90%\n",
      "Epoch 183 | Val Loss: 0.391 | Val Acc:  90.07%\n",
      "learning rate: [0.000149511111111111]\n",
      "Epoch 184 | Train Loss: 0.393 | Train Acc:  89.96%\n",
      "Epoch 184 | Val Loss: 0.388 | Val Acc:  90.37%\n",
      "learning rate: [0.00014694444444444428]\n",
      "Epoch 185 | Train Loss: 0.390 | Train Acc:  90.14%\n",
      "Epoch 185 | Val Loss: 0.384 | Val Acc:  90.52%\n",
      "learning rate: [0.00014439999999999985]\n",
      "Epoch 186 | Train Loss: 0.390 | Train Acc:  90.14%\n",
      "Epoch 186 | Val Loss: 0.380 | Val Acc:  90.87%\n",
      "learning rate: [0.00014187777777777765]\n",
      "Epoch 187 | Train Loss: 0.389 | Train Acc:  90.25%\n",
      "Epoch 187 | Val Loss: 0.388 | Val Acc:  90.15%\n",
      "learning rate: [0.00013937777777777758]\n",
      "Epoch 188 | Train Loss: 0.389 | Train Acc:  90.22%\n",
      "Epoch 188 | Val Loss: 0.385 | Val Acc:  90.20%\n",
      "learning rate: [0.00013689999999999986]\n",
      "Epoch 189 | Train Loss: 0.388 | Train Acc:  90.18%\n",
      "Epoch 189 | Val Loss: 0.378 | Val Acc:  90.87%\n",
      "learning rate: [0.00013444444444444433]\n",
      "Epoch 190 | Train Loss: 0.385 | Train Acc:  90.54%\n",
      "Epoch 190 | Val Loss: 0.391 | Val Acc:  89.71%\n",
      "learning rate: [0.00013201111111111095]\n",
      "Epoch 191 | Train Loss: 0.384 | Train Acc:  90.47%\n",
      "Epoch 191 | Val Loss: 0.387 | Val Acc:  90.34%\n",
      "learning rate: [0.00012959999999999984]\n",
      "Epoch 192 | Train Loss: 0.382 | Train Acc:  90.59%\n",
      "Epoch 192 | Val Loss: 0.378 | Val Acc:  90.91%\n",
      "learning rate: [0.00012721111111111097]\n",
      "Epoch 193 | Train Loss: 0.385 | Train Acc:  90.57%\n",
      "Epoch 193 | Val Loss: 0.378 | Val Acc:  90.70%\n",
      "learning rate: [0.00012484444444444431]\n",
      "Epoch 194 | Train Loss: 0.382 | Train Acc:  90.63%\n",
      "Epoch 194 | Val Loss: 0.374 | Val Acc:  91.07%\n",
      "learning rate: [0.0001224999999999998]\n",
      "Epoch 195 | Train Loss: 0.379 | Train Acc:  90.96%\n",
      "Epoch 195 | Val Loss: 0.374 | Val Acc:  91.32%\n",
      "learning rate: [0.00012017777777777763]\n",
      "Epoch 196 | Train Loss: 0.380 | Train Acc:  90.71%\n",
      "Epoch 196 | Val Loss: 0.373 | Val Acc:  91.24%\n",
      "learning rate: [0.00011787777777777767]\n",
      "Epoch 197 | Train Loss: 0.379 | Train Acc:  90.72%\n",
      "Epoch 197 | Val Loss: 0.368 | Val Acc:  91.49%\n",
      "learning rate: [0.00011559999999999984]\n",
      "Epoch 198 | Train Loss: 0.377 | Train Acc:  90.94%\n",
      "Epoch 198 | Val Loss: 0.369 | Val Acc:  91.44%\n",
      "learning rate: [0.00011334444444444433]\n",
      "Epoch 199 | Train Loss: 0.373 | Train Acc:  91.09%\n",
      "Epoch 199 | Val Loss: 0.366 | Val Acc:  91.70%\n",
      "learning rate: [0.00011111111111111102]\n",
      "Epoch 200 | Train Loss: 0.372 | Train Acc:  91.21%\n",
      "Epoch 200 | Val Loss: 0.365 | Val Acc:  91.73%\n",
      "learning rate: [0.00010889999999999986]\n",
      "Epoch 201 | Train Loss: 0.373 | Train Acc:  91.23%\n",
      "Epoch 201 | Val Loss: 0.366 | Val Acc:  91.72%\n",
      "learning rate: [0.00010671111111111101]\n",
      "Epoch 202 | Train Loss: 0.372 | Train Acc:  91.27%\n",
      "Epoch 202 | Val Loss: 0.367 | Val Acc:  91.50%\n",
      "learning rate: [0.00010454444444444436]\n",
      "Epoch 203 | Train Loss: 0.372 | Train Acc:  91.15%\n",
      "Epoch 203 | Val Loss: 0.363 | Val Acc:  91.98%\n",
      "learning rate: [0.00010239999999999987]\n",
      "Epoch 204 | Train Loss: 0.370 | Train Acc:  91.27%\n",
      "Epoch 204 | Val Loss: 0.368 | Val Acc:  91.27%\n",
      "learning rate: [0.00010027777777777768]\n",
      "Epoch 205 | Train Loss: 0.367 | Train Acc:  91.46%\n",
      "Epoch 205 | Val Loss: 0.364 | Val Acc:  91.62%\n",
      "learning rate: [9.81777777777777e-05]\n",
      "Epoch 206 | Train Loss: 0.367 | Train Acc:  91.51%\n",
      "Epoch 206 | Val Loss: 0.366 | Val Acc:  91.53%\n",
      "learning rate: [9.609999999999995e-05]\n",
      "Epoch 207 | Train Loss: 0.365 | Train Acc:  91.62%\n",
      "Epoch 207 | Val Loss: 0.366 | Val Acc:  91.35%\n",
      "learning rate: [9.404444444444436e-05]\n",
      "Epoch 208 | Train Loss: 0.366 | Train Acc:  91.64%\n",
      "Epoch 208 | Val Loss: 0.362 | Val Acc:  91.73%\n",
      "learning rate: [9.201111111111105e-05]\n",
      "Epoch 209 | Train Loss: 0.367 | Train Acc:  91.52%\n",
      "Epoch 209 | Val Loss: 0.362 | Val Acc:  91.96%\n",
      "learning rate: [8.999999999999997e-05]\n",
      "Epoch 210 | Train Loss: 0.363 | Train Acc:  91.77%\n",
      "Epoch 210 | Val Loss: 0.358 | Val Acc:  92.04%\n",
      "learning rate: [8.801111111111103e-05]\n",
      "Epoch 211 | Train Loss: 0.362 | Train Acc:  92.00%\n",
      "Epoch 211 | Val Loss: 0.373 | Val Acc:  90.71%\n",
      "learning rate: [8.604444444444437e-05]\n",
      "Epoch 212 | Train Loss: 0.365 | Train Acc:  91.63%\n",
      "Epoch 212 | Val Loss: 0.363 | Val Acc:  91.69%\n",
      "learning rate: [8.409999999999996e-05]\n",
      "Epoch 213 | Train Loss: 0.363 | Train Acc:  91.62%\n",
      "Epoch 213 | Val Loss: 0.359 | Val Acc:  91.93%\n",
      "learning rate: [8.217777777777769e-05]\n",
      "Epoch 214 | Train Loss: 0.360 | Train Acc:  91.90%\n",
      "Epoch 214 | Val Loss: 0.357 | Val Acc:  92.20%\n",
      "learning rate: [8.02777777777777e-05]\n",
      "Epoch 215 | Train Loss: 0.359 | Train Acc:  92.03%\n",
      "Epoch 215 | Val Loss: 0.355 | Val Acc:  92.21%\n",
      "learning rate: [7.839999999999995e-05]\n",
      "Epoch 216 | Train Loss: 0.358 | Train Acc:  92.02%\n",
      "Epoch 216 | Val Loss: 0.352 | Val Acc:  92.47%\n",
      "learning rate: [7.654444444444435e-05]\n",
      "Epoch 217 | Train Loss: 0.358 | Train Acc:  92.07%\n",
      "Epoch 217 | Val Loss: 0.354 | Val Acc:  92.25%\n",
      "learning rate: [7.471111111111103e-05]\n",
      "Epoch 218 | Train Loss: 0.358 | Train Acc:  91.86%\n",
      "Epoch 218 | Val Loss: 0.353 | Val Acc:  92.34%\n",
      "learning rate: [7.289999999999994e-05]\n",
      "Epoch 219 | Train Loss: 0.355 | Train Acc:  92.24%\n",
      "Epoch 219 | Val Loss: 0.352 | Val Acc:  92.47%\n",
      "learning rate: [7.111111111111108e-05]\n",
      "Epoch 220 | Train Loss: 0.356 | Train Acc:  92.17%\n",
      "Epoch 220 | Val Loss: 0.351 | Val Acc:  92.66%\n",
      "learning rate: [6.934444444444437e-05]\n",
      "Epoch 221 | Train Loss: 0.354 | Train Acc:  92.30%\n",
      "Epoch 221 | Val Loss: 0.351 | Val Acc:  92.41%\n",
      "learning rate: [6.759999999999995e-05]\n",
      "Epoch 222 | Train Loss: 0.355 | Train Acc:  92.11%\n",
      "Epoch 222 | Val Loss: 0.354 | Val Acc:  92.33%\n",
      "learning rate: [6.587777777777775e-05]\n",
      "Epoch 223 | Train Loss: 0.355 | Train Acc:  92.24%\n",
      "Epoch 223 | Val Loss: 0.348 | Val Acc:  92.62%\n",
      "learning rate: [6.417777777777771e-05]\n",
      "Epoch 224 | Train Loss: 0.355 | Train Acc:  92.22%\n",
      "Epoch 224 | Val Loss: 0.352 | Val Acc:  92.35%\n",
      "learning rate: [6.249999999999996e-05]\n",
      "Epoch 225 | Train Loss: 0.352 | Train Acc:  92.33%\n",
      "Epoch 225 | Val Loss: 0.347 | Val Acc:  92.87%\n",
      "learning rate: [6.084444444444442e-05]\n",
      "Epoch 226 | Train Loss: 0.351 | Train Acc:  92.42%\n",
      "Epoch 226 | Val Loss: 0.346 | Val Acc:  92.73%\n",
      "learning rate: [5.9211111111111054e-05]\n",
      "Epoch 227 | Train Loss: 0.352 | Train Acc:  92.36%\n",
      "Epoch 227 | Val Loss: 0.347 | Val Acc:  92.80%\n",
      "learning rate: [5.7599999999999964e-05]\n",
      "Epoch 228 | Train Loss: 0.350 | Train Acc:  92.50%\n",
      "Epoch 228 | Val Loss: 0.351 | Val Acc:  92.33%\n",
      "learning rate: [5.60111111111111e-05]\n",
      "Epoch 229 | Train Loss: 0.350 | Train Acc:  92.61%\n",
      "Epoch 229 | Val Loss: 0.347 | Val Acc:  92.75%\n",
      "learning rate: [5.44444444444444e-05]\n",
      "Epoch 230 | Train Loss: 0.350 | Train Acc:  92.55%\n",
      "Epoch 230 | Val Loss: 0.350 | Val Acc:  92.36%\n",
      "learning rate: [5.289999999999997e-05]\n",
      "Epoch 231 | Train Loss: 0.350 | Train Acc:  92.46%\n",
      "Epoch 231 | Val Loss: 0.349 | Val Acc:  92.53%\n",
      "learning rate: [5.137777777777776e-05]\n",
      "Epoch 232 | Train Loss: 0.349 | Train Acc:  92.54%\n",
      "Epoch 232 | Val Loss: 0.345 | Val Acc:  92.89%\n",
      "learning rate: [4.987777777777778e-05]\n",
      "Epoch 233 | Train Loss: 0.347 | Train Acc:  92.70%\n",
      "Epoch 233 | Val Loss: 0.344 | Val Acc:  92.73%\n",
      "learning rate: [4.839999999999997e-05]\n",
      "Epoch 234 | Train Loss: 0.346 | Train Acc:  92.74%\n",
      "Epoch 234 | Val Loss: 0.343 | Val Acc:  93.04%\n",
      "learning rate: [4.6944444444444426e-05]\n",
      "Epoch 235 | Train Loss: 0.345 | Train Acc:  92.75%\n",
      "Epoch 235 | Val Loss: 0.343 | Val Acc:  92.95%\n",
      "learning rate: [4.551111111111111e-05]\n",
      "Epoch 236 | Train Loss: 0.346 | Train Acc:  92.77%\n",
      "Epoch 236 | Val Loss: 0.343 | Val Acc:  92.87%\n",
      "learning rate: [4.409999999999997e-05]\n",
      "Epoch 237 | Train Loss: 0.344 | Train Acc:  92.88%\n",
      "Epoch 237 | Val Loss: 0.342 | Val Acc:  93.01%\n",
      "learning rate: [4.2711111111111094e-05]\n",
      "Epoch 238 | Train Loss: 0.344 | Train Acc:  92.81%\n",
      "Epoch 238 | Val Loss: 0.348 | Val Acc:  92.61%\n",
      "learning rate: [4.134444444444444e-05]\n",
      "Epoch 239 | Train Loss: 0.345 | Train Acc:  92.86%\n",
      "Epoch 239 | Val Loss: 0.341 | Val Acc:  93.07%\n",
      "learning rate: [3.999999999999997e-05]\n",
      "Epoch 240 | Train Loss: 0.344 | Train Acc:  92.92%\n",
      "Epoch 240 | Val Loss: 0.341 | Val Acc:  93.03%\n",
      "learning rate: [3.8677777777777766e-05]\n",
      "Epoch 241 | Train Loss: 0.343 | Train Acc:  92.91%\n",
      "Epoch 241 | Val Loss: 0.341 | Val Acc:  92.95%\n",
      "learning rate: [3.737777777777778e-05]\n",
      "Epoch 242 | Train Loss: 0.343 | Train Acc:  92.85%\n",
      "Epoch 242 | Val Loss: 0.354 | Val Acc:  91.82%\n",
      "learning rate: [3.6099999999999976e-05]\n",
      "Epoch 243 | Train Loss: 0.344 | Train Acc:  92.82%\n",
      "Epoch 243 | Val Loss: 0.341 | Val Acc:  93.12%\n",
      "learning rate: [3.484444444444444e-05]\n",
      "Epoch 244 | Train Loss: 0.342 | Train Acc:  93.07%\n",
      "Epoch 244 | Val Loss: 0.341 | Val Acc:  93.05%\n",
      "learning rate: [3.3611111111111116e-05]\n",
      "Epoch 245 | Train Loss: 0.342 | Train Acc:  92.93%\n",
      "Epoch 245 | Val Loss: 0.339 | Val Acc:  93.14%\n",
      "learning rate: [3.240000000000002e-05]\n",
      "Epoch 246 | Train Loss: 0.341 | Train Acc:  93.08%\n",
      "Epoch 246 | Val Loss: 0.339 | Val Acc:  93.16%\n",
      "learning rate: [3.1211111111111106e-05]\n",
      "Epoch 247 | Train Loss: 0.341 | Train Acc:  93.01%\n",
      "Epoch 247 | Val Loss: 0.339 | Val Acc:  93.19%\n",
      "learning rate: [3.0044444444444452e-05]\n",
      "Epoch 248 | Train Loss: 0.340 | Train Acc:  93.06%\n",
      "Epoch 248 | Val Loss: 0.339 | Val Acc:  93.08%\n",
      "learning rate: [2.8900000000000018e-05]\n",
      "Epoch 249 | Train Loss: 0.340 | Train Acc:  93.10%\n",
      "Epoch 249 | Val Loss: 0.340 | Val Acc:  93.07%\n",
      "learning rate: [2.777777777777777e-05]\n",
      "Epoch 250 | Train Loss: 0.340 | Train Acc:  93.13%\n",
      "Epoch 250 | Val Loss: 0.337 | Val Acc:  93.15%\n",
      "learning rate: [2.667777777777778e-05]\n",
      "Epoch 251 | Train Loss: 0.339 | Train Acc:  93.18%\n",
      "Epoch 251 | Val Loss: 0.337 | Val Acc:  93.32%\n",
      "learning rate: [2.5600000000000012e-05]\n",
      "Epoch 252 | Train Loss: 0.339 | Train Acc:  93.09%\n",
      "Epoch 252 | Val Loss: 0.339 | Val Acc:  93.20%\n",
      "learning rate: [2.454444444444443e-05]\n",
      "Epoch 253 | Train Loss: 0.339 | Train Acc:  93.16%\n",
      "Epoch 253 | Val Loss: 0.336 | Val Acc:  93.39%\n",
      "learning rate: [2.3511111111111108e-05]\n",
      "Epoch 254 | Train Loss: 0.338 | Train Acc:  93.17%\n",
      "Epoch 254 | Val Loss: 0.336 | Val Acc:  93.29%\n",
      "learning rate: [2.2500000000000008e-05]\n",
      "Epoch 255 | Train Loss: 0.338 | Train Acc:  93.21%\n",
      "Epoch 255 | Val Loss: 0.337 | Val Acc:  93.25%\n",
      "learning rate: [2.1511111111111097e-05]\n",
      "Epoch 256 | Train Loss: 0.338 | Train Acc:  93.18%\n",
      "Epoch 256 | Val Loss: 0.336 | Val Acc:  93.40%\n",
      "learning rate: [2.054444444444444e-05]\n",
      "Epoch 257 | Train Loss: 0.338 | Train Acc:  93.15%\n",
      "Epoch 257 | Val Loss: 0.335 | Val Acc:  93.39%\n",
      "learning rate: [1.9600000000000005e-05]\n",
      "Epoch 258 | Train Loss: 0.337 | Train Acc:  93.23%\n",
      "Epoch 258 | Val Loss: 0.336 | Val Acc:  93.29%\n",
      "learning rate: [1.8677777777777792e-05]\n",
      "Epoch 259 | Train Loss: 0.336 | Train Acc:  93.41%\n",
      "Epoch 259 | Val Loss: 0.338 | Val Acc:  93.16%\n",
      "learning rate: [1.777777777777777e-05]\n",
      "Epoch 260 | Train Loss: 0.337 | Train Acc:  93.25%\n",
      "Epoch 260 | Val Loss: 0.335 | Val Acc:  93.39%\n",
      "learning rate: [1.69e-05]\n",
      "Epoch 261 | Train Loss: 0.336 | Train Acc:  93.36%\n",
      "Epoch 261 | Val Loss: 0.335 | Val Acc:  93.40%\n",
      "learning rate: [1.6044444444444454e-05]\n",
      "Epoch 262 | Train Loss: 0.337 | Train Acc:  93.31%\n",
      "Epoch 262 | Val Loss: 0.335 | Val Acc:  93.38%\n",
      "learning rate: [1.5211111111111101e-05]\n",
      "Epoch 263 | Train Loss: 0.336 | Train Acc:  93.35%\n",
      "Epoch 263 | Val Loss: 0.335 | Val Acc:  93.46%\n",
      "learning rate: [1.44e-05]\n",
      "Epoch 264 | Train Loss: 0.335 | Train Acc:  93.35%\n",
      "Epoch 264 | Val Loss: 0.336 | Val Acc:  93.24%\n",
      "learning rate: [1.3611111111111118e-05]\n",
      "Epoch 265 | Train Loss: 0.336 | Train Acc:  93.30%\n",
      "Epoch 265 | Val Loss: 0.335 | Val Acc:  93.30%\n",
      "learning rate: [1.2844444444444432e-05]\n",
      "Epoch 266 | Train Loss: 0.336 | Train Acc:  93.26%\n",
      "Epoch 266 | Val Loss: 0.334 | Val Acc:  93.48%\n",
      "learning rate: [1.2099999999999996e-05]\n",
      "Epoch 267 | Train Loss: 0.335 | Train Acc:  93.33%\n",
      "Epoch 267 | Val Loss: 0.335 | Val Acc:  93.42%\n",
      "learning rate: [1.1377777777777782e-05]\n",
      "Epoch 268 | Train Loss: 0.335 | Train Acc:  93.38%\n",
      "Epoch 268 | Val Loss: 0.334 | Val Acc:  93.42%\n",
      "learning rate: [1.0677777777777789e-05]\n",
      "Epoch 269 | Train Loss: 0.334 | Train Acc:  93.44%\n",
      "Epoch 269 | Val Loss: 0.334 | Val Acc:  93.45%\n",
      "learning rate: [9.999999999999994e-06]\n",
      "Epoch 270 | Train Loss: 0.334 | Train Acc:  93.47%\n",
      "Epoch 270 | Val Loss: 0.333 | Val Acc:  93.50%\n",
      "learning rate: [9.344444444444446e-06]\n",
      "Epoch 271 | Train Loss: 0.334 | Train Acc:  93.34%\n",
      "Epoch 271 | Val Loss: 0.333 | Val Acc:  93.47%\n",
      "learning rate: [8.711111111111118e-06]\n",
      "Epoch 272 | Train Loss: 0.334 | Train Acc:  93.42%\n",
      "Epoch 272 | Val Loss: 0.333 | Val Acc:  93.54%\n",
      "learning rate: [8.099999999999994e-06]\n",
      "Epoch 273 | Train Loss: 0.334 | Train Acc:  93.40%\n",
      "Epoch 273 | Val Loss: 0.334 | Val Acc:  93.46%\n",
      "learning rate: [7.511111111111111e-06]\n",
      "Epoch 274 | Train Loss: 0.334 | Train Acc:  93.46%\n",
      "Epoch 274 | Val Loss: 0.333 | Val Acc:  93.54%\n",
      "learning rate: [6.94444444444445e-06]\n",
      "Epoch 275 | Train Loss: 0.334 | Train Acc:  93.41%\n",
      "Epoch 275 | Val Loss: 0.333 | Val Acc:  93.51%\n",
      "learning rate: [6.399999999999992e-06]\n",
      "Epoch 276 | Train Loss: 0.334 | Train Acc:  93.42%\n",
      "Epoch 276 | Val Loss: 0.333 | Val Acc:  93.51%\n",
      "learning rate: [5.8777777777777745e-06]\n",
      "Epoch 277 | Train Loss: 0.333 | Train Acc:  93.46%\n",
      "Epoch 277 | Val Loss: 0.333 | Val Acc:  93.53%\n",
      "learning rate: [5.37777777777778e-06]\n",
      "Epoch 278 | Train Loss: 0.333 | Train Acc:  93.47%\n",
      "Epoch 278 | Val Loss: 0.333 | Val Acc:  93.51%\n",
      "learning rate: [4.899999999999991e-06]\n",
      "Epoch 279 | Train Loss: 0.334 | Train Acc:  93.50%\n",
      "Epoch 279 | Val Loss: 0.333 | Val Acc:  93.54%\n",
      "learning rate: [4.444444444444441e-06]\n",
      "Epoch 280 | Train Loss: 0.334 | Train Acc:  93.50%\n",
      "Epoch 280 | Val Loss: 0.334 | Val Acc:  93.46%\n",
      "learning rate: [4.011111111111112e-06]\n",
      "Epoch 281 | Train Loss: 0.333 | Train Acc:  93.49%\n",
      "Epoch 281 | Val Loss: 0.333 | Val Acc:  93.49%\n",
      "learning rate: [3.6000000000000045e-06]\n",
      "Epoch 282 | Train Loss: 0.333 | Train Acc:  93.53%\n",
      "Epoch 282 | Val Loss: 0.333 | Val Acc:  93.50%\n",
      "learning rate: [3.2111111111111064e-06]\n",
      "Epoch 283 | Train Loss: 0.333 | Train Acc:  93.51%\n",
      "Epoch 283 | Val Loss: 0.333 | Val Acc:  93.51%\n",
      "learning rate: [2.8444444444444434e-06]\n",
      "Epoch 284 | Train Loss: 0.333 | Train Acc:  93.51%\n",
      "Epoch 284 | Val Loss: 0.333 | Val Acc:  93.52%\n",
      "learning rate: [2.5000000000000023e-06]\n",
      "Epoch 285 | Train Loss: 0.333 | Train Acc:  93.47%\n",
      "Epoch 285 | Val Loss: 0.333 | Val Acc:  93.55%\n",
      "learning rate: [2.177777777777773e-06]\n",
      "Epoch 286 | Train Loss: 0.333 | Train Acc:  93.52%\n",
      "Epoch 286 | Val Loss: 0.333 | Val Acc:  93.50%\n",
      "learning rate: [1.8777777777777766e-06]\n",
      "Epoch 287 | Train Loss: 0.333 | Train Acc:  93.46%\n",
      "Epoch 287 | Val Loss: 0.333 | Val Acc:  93.46%\n",
      "learning rate: [1.6000000000000018e-06]\n",
      "Epoch 288 | Train Loss: 0.333 | Train Acc:  93.49%\n",
      "Epoch 288 | Val Loss: 0.332 | Val Acc:  93.54%\n",
      "learning rate: [1.3444444444444406e-06]\n",
      "Epoch 289 | Train Loss: 0.333 | Train Acc:  93.51%\n",
      "Epoch 289 | Val Loss: 0.332 | Val Acc:  93.50%\n",
      "learning rate: [1.11111111111111e-06]\n",
      "Epoch 290 | Train Loss: 0.333 | Train Acc:  93.52%\n",
      "Epoch 290 | Val Loss: 0.332 | Val Acc:  93.52%\n",
      "learning rate: [9.000000000000011e-07]\n",
      "Epoch 291 | Train Loss: 0.333 | Train Acc:  93.57%\n",
      "Epoch 291 | Val Loss: 0.332 | Val Acc:  93.54%\n",
      "learning rate: [7.11111111111108e-07]\n",
      "Epoch 292 | Train Loss: 0.333 | Train Acc:  93.52%\n",
      "Epoch 292 | Val Loss: 0.333 | Val Acc:  93.50%\n",
      "learning rate: [5.444444444444433e-07]\n",
      "Epoch 293 | Train Loss: 0.333 | Train Acc:  93.49%\n",
      "Epoch 293 | Val Loss: 0.332 | Val Acc:  93.51%\n",
      "learning rate: [4.000000000000004e-07]\n",
      "Epoch 294 | Train Loss: 0.332 | Train Acc:  93.55%\n",
      "Epoch 294 | Val Loss: 0.333 | Val Acc:  93.49%\n",
      "learning rate: [2.7777777777777924e-07]\n",
      "Epoch 295 | Train Loss: 0.332 | Train Acc:  93.51%\n",
      "Epoch 295 | Val Loss: 0.332 | Val Acc:  93.51%\n",
      "learning rate: [1.7777777777777697e-07]\n",
      "Epoch 296 | Train Loss: 0.333 | Train Acc:  93.52%\n",
      "Epoch 296 | Val Loss: 0.332 | Val Acc:  93.53%\n",
      "learning rate: [1.0000000000000011e-07]\n",
      "Epoch 297 | Train Loss: 0.332 | Train Acc:  93.51%\n",
      "Epoch 297 | Val Loss: 0.333 | Val Acc:  93.51%\n",
      "learning rate: [4.444444444444499e-08]\n",
      "Epoch 298 | Train Loss: 0.332 | Train Acc:  93.53%\n",
      "Epoch 298 | Val Loss: 0.332 | Val Acc:  93.51%\n",
      "learning rate: [1.1111111111110877e-08]\n",
      "Epoch 299 | Train Loss: 0.332 | Train Acc:  93.51%\n",
      "Epoch 299 | Val Loss: 0.332 | Val Acc:  93.53%\n",
      "learning rate: [0.0]\n",
      "Epoch 300 | Train Loss: 0.332 | Train Acc:  93.51%\n",
      "Epoch 300 | Val Loss: 0.332 | Val Acc:  93.51%\n",
      "learning rate: [0.0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.optim.lr_scheduler.StepLR'>\n",
      "Epoch   0 | Train Loss: 1.480 | Train Acc:  33.02%\n",
      "Epoch   0 | Val Loss: 1.390 | Val Acc:  38.50%\n",
      "learning rate: [0.001]\n",
      "Epoch   1 | Train Loss: 1.360 | Train Acc:  39.78%\n",
      "Epoch   1 | Val Loss: 1.328 | Val Acc:  41.67%\n",
      "learning rate: [0.001]\n",
      "Epoch   2 | Train Loss: 1.309 | Train Acc:  42.64%\n",
      "Epoch   2 | Val Loss: 1.281 | Val Acc:  44.12%\n",
      "learning rate: [0.001]\n",
      "Epoch   3 | Train Loss: 1.277 | Train Acc:  44.43%\n",
      "Epoch   3 | Val Loss: 1.254 | Val Acc:  45.77%\n",
      "learning rate: [0.001]\n",
      "Epoch   4 | Train Loss: 1.249 | Train Acc:  45.86%\n",
      "Epoch   4 | Val Loss: 1.237 | Val Acc:  46.88%\n",
      "learning rate: [0.001]\n",
      "Epoch   5 | Train Loss: 1.230 | Train Acc:  47.09%\n",
      "Epoch   5 | Val Loss: 1.209 | Val Acc:  48.23%\n",
      "learning rate: [0.001]\n",
      "Epoch   6 | Train Loss: 1.206 | Train Acc:  48.33%\n",
      "Epoch   6 | Val Loss: 1.185 | Val Acc:  49.62%\n",
      "learning rate: [0.001]\n",
      "Epoch   7 | Train Loss: 1.183 | Train Acc:  49.33%\n",
      "Epoch   7 | Val Loss: 1.168 | Val Acc:  50.79%\n",
      "learning rate: [0.001]\n",
      "Epoch   8 | Train Loss: 1.168 | Train Acc:  49.96%\n",
      "Epoch   8 | Val Loss: 1.144 | Val Acc:  51.55%\n",
      "learning rate: [0.001]\n",
      "Epoch   9 | Train Loss: 1.145 | Train Acc:  51.35%\n",
      "Epoch   9 | Val Loss: 1.144 | Val Acc:  51.98%\n",
      "learning rate: [0.001]\n",
      "Epoch  10 | Train Loss: 1.135 | Train Acc:  51.98%\n",
      "Epoch  10 | Val Loss: 1.114 | Val Acc:  52.92%\n",
      "learning rate: [0.001]\n",
      "Epoch  11 | Train Loss: 1.116 | Train Acc:  53.33%\n",
      "Epoch  11 | Val Loss: 1.099 | Val Acc:  54.22%\n",
      "learning rate: [0.001]\n",
      "Epoch  12 | Train Loss: 1.108 | Train Acc:  53.38%\n",
      "Epoch  12 | Val Loss: 1.086 | Val Acc:  54.99%\n",
      "learning rate: [0.001]\n",
      "Epoch  13 | Train Loss: 1.091 | Train Acc:  54.44%\n",
      "Epoch  13 | Val Loss: 1.080 | Val Acc:  55.24%\n",
      "learning rate: [0.001]\n",
      "Epoch  14 | Train Loss: 1.084 | Train Acc:  55.03%\n",
      "Epoch  14 | Val Loss: 1.064 | Val Acc:  56.29%\n",
      "learning rate: [0.001]\n",
      "Epoch  15 | Train Loss: 1.071 | Train Acc:  55.57%\n",
      "Epoch  15 | Val Loss: 1.062 | Val Acc:  56.24%\n",
      "learning rate: [0.001]\n",
      "Epoch  16 | Train Loss: 1.063 | Train Acc:  56.13%\n",
      "Epoch  16 | Val Loss: 1.092 | Val Acc:  54.08%\n",
      "learning rate: [0.001]\n",
      "Epoch  17 | Train Loss: 1.062 | Train Acc:  56.03%\n",
      "Epoch  17 | Val Loss: 1.042 | Val Acc:  57.62%\n",
      "learning rate: [0.001]\n",
      "Epoch  18 | Train Loss: 1.043 | Train Acc:  57.04%\n",
      "Epoch  18 | Val Loss: 1.042 | Val Acc:  57.88%\n",
      "learning rate: [0.001]\n",
      "Epoch  19 | Train Loss: 1.042 | Train Acc:  57.27%\n",
      "Epoch  19 | Val Loss: 1.016 | Val Acc:  59.07%\n",
      "learning rate: [0.001]\n",
      "Epoch  20 | Train Loss: 1.043 | Train Acc:  57.11%\n",
      "Epoch  20 | Val Loss: 1.029 | Val Acc:  58.01%\n",
      "learning rate: [0.001]\n",
      "Epoch  21 | Train Loss: 1.023 | Train Acc:  58.13%\n",
      "Epoch  21 | Val Loss: 1.007 | Val Acc:  59.53%\n",
      "learning rate: [0.001]\n",
      "Epoch  22 | Train Loss: 1.014 | Train Acc:  58.81%\n",
      "Epoch  22 | Val Loss: 0.992 | Val Acc:  60.08%\n",
      "learning rate: [0.001]\n",
      "Epoch  23 | Train Loss: 1.004 | Train Acc:  59.20%\n",
      "Epoch  23 | Val Loss: 0.987 | Val Acc:  60.77%\n",
      "learning rate: [0.001]\n",
      "Epoch  24 | Train Loss: 0.997 | Train Acc:  59.77%\n",
      "Epoch  24 | Val Loss: 0.979 | Val Acc:  60.75%\n",
      "learning rate: [0.001]\n",
      "Epoch  25 | Train Loss: 1.003 | Train Acc:  58.98%\n",
      "Epoch  25 | Val Loss: 0.997 | Val Acc:  60.02%\n",
      "learning rate: [0.001]\n",
      "Epoch  26 | Train Loss: 0.988 | Train Acc:  60.16%\n",
      "Epoch  26 | Val Loss: 0.960 | Val Acc:  61.86%\n",
      "learning rate: [0.001]\n",
      "Epoch  27 | Train Loss: 0.979 | Train Acc:  60.66%\n",
      "Epoch  27 | Val Loss: 0.963 | Val Acc:  61.89%\n",
      "learning rate: [0.001]\n",
      "Epoch  28 | Train Loss: 0.974 | Train Acc:  60.53%\n",
      "Epoch  28 | Val Loss: 0.951 | Val Acc:  62.12%\n",
      "learning rate: [0.001]\n",
      "Epoch  29 | Train Loss: 0.964 | Train Acc:  61.38%\n",
      "Epoch  29 | Val Loss: 1.025 | Val Acc:  58.19%\n",
      "learning rate: [0.001]\n",
      "Epoch  30 | Train Loss: 0.963 | Train Acc:  61.32%\n",
      "Epoch  30 | Val Loss: 0.969 | Val Acc:  61.64%\n",
      "learning rate: [0.001]\n",
      "Epoch  31 | Train Loss: 0.950 | Train Acc:  62.08%\n",
      "Epoch  31 | Val Loss: 0.935 | Val Acc:  62.81%\n",
      "learning rate: [0.001]\n",
      "Epoch  32 | Train Loss: 0.943 | Train Acc:  62.43%\n",
      "Epoch  32 | Val Loss: 0.919 | Val Acc:  64.36%\n",
      "learning rate: [0.001]\n",
      "Epoch  33 | Train Loss: 0.929 | Train Acc:  63.20%\n",
      "Epoch  33 | Val Loss: 0.922 | Val Acc:  62.98%\n",
      "learning rate: [0.001]\n",
      "Epoch  34 | Train Loss: 0.932 | Train Acc:  62.67%\n",
      "Epoch  34 | Val Loss: 0.915 | Val Acc:  63.93%\n",
      "learning rate: [0.001]\n",
      "Epoch  35 | Train Loss: 0.918 | Train Acc:  63.73%\n",
      "Epoch  35 | Val Loss: 0.932 | Val Acc:  63.16%\n",
      "learning rate: [0.001]\n",
      "Epoch  36 | Train Loss: 0.925 | Train Acc:  63.10%\n",
      "Epoch  36 | Val Loss: 0.892 | Val Acc:  64.75%\n",
      "learning rate: [0.001]\n",
      "Epoch  37 | Train Loss: 0.903 | Train Acc:  64.77%\n",
      "Epoch  37 | Val Loss: 0.879 | Val Acc:  65.67%\n",
      "learning rate: [0.001]\n",
      "Epoch  38 | Train Loss: 0.894 | Train Acc:  64.77%\n",
      "Epoch  38 | Val Loss: 0.887 | Val Acc:  65.59%\n",
      "learning rate: [0.001]\n",
      "Epoch  39 | Train Loss: 0.888 | Train Acc:  64.87%\n",
      "Epoch  39 | Val Loss: 0.862 | Val Acc:  66.58%\n",
      "learning rate: [0.001]\n",
      "Epoch  40 | Train Loss: 0.885 | Train Acc:  65.24%\n",
      "Epoch  40 | Val Loss: 0.879 | Val Acc:  65.12%\n",
      "learning rate: [0.001]\n",
      "Epoch  41 | Train Loss: 0.871 | Train Acc:  65.90%\n",
      "Epoch  41 | Val Loss: 0.850 | Val Acc:  67.08%\n",
      "learning rate: [0.001]\n",
      "Epoch  42 | Train Loss: 0.865 | Train Acc:  66.35%\n",
      "Epoch  42 | Val Loss: 0.856 | Val Acc:  66.54%\n",
      "learning rate: [0.001]\n",
      "Epoch  43 | Train Loss: 0.872 | Train Acc:  65.78%\n",
      "Epoch  43 | Val Loss: 0.934 | Val Acc:  61.51%\n",
      "learning rate: [0.001]\n",
      "Epoch  44 | Train Loss: 0.850 | Train Acc:  66.92%\n",
      "Epoch  44 | Val Loss: 0.828 | Val Acc:  68.25%\n",
      "learning rate: [0.001]\n",
      "Epoch  45 | Train Loss: 0.843 | Train Acc:  67.42%\n",
      "Epoch  45 | Val Loss: 0.814 | Val Acc:  68.83%\n",
      "learning rate: [0.001]\n",
      "Epoch  46 | Train Loss: 0.838 | Train Acc:  67.48%\n",
      "Epoch  46 | Val Loss: 0.819 | Val Acc:  68.59%\n",
      "learning rate: [0.001]\n",
      "Epoch  47 | Train Loss: 0.836 | Train Acc:  67.58%\n",
      "Epoch  47 | Val Loss: 0.794 | Val Acc:  70.07%\n",
      "learning rate: [0.001]\n",
      "Epoch  48 | Train Loss: 0.818 | Train Acc:  68.59%\n",
      "Epoch  48 | Val Loss: 0.797 | Val Acc:  69.08%\n",
      "learning rate: [0.001]\n",
      "Epoch  49 | Train Loss: 0.818 | Train Acc:  68.45%\n",
      "Epoch  49 | Val Loss: 0.788 | Val Acc:  70.00%\n",
      "learning rate: [0.001]\n",
      "Epoch  50 | Train Loss: 0.809 | Train Acc:  68.87%\n",
      "Epoch  50 | Val Loss: 0.782 | Val Acc:  70.67%\n",
      "learning rate: [0.001]\n",
      "Epoch  51 | Train Loss: 0.798 | Train Acc:  69.42%\n",
      "Epoch  51 | Val Loss: 0.779 | Val Acc:  70.21%\n",
      "learning rate: [0.001]\n",
      "Epoch  52 | Train Loss: 0.790 | Train Acc:  69.80%\n",
      "Epoch  52 | Val Loss: 0.828 | Val Acc:  67.16%\n",
      "learning rate: [0.001]\n",
      "Epoch  53 | Train Loss: 0.796 | Train Acc:  69.48%\n",
      "Epoch  53 | Val Loss: 0.752 | Val Acc:  72.24%\n",
      "learning rate: [0.001]\n",
      "Epoch  54 | Train Loss: 0.782 | Train Acc:  70.40%\n",
      "Epoch  54 | Val Loss: 0.761 | Val Acc:  70.90%\n",
      "learning rate: [0.001]\n",
      "Epoch  55 | Train Loss: 0.768 | Train Acc:  70.73%\n",
      "Epoch  55 | Val Loss: 0.733 | Val Acc:  73.11%\n",
      "learning rate: [0.001]\n",
      "Epoch  56 | Train Loss: 0.756 | Train Acc:  71.41%\n",
      "Epoch  56 | Val Loss: 0.740 | Val Acc:  72.21%\n",
      "learning rate: [0.001]\n",
      "Epoch  57 | Train Loss: 0.765 | Train Acc:  70.91%\n",
      "Epoch  57 | Val Loss: 0.832 | Val Acc:  66.42%\n",
      "learning rate: [0.001]\n",
      "Epoch  58 | Train Loss: 0.763 | Train Acc:  70.70%\n",
      "Epoch  58 | Val Loss: 0.764 | Val Acc:  70.64%\n",
      "learning rate: [0.001]\n",
      "Epoch  59 | Train Loss: 0.739 | Train Acc:  72.13%\n",
      "Epoch  59 | Val Loss: 0.711 | Val Acc:  74.03%\n",
      "learning rate: [0.001]\n",
      "Epoch  60 | Train Loss: 0.731 | Train Acc:  72.51%\n",
      "Epoch  60 | Val Loss: 0.723 | Val Acc:  72.85%\n",
      "learning rate: [0.001]\n",
      "Epoch  61 | Train Loss: 0.722 | Train Acc:  72.98%\n",
      "Epoch  61 | Val Loss: 0.704 | Val Acc:  73.85%\n",
      "learning rate: [0.001]\n",
      "Epoch  62 | Train Loss: 0.734 | Train Acc:  72.55%\n",
      "Epoch  62 | Val Loss: 0.709 | Val Acc:  73.29%\n",
      "learning rate: [0.001]\n",
      "Epoch  63 | Train Loss: 0.710 | Train Acc:  73.45%\n",
      "Epoch  63 | Val Loss: 0.690 | Val Acc:  74.42%\n",
      "learning rate: [0.001]\n",
      "Epoch  64 | Train Loss: 0.703 | Train Acc:  74.02%\n",
      "Epoch  64 | Val Loss: 0.691 | Val Acc:  74.48%\n",
      "learning rate: [0.001]\n",
      "Epoch  65 | Train Loss: 0.701 | Train Acc:  73.70%\n",
      "Epoch  65 | Val Loss: 0.683 | Val Acc:  74.52%\n",
      "learning rate: [0.001]\n",
      "Epoch  66 | Train Loss: 0.690 | Train Acc:  74.29%\n",
      "Epoch  66 | Val Loss: 0.671 | Val Acc:  75.62%\n",
      "learning rate: [0.001]\n",
      "Epoch  67 | Train Loss: 0.677 | Train Acc:  75.08%\n",
      "Epoch  67 | Val Loss: 0.686 | Val Acc:  74.53%\n",
      "learning rate: [0.001]\n",
      "Epoch  68 | Train Loss: 0.679 | Train Acc:  75.20%\n",
      "Epoch  68 | Val Loss: 0.655 | Val Acc:  76.06%\n",
      "learning rate: [0.001]\n",
      "Epoch  69 | Train Loss: 0.678 | Train Acc:  75.03%\n",
      "Epoch  69 | Val Loss: 0.640 | Val Acc:  77.35%\n",
      "learning rate: [0.001]\n",
      "Epoch  70 | Train Loss: 0.664 | Train Acc:  75.74%\n",
      "Epoch  70 | Val Loss: 0.667 | Val Acc:  74.95%\n",
      "learning rate: [0.001]\n",
      "Epoch  71 | Train Loss: 0.646 | Train Acc:  76.89%\n",
      "Epoch  71 | Val Loss: 0.637 | Val Acc:  77.19%\n",
      "learning rate: [0.001]\n",
      "Epoch  72 | Train Loss: 0.642 | Train Acc:  76.90%\n",
      "Epoch  72 | Val Loss: 0.603 | Val Acc:  79.29%\n",
      "learning rate: [0.001]\n",
      "Epoch  73 | Train Loss: 0.641 | Train Acc:  76.72%\n",
      "Epoch  73 | Val Loss: 0.612 | Val Acc:  78.53%\n",
      "learning rate: [0.001]\n",
      "Epoch  74 | Train Loss: 0.647 | Train Acc:  76.46%\n",
      "Epoch  74 | Val Loss: 0.657 | Val Acc:  75.41%\n",
      "learning rate: [0.001]\n",
      "Epoch  75 | Train Loss: 0.627 | Train Acc:  77.21%\n",
      "Epoch  75 | Val Loss: 0.716 | Val Acc:  71.71%\n",
      "learning rate: [0.001]\n",
      "Epoch  76 | Train Loss: 0.616 | Train Acc:  77.89%\n",
      "Epoch  76 | Val Loss: 0.593 | Val Acc:  79.11%\n",
      "learning rate: [0.001]\n",
      "Epoch  77 | Train Loss: 0.610 | Train Acc:  78.26%\n",
      "Epoch  77 | Val Loss: 0.586 | Val Acc:  79.57%\n",
      "learning rate: [0.001]\n",
      "Epoch  78 | Train Loss: 0.603 | Train Acc:  78.47%\n",
      "Epoch  78 | Val Loss: 0.591 | Val Acc:  79.71%\n",
      "learning rate: [0.001]\n",
      "Epoch  79 | Train Loss: 0.595 | Train Acc:  79.07%\n",
      "Epoch  79 | Val Loss: 0.558 | Val Acc:  81.25%\n",
      "learning rate: [0.001]\n",
      "Epoch  80 | Train Loss: 0.583 | Train Acc:  79.94%\n",
      "Epoch  80 | Val Loss: 0.577 | Val Acc:  79.87%\n",
      "learning rate: [0.001]\n",
      "Epoch  81 | Train Loss: 0.587 | Train Acc:  79.14%\n",
      "Epoch  81 | Val Loss: 0.592 | Val Acc:  78.76%\n",
      "learning rate: [0.001]\n",
      "Epoch  82 | Train Loss: 0.588 | Train Acc:  79.23%\n",
      "Epoch  82 | Val Loss: 0.585 | Val Acc:  79.25%\n",
      "learning rate: [0.001]\n",
      "Epoch  83 | Train Loss: 0.566 | Train Acc:  80.27%\n",
      "Epoch  83 | Val Loss: 0.530 | Val Acc:  82.86%\n",
      "learning rate: [0.001]\n",
      "Epoch  84 | Train Loss: 0.552 | Train Acc:  81.48%\n",
      "Epoch  84 | Val Loss: 0.520 | Val Acc:  82.97%\n",
      "learning rate: [0.001]\n",
      "Epoch  85 | Train Loss: 0.564 | Train Acc:  80.57%\n",
      "Epoch  85 | Val Loss: 0.514 | Val Acc:  83.49%\n",
      "learning rate: [0.001]\n",
      "Epoch  86 | Train Loss: 0.554 | Train Acc:  80.86%\n",
      "Epoch  86 | Val Loss: 0.520 | Val Acc:  82.92%\n",
      "learning rate: [0.001]\n",
      "Epoch  87 | Train Loss: 0.545 | Train Acc:  81.31%\n",
      "Epoch  87 | Val Loss: 0.560 | Val Acc:  80.22%\n",
      "learning rate: [0.001]\n",
      "Epoch  88 | Train Loss: 0.530 | Train Acc:  82.52%\n",
      "Epoch  88 | Val Loss: 0.500 | Val Acc:  83.87%\n",
      "learning rate: [0.001]\n",
      "Epoch  89 | Train Loss: 0.527 | Train Acc:  82.42%\n",
      "Epoch  89 | Val Loss: 0.490 | Val Acc:  84.65%\n",
      "learning rate: [0.001]\n",
      "Epoch  90 | Train Loss: 0.521 | Train Acc:  82.53%\n",
      "Epoch  90 | Val Loss: 0.483 | Val Acc:  85.26%\n",
      "learning rate: [0.001]\n",
      "Epoch  91 | Train Loss: 0.516 | Train Acc:  82.64%\n",
      "Epoch  91 | Val Loss: 0.489 | Val Acc:  84.09%\n",
      "learning rate: [0.001]\n",
      "Epoch  92 | Train Loss: 0.503 | Train Acc:  83.69%\n",
      "Epoch  92 | Val Loss: 0.473 | Val Acc:  85.31%\n",
      "learning rate: [0.001]\n",
      "Epoch  93 | Train Loss: 0.506 | Train Acc:  83.26%\n",
      "Epoch  93 | Val Loss: 0.454 | Val Acc:  86.91%\n",
      "learning rate: [0.001]\n",
      "Epoch  94 | Train Loss: 0.496 | Train Acc:  83.85%\n",
      "Epoch  94 | Val Loss: 0.466 | Val Acc:  85.49%\n",
      "learning rate: [0.001]\n",
      "Epoch  95 | Train Loss: 0.490 | Train Acc:  84.10%\n",
      "Epoch  95 | Val Loss: 0.463 | Val Acc:  85.53%\n",
      "learning rate: [0.001]\n",
      "Epoch  96 | Train Loss: 0.497 | Train Acc:  83.92%\n",
      "Epoch  96 | Val Loss: 0.454 | Val Acc:  86.27%\n",
      "learning rate: [0.001]\n",
      "Epoch  97 | Train Loss: 0.474 | Train Acc:  84.94%\n",
      "Epoch  97 | Val Loss: 0.464 | Val Acc:  85.50%\n",
      "learning rate: [0.001]\n",
      "Epoch  98 | Train Loss: 0.467 | Train Acc:  85.23%\n",
      "Epoch  98 | Val Loss: 0.426 | Val Acc:  88.06%\n",
      "learning rate: [0.001]\n",
      "Epoch  99 | Train Loss: 0.453 | Train Acc:  86.20%\n",
      "Epoch  99 | Val Loss: 0.446 | Val Acc:  86.33%\n",
      "learning rate: [0.0005]\n",
      "Epoch 100 | Train Loss: 0.432 | Train Acc:  87.46%\n",
      "Epoch 100 | Val Loss: 0.415 | Val Acc:  88.68%\n",
      "learning rate: [0.0005]\n",
      "Epoch 101 | Train Loss: 0.418 | Train Acc:  88.53%\n",
      "Epoch 101 | Val Loss: 0.428 | Val Acc:  87.41%\n",
      "learning rate: [0.0005]\n",
      "Epoch 102 | Train Loss: 0.418 | Train Acc:  88.17%\n",
      "Epoch 102 | Val Loss: 0.414 | Val Acc:  88.31%\n",
      "learning rate: [0.0005]\n",
      "Epoch 103 | Train Loss: 0.413 | Train Acc:  88.63%\n",
      "Epoch 103 | Val Loss: 0.388 | Val Acc:  90.48%\n",
      "learning rate: [0.0005]\n",
      "Epoch 104 | Train Loss: 0.411 | Train Acc:  88.78%\n",
      "Epoch 104 | Val Loss: 0.394 | Val Acc:  89.90%\n",
      "learning rate: [0.0005]\n",
      "Epoch 105 | Train Loss: 0.409 | Train Acc:  88.72%\n",
      "Epoch 105 | Val Loss: 0.386 | Val Acc:  90.27%\n",
      "learning rate: [0.0005]\n",
      "Epoch 106 | Train Loss: 0.409 | Train Acc:  88.50%\n",
      "Epoch 106 | Val Loss: 0.386 | Val Acc:  90.31%\n",
      "learning rate: [0.0005]\n",
      "Epoch 107 | Train Loss: 0.398 | Train Acc:  89.24%\n",
      "Epoch 107 | Val Loss: 0.401 | Val Acc:  88.83%\n",
      "learning rate: [0.0005]\n",
      "Epoch 108 | Train Loss: 0.394 | Train Acc:  89.32%\n",
      "Epoch 108 | Val Loss: 0.387 | Val Acc:  89.71%\n",
      "learning rate: [0.0005]\n",
      "Epoch 109 | Train Loss: 0.394 | Train Acc:  89.25%\n",
      "Epoch 109 | Val Loss: 0.400 | Val Acc:  88.55%\n",
      "learning rate: [0.0005]\n",
      "Epoch 110 | Train Loss: 0.390 | Train Acc:  89.73%\n",
      "Epoch 110 | Val Loss: 0.395 | Val Acc:  89.25%\n",
      "learning rate: [0.0005]\n",
      "Epoch 111 | Train Loss: 0.390 | Train Acc:  89.59%\n",
      "Epoch 111 | Val Loss: 0.373 | Val Acc:  90.53%\n",
      "learning rate: [0.0005]\n",
      "Epoch 112 | Train Loss: 0.378 | Train Acc:  90.38%\n",
      "Epoch 112 | Val Loss: 0.366 | Val Acc:  91.15%\n",
      "learning rate: [0.0005]\n",
      "Epoch 113 | Train Loss: 0.374 | Train Acc:  90.60%\n",
      "Epoch 113 | Val Loss: 0.355 | Val Acc:  91.95%\n",
      "learning rate: [0.0005]\n",
      "Epoch 114 | Train Loss: 0.374 | Train Acc:  90.57%\n",
      "Epoch 114 | Val Loss: 0.353 | Val Acc:  91.83%\n",
      "learning rate: [0.0005]\n",
      "Epoch 115 | Train Loss: 0.369 | Train Acc:  90.70%\n",
      "Epoch 115 | Val Loss: 0.346 | Val Acc:  92.39%\n",
      "learning rate: [0.0005]\n",
      "Epoch 116 | Train Loss: 0.373 | Train Acc:  90.57%\n",
      "Epoch 116 | Val Loss: 0.368 | Val Acc:  90.30%\n",
      "learning rate: [0.0005]\n",
      "Epoch 117 | Train Loss: 0.364 | Train Acc:  91.15%\n",
      "Epoch 117 | Val Loss: 0.359 | Val Acc:  91.08%\n",
      "learning rate: [0.0005]\n",
      "Epoch 118 | Train Loss: 0.369 | Train Acc:  90.42%\n",
      "Epoch 118 | Val Loss: 0.359 | Val Acc:  90.85%\n",
      "learning rate: [0.0005]\n",
      "Epoch 119 | Train Loss: 0.352 | Train Acc:  91.82%\n",
      "Epoch 119 | Val Loss: 0.348 | Val Acc:  91.81%\n",
      "learning rate: [0.0005]\n",
      "Epoch 120 | Train Loss: 0.355 | Train Acc:  91.42%\n",
      "Epoch 120 | Val Loss: 0.340 | Val Acc:  92.56%\n",
      "learning rate: [0.0005]\n",
      "Epoch 121 | Train Loss: 0.344 | Train Acc:  92.31%\n",
      "Epoch 121 | Val Loss: 0.337 | Val Acc:  92.65%\n",
      "learning rate: [0.0005]\n",
      "Epoch 122 | Train Loss: 0.345 | Train Acc:  91.98%\n",
      "Epoch 122 | Val Loss: 0.335 | Val Acc:  92.54%\n",
      "learning rate: [0.0005]\n",
      "Epoch 123 | Train Loss: 0.339 | Train Acc:  92.42%\n",
      "Epoch 123 | Val Loss: 0.326 | Val Acc:  93.01%\n",
      "learning rate: [0.0005]\n",
      "Epoch 124 | Train Loss: 0.343 | Train Acc:  92.08%\n",
      "Epoch 124 | Val Loss: 0.317 | Val Acc:  93.93%\n",
      "learning rate: [0.0005]\n",
      "Epoch 125 | Train Loss: 0.330 | Train Acc:  93.02%\n",
      "Epoch 125 | Val Loss: 0.337 | Val Acc:  92.44%\n",
      "learning rate: [0.0005]\n",
      "Epoch 126 | Train Loss: 0.329 | Train Acc:  93.00%\n",
      "Epoch 126 | Val Loss: 0.319 | Val Acc:  93.86%\n",
      "learning rate: [0.0005]\n",
      "Epoch 127 | Train Loss: 0.330 | Train Acc:  92.70%\n",
      "Epoch 127 | Val Loss: 0.316 | Val Acc:  93.69%\n",
      "learning rate: [0.0005]\n",
      "Epoch 128 | Train Loss: 0.325 | Train Acc:  93.08%\n",
      "Epoch 128 | Val Loss: 0.334 | Val Acc:  92.15%\n",
      "learning rate: [0.0005]\n",
      "Epoch 129 | Train Loss: 0.321 | Train Acc:  93.31%\n",
      "Epoch 129 | Val Loss: 0.311 | Val Acc:  94.13%\n",
      "learning rate: [0.0005]\n",
      "Epoch 130 | Train Loss: 0.317 | Train Acc:  93.59%\n",
      "Epoch 130 | Val Loss: 0.309 | Val Acc:  94.15%\n",
      "learning rate: [0.0005]\n",
      "Epoch 131 | Train Loss: 0.316 | Train Acc:  93.68%\n",
      "Epoch 131 | Val Loss: 0.307 | Val Acc:  93.78%\n",
      "learning rate: [0.0005]\n",
      "Epoch 132 | Train Loss: 0.312 | Train Acc:  93.80%\n",
      "Epoch 132 | Val Loss: 0.293 | Val Acc:  95.33%\n",
      "learning rate: [0.0005]\n",
      "Epoch 133 | Train Loss: 0.310 | Train Acc:  93.79%\n",
      "Epoch 133 | Val Loss: 0.321 | Val Acc:  93.07%\n",
      "learning rate: [0.0005]\n",
      "Epoch 134 | Train Loss: 0.305 | Train Acc:  94.21%\n",
      "Epoch 134 | Val Loss: 0.288 | Val Acc:  95.34%\n",
      "learning rate: [0.0005]\n",
      "Epoch 135 | Train Loss: 0.310 | Train Acc:  93.83%\n",
      "Epoch 135 | Val Loss: 0.300 | Val Acc:  94.42%\n",
      "learning rate: [0.0005]\n",
      "Epoch 136 | Train Loss: 0.295 | Train Acc:  94.81%\n",
      "Epoch 136 | Val Loss: 0.290 | Val Acc:  94.90%\n",
      "learning rate: [0.0005]\n",
      "Epoch 137 | Train Loss: 0.297 | Train Acc:  94.44%\n",
      "Epoch 137 | Val Loss: 0.277 | Val Acc:  95.72%\n",
      "learning rate: [0.0005]\n",
      "Epoch 138 | Train Loss: 0.292 | Train Acc:  94.84%\n",
      "Epoch 138 | Val Loss: 0.298 | Val Acc:  94.24%\n",
      "learning rate: [0.0005]\n",
      "Epoch 139 | Train Loss: 0.296 | Train Acc:  94.54%\n",
      "Epoch 139 | Val Loss: 0.298 | Val Acc:  94.41%\n",
      "learning rate: [0.0005]\n",
      "Epoch 140 | Train Loss: 0.289 | Train Acc:  94.98%\n",
      "Epoch 140 | Val Loss: 0.272 | Val Acc:  96.13%\n",
      "learning rate: [0.0005]\n",
      "Epoch 141 | Train Loss: 0.286 | Train Acc:  95.08%\n",
      "Epoch 141 | Val Loss: 0.279 | Val Acc:  95.67%\n",
      "learning rate: [0.0005]\n",
      "Epoch 142 | Train Loss: 0.285 | Train Acc:  95.23%\n",
      "Epoch 142 | Val Loss: 0.268 | Val Acc:  96.12%\n",
      "learning rate: [0.0005]\n",
      "Epoch 143 | Train Loss: 0.279 | Train Acc:  95.48%\n",
      "Epoch 143 | Val Loss: 0.282 | Val Acc:  95.16%\n",
      "learning rate: [0.0005]\n",
      "Epoch 144 | Train Loss: 0.281 | Train Acc:  95.43%\n",
      "Epoch 144 | Val Loss: 0.272 | Val Acc:  95.84%\n",
      "learning rate: [0.0005]\n",
      "Epoch 145 | Train Loss: 0.277 | Train Acc:  95.61%\n",
      "Epoch 145 | Val Loss: 0.269 | Val Acc:  96.12%\n",
      "learning rate: [0.0005]\n",
      "Epoch 146 | Train Loss: 0.275 | Train Acc:  95.53%\n",
      "Epoch 146 | Val Loss: 0.256 | Val Acc:  96.95%\n",
      "learning rate: [0.0005]\n",
      "Epoch 147 | Train Loss: 0.274 | Train Acc:  95.61%\n",
      "Epoch 147 | Val Loss: 0.250 | Val Acc:  97.37%\n",
      "learning rate: [0.0005]\n",
      "Epoch 148 | Train Loss: 0.264 | Train Acc:  96.31%\n",
      "Epoch 148 | Val Loss: 0.248 | Val Acc:  97.48%\n",
      "learning rate: [0.0005]\n",
      "Epoch 149 | Train Loss: 0.265 | Train Acc:  96.26%\n",
      "Epoch 149 | Val Loss: 0.299 | Val Acc:  93.56%\n",
      "learning rate: [0.0005]\n",
      "Epoch 150 | Train Loss: 0.269 | Train Acc:  95.86%\n",
      "Epoch 150 | Val Loss: 0.241 | Val Acc:  97.75%\n",
      "learning rate: [0.0005]\n",
      "Epoch 151 | Train Loss: 0.258 | Train Acc:  96.64%\n",
      "Epoch 151 | Val Loss: 0.263 | Val Acc:  96.12%\n",
      "learning rate: [0.0005]\n",
      "Epoch 152 | Train Loss: 0.262 | Train Acc:  96.38%\n",
      "Epoch 152 | Val Loss: 0.255 | Val Acc:  96.81%\n",
      "learning rate: [0.0005]\n",
      "Epoch 153 | Train Loss: 0.260 | Train Acc:  96.46%\n",
      "Epoch 153 | Val Loss: 0.275 | Val Acc:  95.30%\n",
      "learning rate: [0.0005]\n",
      "Epoch 154 | Train Loss: 0.252 | Train Acc:  96.95%\n",
      "Epoch 154 | Val Loss: 0.241 | Val Acc:  97.74%\n",
      "learning rate: [0.0005]\n",
      "Epoch 155 | Train Loss: 0.249 | Train Acc:  97.15%\n",
      "Epoch 155 | Val Loss: 0.242 | Val Acc:  97.49%\n",
      "learning rate: [0.0005]\n",
      "Epoch 156 | Train Loss: 0.247 | Train Acc:  97.24%\n",
      "Epoch 156 | Val Loss: 0.252 | Val Acc:  96.86%\n",
      "learning rate: [0.0005]\n",
      "Epoch 157 | Train Loss: 0.243 | Train Acc:  97.41%\n",
      "Epoch 157 | Val Loss: 0.227 | Val Acc:  98.30%\n",
      "learning rate: [0.0005]\n",
      "Epoch 158 | Train Loss: 0.244 | Train Acc:  97.39%\n",
      "Epoch 158 | Val Loss: 0.238 | Val Acc:  97.83%\n",
      "learning rate: [0.0005]\n",
      "Epoch 159 | Train Loss: 0.261 | Train Acc:  95.99%\n",
      "Epoch 159 | Val Loss: 0.270 | Val Acc:  95.51%\n",
      "learning rate: [0.0005]\n",
      "Epoch 160 | Train Loss: 0.245 | Train Acc:  97.24%\n",
      "Epoch 160 | Val Loss: 0.238 | Val Acc:  97.59%\n",
      "learning rate: [0.0005]\n",
      "Epoch 161 | Train Loss: 0.240 | Train Acc:  97.53%\n",
      "Epoch 161 | Val Loss: 0.240 | Val Acc:  97.50%\n",
      "learning rate: [0.0005]\n",
      "Epoch 162 | Train Loss: 0.236 | Train Acc:  97.78%\n",
      "Epoch 162 | Val Loss: 0.228 | Val Acc:  98.15%\n",
      "learning rate: [0.0005]\n",
      "Epoch 163 | Train Loss: 0.236 | Train Acc:  97.81%\n",
      "Epoch 163 | Val Loss: 0.242 | Val Acc:  97.17%\n",
      "learning rate: [0.0005]\n",
      "Epoch 164 | Train Loss: 0.234 | Train Acc:  97.75%\n",
      "Epoch 164 | Val Loss: 0.218 | Val Acc:  98.68%\n",
      "learning rate: [0.0005]\n",
      "Epoch 165 | Train Loss: 0.228 | Train Acc:  98.15%\n",
      "Epoch 165 | Val Loss: 0.220 | Val Acc:  98.61%\n",
      "learning rate: [0.0005]\n",
      "Epoch 166 | Train Loss: 0.228 | Train Acc:  98.19%\n",
      "Epoch 166 | Val Loss: 0.214 | Val Acc:  98.92%\n",
      "learning rate: [0.0005]\n",
      "Epoch 167 | Train Loss: 0.223 | Train Acc:  98.55%\n",
      "Epoch 167 | Val Loss: 0.231 | Val Acc:  97.89%\n",
      "learning rate: [0.0005]\n",
      "Epoch 168 | Train Loss: 0.223 | Train Acc:  98.45%\n",
      "Epoch 168 | Val Loss: 0.216 | Val Acc:  98.64%\n",
      "learning rate: [0.0005]\n",
      "Epoch 169 | Train Loss: 0.218 | Train Acc:  98.71%\n",
      "Epoch 169 | Val Loss: 0.208 | Val Acc:  99.16%\n",
      "learning rate: [0.0005]\n",
      "Epoch 170 | Train Loss: 0.218 | Train Acc:  98.70%\n",
      "Epoch 170 | Val Loss: 0.219 | Val Acc:  98.57%\n",
      "learning rate: [0.0005]\n",
      "Epoch 171 | Train Loss: 0.219 | Train Acc:  98.60%\n",
      "Epoch 171 | Val Loss: 0.208 | Val Acc:  99.01%\n",
      "learning rate: [0.0005]\n",
      "Epoch 172 | Train Loss: 0.220 | Train Acc:  98.59%\n",
      "Epoch 172 | Val Loss: 0.224 | Val Acc:  98.36%\n",
      "learning rate: [0.0005]\n",
      "Epoch 173 | Train Loss: 0.216 | Train Acc:  98.69%\n",
      "Epoch 173 | Val Loss: 0.217 | Val Acc:  98.75%\n",
      "learning rate: [0.0005]\n",
      "Epoch 174 | Train Loss: 0.215 | Train Acc:  98.80%\n",
      "Epoch 174 | Val Loss: 0.208 | Val Acc:  99.16%\n",
      "learning rate: [0.0005]\n",
      "Epoch 175 | Train Loss: 0.210 | Train Acc:  99.04%\n",
      "Epoch 175 | Val Loss: 0.209 | Val Acc:  99.13%\n",
      "learning rate: [0.0005]\n",
      "Epoch 176 | Train Loss: 0.213 | Train Acc:  98.89%\n",
      "Epoch 176 | Val Loss: 0.206 | Val Acc:  98.97%\n",
      "learning rate: [0.0005]\n",
      "Epoch 177 | Train Loss: 0.215 | Train Acc:  98.71%\n",
      "Epoch 177 | Val Loss: 0.206 | Val Acc:  99.17%\n",
      "learning rate: [0.0005]\n",
      "Epoch 178 | Train Loss: 0.214 | Train Acc:  98.80%\n",
      "Epoch 178 | Val Loss: 0.198 | Val Acc:  99.49%\n",
      "learning rate: [0.0005]\n",
      "Epoch 179 | Train Loss: 0.206 | Train Acc:  99.15%\n",
      "Epoch 179 | Val Loss: 0.195 | Val Acc:  99.61%\n",
      "learning rate: [0.0005]\n",
      "Epoch 180 | Train Loss: 0.203 | Train Acc:  99.31%\n",
      "Epoch 180 | Val Loss: 0.200 | Val Acc:  99.50%\n",
      "learning rate: [0.0005]\n",
      "Epoch 181 | Train Loss: 0.207 | Train Acc:  99.21%\n",
      "Epoch 181 | Val Loss: 0.206 | Val Acc:  99.08%\n",
      "learning rate: [0.0005]\n",
      "Epoch 182 | Train Loss: 0.206 | Train Acc:  99.10%\n",
      "Epoch 182 | Val Loss: 0.197 | Val Acc:  99.57%\n",
      "learning rate: [0.0005]\n",
      "Epoch 183 | Train Loss: 0.201 | Train Acc:  99.35%\n",
      "Epoch 183 | Val Loss: 0.201 | Val Acc:  99.41%\n",
      "learning rate: [0.0005]\n",
      "Epoch 184 | Train Loss: 0.203 | Train Acc:  99.28%\n",
      "Epoch 184 | Val Loss: 0.193 | Val Acc:  99.61%\n",
      "learning rate: [0.0005]\n",
      "Epoch 185 | Train Loss: 0.201 | Train Acc:  99.32%\n",
      "Epoch 185 | Val Loss: 0.190 | Val Acc:  99.71%\n",
      "learning rate: [0.0005]\n",
      "Epoch 186 | Train Loss: 0.200 | Train Acc:  99.35%\n",
      "Epoch 186 | Val Loss: 0.192 | Val Acc:  99.60%\n",
      "learning rate: [0.0005]\n",
      "Epoch 187 | Train Loss: 0.194 | Train Acc:  99.61%\n",
      "Epoch 187 | Val Loss: 0.189 | Val Acc:  99.74%\n",
      "learning rate: [0.0005]\n",
      "Epoch 188 | Train Loss: 0.201 | Train Acc:  99.28%\n",
      "Epoch 188 | Val Loss: 0.187 | Val Acc:  99.74%\n",
      "learning rate: [0.0005]\n",
      "Epoch 189 | Train Loss: 0.197 | Train Acc:  99.41%\n",
      "Epoch 189 | Val Loss: 0.187 | Val Acc:  99.76%\n",
      "learning rate: [0.0005]\n",
      "Epoch 190 | Train Loss: 0.195 | Train Acc:  99.58%\n",
      "Epoch 190 | Val Loss: 0.189 | Val Acc:  99.67%\n",
      "learning rate: [0.0005]\n",
      "Epoch 191 | Train Loss: 0.195 | Train Acc:  99.47%\n",
      "Epoch 191 | Val Loss: 0.204 | Val Acc:  99.24%\n",
      "learning rate: [0.0005]\n",
      "Epoch 192 | Train Loss: 0.196 | Train Acc:  99.49%\n",
      "Epoch 192 | Val Loss: 0.191 | Val Acc:  99.57%\n",
      "learning rate: [0.0005]\n",
      "Epoch 193 | Train Loss: 0.193 | Train Acc:  99.55%\n",
      "Epoch 193 | Val Loss: 0.188 | Val Acc:  99.73%\n",
      "learning rate: [0.0005]\n",
      "Epoch 194 | Train Loss: 0.189 | Train Acc:  99.68%\n",
      "Epoch 194 | Val Loss: 0.208 | Val Acc:  99.15%\n",
      "learning rate: [0.0005]\n",
      "Epoch 195 | Train Loss: 0.195 | Train Acc:  99.46%\n",
      "Epoch 195 | Val Loss: 0.187 | Val Acc:  99.70%\n",
      "learning rate: [0.0005]\n",
      "Epoch 196 | Train Loss: 0.189 | Train Acc:  99.78%\n",
      "Epoch 196 | Val Loss: 0.183 | Val Acc:  99.85%\n",
      "learning rate: [0.0005]\n",
      "Epoch 197 | Train Loss: 0.187 | Train Acc:  99.72%\n",
      "Epoch 197 | Val Loss: 0.179 | Val Acc:  99.88%\n",
      "learning rate: [0.0005]\n",
      "Epoch 198 | Train Loss: 0.190 | Train Acc:  99.64%\n",
      "Epoch 198 | Val Loss: 0.183 | Val Acc:  99.80%\n",
      "learning rate: [0.0005]\n",
      "Epoch 199 | Train Loss: 0.188 | Train Acc:  99.64%\n",
      "Epoch 199 | Val Loss: 0.186 | Val Acc:  99.78%\n",
      "learning rate: [0.00025]\n",
      "Epoch 200 | Train Loss: 0.179 | Train Acc:  99.86%\n",
      "Epoch 200 | Val Loss: 0.175 | Val Acc:  99.94%\n",
      "learning rate: [0.00025]\n",
      "Epoch 201 | Train Loss: 0.178 | Train Acc:  99.88%\n",
      "Epoch 201 | Val Loss: 0.174 | Val Acc:  99.94%\n",
      "learning rate: [0.00025]\n",
      "Epoch 202 | Train Loss: 0.179 | Train Acc:  99.89%\n",
      "Epoch 202 | Val Loss: 0.175 | Val Acc:  99.93%\n",
      "learning rate: [0.00025]\n",
      "Epoch 203 | Train Loss: 0.177 | Train Acc:  99.94%\n",
      "Epoch 203 | Val Loss: 0.177 | Val Acc:  99.92%\n",
      "learning rate: [0.00025]\n",
      "Epoch 204 | Train Loss: 0.177 | Train Acc:  99.90%\n",
      "Epoch 204 | Val Loss: 0.178 | Val Acc:  99.88%\n",
      "learning rate: [0.00025]\n",
      "Epoch 205 | Train Loss: 0.178 | Train Acc:  99.91%\n",
      "Epoch 205 | Val Loss: 0.174 | Val Acc:  99.95%\n",
      "learning rate: [0.00025]\n",
      "Epoch 206 | Train Loss: 0.176 | Train Acc:  99.93%\n",
      "Epoch 206 | Val Loss: 0.175 | Val Acc:  99.94%\n",
      "learning rate: [0.00025]\n",
      "Epoch 207 | Train Loss: 0.176 | Train Acc:  99.93%\n",
      "Epoch 207 | Val Loss: 0.172 | Val Acc:  99.96%\n",
      "learning rate: [0.00025]\n",
      "Epoch 208 | Train Loss: 0.177 | Train Acc:  99.89%\n",
      "Epoch 208 | Val Loss: 0.179 | Val Acc:  99.86%\n",
      "learning rate: [0.00025]\n",
      "Epoch 209 | Train Loss: 0.177 | Train Acc:  99.92%\n",
      "Epoch 209 | Val Loss: 0.171 | Val Acc:  99.97%\n",
      "learning rate: [0.00025]\n",
      "Epoch 210 | Train Loss: 0.175 | Train Acc:  99.91%\n",
      "Epoch 210 | Val Loss: 0.175 | Val Acc:  99.94%\n",
      "learning rate: [0.00025]\n",
      "Epoch 211 | Train Loss: 0.176 | Train Acc:  99.94%\n",
      "Epoch 211 | Val Loss: 0.186 | Val Acc:  99.78%\n",
      "learning rate: [0.00025]\n",
      "Epoch 212 | Train Loss: 0.176 | Train Acc:  99.95%\n",
      "Epoch 212 | Val Loss: 0.172 | Val Acc:  99.96%\n",
      "learning rate: [0.00025]\n",
      "Epoch 213 | Train Loss: 0.175 | Train Acc:  99.93%\n",
      "Epoch 213 | Val Loss: 0.171 | Val Acc:  99.96%\n",
      "learning rate: [0.00025]\n",
      "Epoch 214 | Train Loss: 0.175 | Train Acc:  99.94%\n",
      "Epoch 214 | Val Loss: 0.173 | Val Acc:  99.95%\n",
      "learning rate: [0.00025]\n",
      "Epoch 215 | Train Loss: 0.175 | Train Acc:  99.94%\n",
      "Epoch 215 | Val Loss: 0.170 | Val Acc:  99.97%\n",
      "learning rate: [0.00025]\n",
      "Epoch 216 | Train Loss: 0.174 | Train Acc:  99.93%\n",
      "Epoch 216 | Val Loss: 0.186 | Val Acc:  99.74%\n",
      "learning rate: [0.00025]\n",
      "Epoch 217 | Train Loss: 0.175 | Train Acc:  99.93%\n",
      "Epoch 217 | Val Loss: 0.172 | Val Acc:  99.93%\n",
      "learning rate: [0.00025]\n",
      "Epoch 218 | Train Loss: 0.173 | Train Acc:  99.96%\n",
      "Epoch 218 | Val Loss: 0.171 | Val Acc:  99.98%\n",
      "learning rate: [0.00025]\n",
      "Epoch 219 | Train Loss: 0.174 | Train Acc:  99.93%\n",
      "Epoch 219 | Val Loss: 0.173 | Val Acc:  99.96%\n",
      "learning rate: [0.00025]\n",
      "Epoch 220 | Train Loss: 0.174 | Train Acc:  99.95%\n",
      "Epoch 220 | Val Loss: 0.169 | Val Acc:  99.97%\n",
      "learning rate: [0.00025]\n",
      "Epoch 221 | Train Loss: 0.172 | Train Acc:  99.96%\n",
      "Epoch 221 | Val Loss: 0.170 | Val Acc:  99.97%\n",
      "learning rate: [0.00025]\n",
      "Epoch 222 | Train Loss: 0.172 | Train Acc:  99.96%\n",
      "Epoch 222 | Val Loss: 0.170 | Val Acc:  99.97%\n",
      "learning rate: [0.00025]\n",
      "Epoch 223 | Train Loss: 0.173 | Train Acc:  99.95%\n",
      "Epoch 223 | Val Loss: 0.169 | Val Acc:  99.97%\n",
      "learning rate: [0.00025]\n",
      "Epoch 224 | Train Loss: 0.172 | Train Acc:  99.95%\n",
      "Epoch 224 | Val Loss: 0.172 | Val Acc:  99.97%\n",
      "learning rate: [0.00025]\n",
      "Epoch 225 | Train Loss: 0.172 | Train Acc:  99.93%\n",
      "Epoch 225 | Val Loss: 0.168 | Val Acc:  99.98%\n",
      "learning rate: [0.00025]\n",
      "Epoch 226 | Train Loss: 0.171 | Train Acc:  99.97%\n",
      "Epoch 226 | Val Loss: 0.169 | Val Acc:  99.98%\n",
      "learning rate: [0.00025]\n",
      "Epoch 227 | Train Loss: 0.171 | Train Acc:  99.97%\n",
      "Epoch 227 | Val Loss: 0.170 | Val Acc:  99.97%\n",
      "learning rate: [0.00025]\n",
      "Epoch 228 | Train Loss: 0.171 | Train Acc:  99.96%\n",
      "Epoch 228 | Val Loss: 0.172 | Val Acc:  99.96%\n",
      "learning rate: [0.00025]\n",
      "Epoch 229 | Train Loss: 0.171 | Train Acc:  99.96%\n",
      "Epoch 229 | Val Loss: 0.167 | Val Acc:  99.98%\n",
      "learning rate: [0.00025]\n",
      "Epoch 230 | Train Loss: 0.170 | Train Acc:  99.98%\n",
      "Epoch 230 | Val Loss: 0.170 | Val Acc:  99.98%\n",
      "learning rate: [0.00025]\n",
      "Epoch 231 | Train Loss: 0.170 | Train Acc:  99.95%\n",
      "Epoch 231 | Val Loss: 0.166 | Val Acc:  99.99%\n",
      "learning rate: [0.00025]\n",
      "Epoch 232 | Train Loss: 0.171 | Train Acc:  99.98%\n",
      "Epoch 232 | Val Loss: 0.168 | Val Acc:  99.99%\n",
      "learning rate: [0.00025]\n",
      "Epoch 233 | Train Loss: 0.169 | Train Acc:  99.97%\n",
      "Epoch 233 | Val Loss: 0.166 | Val Acc:  99.99%\n",
      "learning rate: [0.00025]\n",
      "Epoch 234 | Train Loss: 0.170 | Train Acc:  99.98%\n",
      "Epoch 234 | Val Loss: 0.170 | Val Acc:  99.98%\n",
      "learning rate: [0.00025]\n",
      "Epoch 235 | Train Loss: 0.170 | Train Acc:  99.97%\n",
      "Epoch 235 | Val Loss: 0.166 | Val Acc:  99.97%\n",
      "learning rate: [0.00025]\n",
      "Epoch 236 | Train Loss: 0.169 | Train Acc:  99.95%\n",
      "Epoch 236 | Val Loss: 0.171 | Val Acc:  99.98%\n",
      "learning rate: [0.00025]\n",
      "Epoch 237 | Train Loss: 0.169 | Train Acc:  99.97%\n",
      "Epoch 237 | Val Loss: 0.165 | Val Acc:  99.99%\n",
      "learning rate: [0.00025]\n",
      "Epoch 238 | Train Loss: 0.168 | Train Acc:  99.98%\n",
      "Epoch 238 | Val Loss: 0.167 | Val Acc:  99.99%\n",
      "learning rate: [0.00025]\n",
      "Epoch 239 | Train Loss: 0.168 | Train Acc:  99.97%\n",
      "Epoch 239 | Val Loss: 0.164 | Val Acc: 100.00%\n",
      "learning rate: [0.00025]\n",
      "Epoch 240 | Train Loss: 0.167 | Train Acc:  99.98%\n",
      "Epoch 240 | Val Loss: 0.164 | Val Acc:  99.99%\n",
      "learning rate: [0.00025]\n",
      "Epoch 241 | Train Loss: 0.168 | Train Acc:  99.98%\n",
      "Epoch 241 | Val Loss: 0.163 | Val Acc: 100.00%\n",
      "learning rate: [0.00025]\n",
      "Epoch 242 | Train Loss: 0.167 | Train Acc:  99.98%\n",
      "Epoch 242 | Val Loss: 0.164 | Val Acc: 100.00%\n",
      "learning rate: [0.00025]\n",
      "Epoch 243 | Train Loss: 0.166 | Train Acc:  99.99%\n",
      "Epoch 243 | Val Loss: 0.167 | Val Acc:  99.99%\n",
      "learning rate: [0.00025]\n",
      "Epoch 244 | Train Loss: 0.168 | Train Acc:  99.98%\n",
      "Epoch 244 | Val Loss: 0.190 | Val Acc:  99.71%\n",
      "learning rate: [0.00025]\n",
      "Epoch 245 | Train Loss: 0.172 | Train Acc:  99.96%\n",
      "Epoch 245 | Val Loss: 0.168 | Val Acc:  99.98%\n",
      "learning rate: [0.00025]\n",
      "Epoch 246 | Train Loss: 0.166 | Train Acc:  99.97%\n",
      "Epoch 246 | Val Loss: 0.169 | Val Acc:  99.96%\n",
      "learning rate: [0.00025]\n",
      "Epoch 247 | Train Loss: 0.165 | Train Acc:  99.98%\n",
      "Epoch 247 | Val Loss: 0.164 | Val Acc:  99.99%\n",
      "learning rate: [0.00025]\n",
      "Epoch 248 | Train Loss: 0.165 | Train Acc:  99.99%\n",
      "Epoch 248 | Val Loss: 0.166 | Val Acc:  99.98%\n",
      "learning rate: [0.00025]\n",
      "Epoch 249 | Train Loss: 0.167 | Train Acc:  99.97%\n",
      "Epoch 249 | Val Loss: 0.161 | Val Acc: 100.00%\n",
      "learning rate: [0.00025]\n",
      "Epoch 250 | Train Loss: 0.165 | Train Acc: 100.00%\n",
      "Epoch 250 | Val Loss: 0.161 | Val Acc: 100.00%\n",
      "learning rate: [0.00025]\n",
      "Epoch 251 | Train Loss: 0.164 | Train Acc:  99.99%\n",
      "Epoch 251 | Val Loss: 0.161 | Val Acc: 100.00%\n",
      "learning rate: [0.00025]\n",
      "Epoch 252 | Train Loss: 0.165 | Train Acc:  99.97%\n",
      "Epoch 252 | Val Loss: 0.168 | Val Acc:  99.96%\n",
      "learning rate: [0.00025]\n",
      "Epoch 253 | Train Loss: 0.165 | Train Acc:  99.99%\n",
      "Epoch 253 | Val Loss: 0.163 | Val Acc: 100.00%\n",
      "learning rate: [0.00025]\n",
      "Epoch 254 | Train Loss: 0.164 | Train Acc: 100.00%\n",
      "Epoch 254 | Val Loss: 0.172 | Val Acc:  99.95%\n",
      "learning rate: [0.00025]\n",
      "Epoch 255 | Train Loss: 0.164 | Train Acc:  99.99%\n",
      "Epoch 255 | Val Loss: 0.163 | Val Acc:  99.99%\n",
      "learning rate: [0.00025]\n",
      "Epoch 256 | Train Loss: 0.165 | Train Acc: 100.00%\n",
      "Epoch 256 | Val Loss: 0.162 | Val Acc: 100.00%\n",
      "learning rate: [0.00025]\n",
      "Epoch 257 | Train Loss: 0.164 | Train Acc:  99.99%\n",
      "Epoch 257 | Val Loss: 0.169 | Val Acc:  99.98%\n",
      "learning rate: [0.00025]\n",
      "Epoch 258 | Train Loss: 0.163 | Train Acc:  99.99%\n",
      "Epoch 258 | Val Loss: 0.162 | Val Acc:  99.99%\n",
      "learning rate: [0.00025]\n",
      "Epoch 259 | Train Loss: 0.164 | Train Acc:  99.98%\n",
      "Epoch 259 | Val Loss: 0.163 | Val Acc: 100.00%\n",
      "learning rate: [0.00025]\n",
      "Epoch 260 | Train Loss: 0.165 | Train Acc:  99.99%\n",
      "Epoch 260 | Val Loss: 0.159 | Val Acc: 100.00%\n",
      "learning rate: [0.00025]\n",
      "Epoch 261 | Train Loss: 0.162 | Train Acc: 100.00%\n",
      "Epoch 261 | Val Loss: 0.173 | Val Acc:  99.94%\n",
      "learning rate: [0.00025]\n",
      "Epoch 262 | Train Loss: 0.163 | Train Acc:  99.99%\n",
      "Epoch 262 | Val Loss: 0.160 | Val Acc: 100.00%\n",
      "learning rate: [0.00025]\n",
      "Epoch 263 | Train Loss: 0.162 | Train Acc: 100.00%\n",
      "Epoch 263 | Val Loss: 0.161 | Val Acc:  99.99%\n",
      "learning rate: [0.00025]\n",
      "Epoch 264 | Train Loss: 0.163 | Train Acc:  99.99%\n",
      "Epoch 264 | Val Loss: 0.167 | Val Acc:  99.97%\n",
      "learning rate: [0.00025]\n",
      "Epoch 265 | Train Loss: 0.164 | Train Acc:  99.99%\n",
      "Epoch 265 | Val Loss: 0.165 | Val Acc:  99.98%\n",
      "learning rate: [0.00025]\n",
      "Epoch 266 | Train Loss: 0.162 | Train Acc:  99.99%\n",
      "Epoch 266 | Val Loss: 0.161 | Val Acc: 100.00%\n",
      "learning rate: [0.00025]\n",
      "Epoch 267 | Train Loss: 0.162 | Train Acc: 100.00%\n",
      "Epoch 267 | Val Loss: 0.158 | Val Acc: 100.00%\n",
      "learning rate: [0.00025]\n",
      "Epoch 268 | Train Loss: 0.161 | Train Acc: 100.00%\n",
      "Epoch 268 | Val Loss: 0.161 | Val Acc: 100.00%\n",
      "learning rate: [0.00025]\n",
      "Epoch 269 | Train Loss: 0.162 | Train Acc:  99.99%\n",
      "Epoch 269 | Val Loss: 0.167 | Val Acc:  99.97%\n",
      "learning rate: [0.00025]\n",
      "Epoch 270 | Train Loss: 0.162 | Train Acc: 100.00%\n",
      "Epoch 270 | Val Loss: 0.163 | Val Acc: 100.00%\n",
      "learning rate: [0.00025]\n",
      "Epoch 271 | Train Loss: 0.162 | Train Acc:  99.98%\n",
      "Epoch 271 | Val Loss: 0.159 | Val Acc: 100.00%\n",
      "learning rate: [0.00025]\n",
      "Epoch 272 | Train Loss: 0.160 | Train Acc:  99.99%\n",
      "Epoch 272 | Val Loss: 0.158 | Val Acc: 100.00%\n",
      "learning rate: [0.00025]\n",
      "Epoch 273 | Train Loss: 0.160 | Train Acc:  99.99%\n",
      "Epoch 273 | Val Loss: 0.165 | Val Acc:  99.97%\n",
      "learning rate: [0.00025]\n",
      "Epoch 274 | Train Loss: 0.161 | Train Acc:  99.99%\n",
      "Epoch 274 | Val Loss: 0.166 | Val Acc:  99.97%\n",
      "learning rate: [0.00025]\n",
      "Epoch 275 | Train Loss: 0.160 | Train Acc:  99.99%\n",
      "Epoch 275 | Val Loss: 0.158 | Val Acc: 100.00%\n",
      "learning rate: [0.00025]\n",
      "Epoch 276 | Train Loss: 0.160 | Train Acc: 100.00%\n",
      "Epoch 276 | Val Loss: 0.157 | Val Acc: 100.00%\n",
      "learning rate: [0.00025]\n",
      "Epoch 277 | Train Loss: 0.159 | Train Acc: 100.00%\n",
      "Epoch 277 | Val Loss: 0.156 | Val Acc: 100.00%\n",
      "learning rate: [0.00025]\n",
      "Epoch 278 | Train Loss: 0.161 | Train Acc:  99.99%\n",
      "Epoch 278 | Val Loss: 0.158 | Val Acc:  99.99%\n",
      "learning rate: [0.00025]\n",
      "Epoch 279 | Train Loss: 0.161 | Train Acc:  99.98%\n",
      "Epoch 279 | Val Loss: 0.173 | Val Acc:  99.94%\n",
      "learning rate: [0.00025]\n",
      "Epoch 280 | Train Loss: 0.160 | Train Acc: 100.00%\n",
      "Epoch 280 | Val Loss: 0.157 | Val Acc: 100.00%\n",
      "learning rate: [0.00025]\n",
      "Epoch 281 | Train Loss: 0.159 | Train Acc: 100.00%\n",
      "Epoch 281 | Val Loss: 0.162 | Val Acc:  99.99%\n",
      "learning rate: [0.00025]\n",
      "Epoch 282 | Train Loss: 0.160 | Train Acc: 100.00%\n",
      "Epoch 282 | Val Loss: 0.156 | Val Acc: 100.00%\n",
      "learning rate: [0.00025]\n",
      "Epoch 283 | Train Loss: 0.158 | Train Acc: 100.00%\n",
      "Epoch 283 | Val Loss: 0.158 | Val Acc:  99.99%\n",
      "learning rate: [0.00025]\n",
      "Epoch 284 | Train Loss: 0.158 | Train Acc:  99.99%\n",
      "Epoch 284 | Val Loss: 0.155 | Val Acc: 100.00%\n",
      "learning rate: [0.00025]\n",
      "Epoch 285 | Train Loss: 0.158 | Train Acc:  99.99%\n",
      "Epoch 285 | Val Loss: 0.156 | Val Acc: 100.00%\n",
      "learning rate: [0.00025]\n",
      "Epoch 286 | Train Loss: 0.159 | Train Acc: 100.00%\n",
      "Epoch 286 | Val Loss: 0.160 | Val Acc: 100.00%\n",
      "learning rate: [0.00025]\n",
      "Epoch 287 | Train Loss: 0.159 | Train Acc:  99.99%\n",
      "Epoch 287 | Val Loss: 0.162 | Val Acc: 100.00%\n",
      "learning rate: [0.00025]\n",
      "Epoch 288 | Train Loss: 0.158 | Train Acc:  99.99%\n",
      "Epoch 288 | Val Loss: 0.158 | Val Acc: 100.00%\n",
      "learning rate: [0.00025]\n",
      "Epoch 289 | Train Loss: 0.158 | Train Acc: 100.00%\n",
      "Epoch 289 | Val Loss: 0.155 | Val Acc: 100.00%\n",
      "learning rate: [0.00025]\n",
      "Epoch 290 | Train Loss: 0.157 | Train Acc: 100.00%\n",
      "Epoch 290 | Val Loss: 0.155 | Val Acc: 100.00%\n",
      "learning rate: [0.00025]\n",
      "Epoch 291 | Train Loss: 0.157 | Train Acc: 100.00%\n",
      "Epoch 291 | Val Loss: 0.158 | Val Acc: 100.00%\n",
      "learning rate: [0.00025]\n",
      "Epoch 292 | Train Loss: 0.157 | Train Acc: 100.00%\n",
      "Epoch 292 | Val Loss: 0.155 | Val Acc: 100.00%\n",
      "learning rate: [0.00025]\n",
      "Epoch 293 | Train Loss: 0.161 | Train Acc:  99.98%\n",
      "Epoch 293 | Val Loss: 0.156 | Val Acc: 100.00%\n",
      "learning rate: [0.00025]\n",
      "Epoch 294 | Train Loss: 0.157 | Train Acc: 100.00%\n",
      "Epoch 294 | Val Loss: 0.155 | Val Acc:  99.99%\n",
      "learning rate: [0.00025]\n",
      "Epoch 295 | Train Loss: 0.157 | Train Acc: 100.00%\n",
      "Epoch 295 | Val Loss: 0.154 | Val Acc: 100.00%\n",
      "learning rate: [0.00025]\n",
      "Epoch 296 | Train Loss: 0.158 | Train Acc: 100.00%\n",
      "Epoch 296 | Val Loss: 0.155 | Val Acc: 100.00%\n",
      "learning rate: [0.00025]\n",
      "Epoch 297 | Train Loss: 0.157 | Train Acc: 100.00%\n",
      "Epoch 297 | Val Loss: 0.155 | Val Acc:  99.99%\n",
      "learning rate: [0.00025]\n",
      "Epoch 298 | Train Loss: 0.156 | Train Acc: 100.00%\n",
      "Epoch 298 | Val Loss: 0.154 | Val Acc: 100.00%\n",
      "learning rate: [0.00025]\n",
      "Epoch 299 | Train Loss: 0.156 | Train Acc: 100.00%\n",
      "Epoch 299 | Val Loss: 0.154 | Val Acc: 100.00%\n",
      "learning rate: [0.000125]\n",
      "Epoch 300 | Train Loss: 0.154 | Train Acc: 100.00%\n",
      "Epoch 300 | Val Loss: 0.153 | Val Acc: 100.00%\n",
      "learning rate: [0.000125]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved result: acc 1.000, scheduler:\n",
      " functools.partial(<class 'torch.optim.lr_scheduler.StepLR'>, step_size=100, gamma=0.5)\n",
      "epoch: 250\n",
      "<class 'torch.optim.lr_scheduler.StepLR'>\n",
      "Epoch   0 | Train Loss: 1.471 | Train Acc:  33.58%\n",
      "Epoch   0 | Val Loss: 1.381 | Val Acc:  39.08%\n",
      "learning rate: [0.001]\n",
      "Epoch   1 | Train Loss: 1.356 | Train Acc:  40.08%\n",
      "Epoch   1 | Val Loss: 1.325 | Val Acc:  41.96%\n",
      "learning rate: [0.001]\n",
      "Epoch   2 | Train Loss: 1.310 | Train Acc:  42.40%\n",
      "Epoch   2 | Val Loss: 1.290 | Val Acc:  43.44%\n",
      "learning rate: [0.001]\n",
      "Epoch   3 | Train Loss: 1.275 | Train Acc:  44.70%\n",
      "Epoch   3 | Val Loss: 1.262 | Val Acc:  45.11%\n",
      "learning rate: [0.001]\n",
      "Epoch   4 | Train Loss: 1.248 | Train Acc:  46.08%\n",
      "Epoch   4 | Val Loss: 1.228 | Val Acc:  47.30%\n",
      "learning rate: [0.001]\n",
      "Epoch   5 | Train Loss: 1.228 | Train Acc:  47.14%\n",
      "Epoch   5 | Val Loss: 1.210 | Val Acc:  48.19%\n",
      "learning rate: [0.001]\n",
      "Epoch   6 | Train Loss: 1.206 | Train Acc:  48.16%\n",
      "Epoch   6 | Val Loss: 1.190 | Val Acc:  49.33%\n",
      "learning rate: [0.001]\n",
      "Epoch   7 | Train Loss: 1.183 | Train Acc:  49.55%\n",
      "Epoch   7 | Val Loss: 1.171 | Val Acc:  49.82%\n",
      "learning rate: [0.001]\n",
      "Epoch   8 | Train Loss: 1.161 | Train Acc:  50.80%\n",
      "Epoch   8 | Val Loss: 1.144 | Val Acc:  52.12%\n",
      "learning rate: [0.001]\n",
      "Epoch   9 | Train Loss: 1.146 | Train Acc:  51.56%\n",
      "Epoch   9 | Val Loss: 1.165 | Val Acc:  51.20%\n",
      "learning rate: [0.001]\n",
      "Epoch  10 | Train Loss: 1.135 | Train Acc:  51.94%\n",
      "Epoch  10 | Val Loss: 1.127 | Val Acc:  53.20%\n",
      "learning rate: [0.001]\n",
      "Epoch  11 | Train Loss: 1.127 | Train Acc:  52.39%\n",
      "Epoch  11 | Val Loss: 1.109 | Val Acc:  53.03%\n",
      "learning rate: [0.001]\n",
      "Epoch  12 | Train Loss: 1.105 | Train Acc:  53.88%\n",
      "Epoch  12 | Val Loss: 1.098 | Val Acc:  53.72%\n",
      "learning rate: [0.001]\n",
      "Epoch  13 | Train Loss: 1.094 | Train Acc:  54.30%\n",
      "Epoch  13 | Val Loss: 1.091 | Val Acc:  53.33%\n",
      "learning rate: [0.001]\n",
      "Epoch  14 | Train Loss: 1.089 | Train Acc:  54.42%\n",
      "Epoch  14 | Val Loss: 1.065 | Val Acc:  55.65%\n",
      "learning rate: [0.001]\n",
      "Epoch  15 | Train Loss: 1.073 | Train Acc:  55.56%\n",
      "Epoch  15 | Val Loss: 1.053 | Val Acc:  56.75%\n",
      "learning rate: [0.001]\n",
      "Epoch  16 | Train Loss: 1.065 | Train Acc:  56.01%\n",
      "Epoch  16 | Val Loss: 1.062 | Val Acc:  55.21%\n",
      "learning rate: [0.001]\n",
      "Epoch  17 | Train Loss: 1.056 | Train Acc:  56.23%\n",
      "Epoch  17 | Val Loss: 1.035 | Val Acc:  57.52%\n",
      "learning rate: [0.001]\n",
      "Epoch  18 | Train Loss: 1.048 | Train Acc:  57.05%\n",
      "Epoch  18 | Val Loss: 1.026 | Val Acc:  57.95%\n",
      "learning rate: [0.001]\n",
      "Epoch  19 | Train Loss: 1.044 | Train Acc:  56.94%\n",
      "Epoch  19 | Val Loss: 1.017 | Val Acc:  58.97%\n",
      "learning rate: [0.001]\n",
      "Epoch  20 | Train Loss: 1.032 | Train Acc:  57.52%\n",
      "Epoch  20 | Val Loss: 1.011 | Val Acc:  58.79%\n",
      "learning rate: [0.001]\n",
      "Epoch  21 | Train Loss: 1.017 | Train Acc:  58.39%\n",
      "Epoch  21 | Val Loss: 0.999 | Val Acc:  59.37%\n",
      "learning rate: [0.001]\n",
      "Epoch  22 | Train Loss: 1.005 | Train Acc:  59.07%\n",
      "Epoch  22 | Val Loss: 1.003 | Val Acc:  59.58%\n",
      "learning rate: [0.001]\n",
      "Epoch  23 | Train Loss: 1.002 | Train Acc:  59.28%\n",
      "Epoch  23 | Val Loss: 0.994 | Val Acc:  60.12%\n",
      "learning rate: [0.001]\n",
      "Epoch  24 | Train Loss: 0.992 | Train Acc:  59.66%\n",
      "Epoch  24 | Val Loss: 0.975 | Val Acc:  60.99%\n",
      "learning rate: [0.001]\n",
      "Epoch  25 | Train Loss: 0.988 | Train Acc:  59.91%\n",
      "Epoch  25 | Val Loss: 0.962 | Val Acc:  61.27%\n",
      "learning rate: [0.001]\n",
      "Epoch  26 | Train Loss: 0.977 | Train Acc:  60.51%\n",
      "Epoch  26 | Val Loss: 0.975 | Val Acc:  60.86%\n",
      "learning rate: [0.001]\n",
      "Epoch  27 | Train Loss: 0.970 | Train Acc:  60.61%\n",
      "Epoch  27 | Val Loss: 0.962 | Val Acc:  61.10%\n",
      "learning rate: [0.001]\n",
      "Epoch  28 | Train Loss: 0.957 | Train Acc:  61.52%\n",
      "Epoch  28 | Val Loss: 0.934 | Val Acc:  63.00%\n",
      "learning rate: [0.001]\n",
      "Epoch  29 | Train Loss: 0.951 | Train Acc:  61.84%\n",
      "Epoch  29 | Val Loss: 0.962 | Val Acc:  61.18%\n",
      "learning rate: [0.001]\n",
      "Epoch  30 | Train Loss: 0.943 | Train Acc:  62.12%\n",
      "Epoch  30 | Val Loss: 0.917 | Val Acc:  63.31%\n",
      "learning rate: [0.001]\n",
      "Epoch  31 | Train Loss: 0.929 | Train Acc:  63.07%\n",
      "Epoch  31 | Val Loss: 0.910 | Val Acc:  64.52%\n",
      "learning rate: [0.001]\n",
      "Epoch  32 | Train Loss: 0.932 | Train Acc:  62.69%\n",
      "Epoch  32 | Val Loss: 0.930 | Val Acc:  62.21%\n",
      "learning rate: [0.001]\n",
      "Epoch  33 | Train Loss: 0.924 | Train Acc:  62.99%\n",
      "Epoch  33 | Val Loss: 0.905 | Val Acc:  64.68%\n",
      "learning rate: [0.001]\n",
      "Epoch  34 | Train Loss: 0.910 | Train Acc:  63.71%\n",
      "Epoch  34 | Val Loss: 0.908 | Val Acc:  63.32%\n",
      "learning rate: [0.001]\n",
      "Epoch  35 | Train Loss: 0.909 | Train Acc:  63.84%\n",
      "Epoch  35 | Val Loss: 0.939 | Val Acc:  62.03%\n",
      "learning rate: [0.001]\n",
      "Epoch  36 | Train Loss: 0.905 | Train Acc:  64.20%\n",
      "Epoch  36 | Val Loss: 0.886 | Val Acc:  65.33%\n",
      "learning rate: [0.001]\n",
      "Epoch  37 | Train Loss: 0.892 | Train Acc:  64.86%\n",
      "Epoch  37 | Val Loss: 0.879 | Val Acc:  65.22%\n",
      "learning rate: [0.001]\n",
      "Epoch  38 | Train Loss: 0.887 | Train Acc:  64.92%\n",
      "Epoch  38 | Val Loss: 0.879 | Val Acc:  65.51%\n",
      "learning rate: [0.001]\n",
      "Epoch  39 | Train Loss: 0.875 | Train Acc:  65.50%\n",
      "Epoch  39 | Val Loss: 0.891 | Val Acc:  64.91%\n",
      "learning rate: [0.001]\n",
      "Epoch  40 | Train Loss: 0.871 | Train Acc:  65.66%\n",
      "Epoch  40 | Val Loss: 0.850 | Val Acc:  66.64%\n",
      "learning rate: [0.001]\n",
      "Epoch  41 | Train Loss: 0.859 | Train Acc:  66.37%\n",
      "Epoch  41 | Val Loss: 0.844 | Val Acc:  67.26%\n",
      "learning rate: [0.001]\n",
      "Epoch  42 | Train Loss: 0.859 | Train Acc:  66.44%\n",
      "Epoch  42 | Val Loss: 0.870 | Val Acc:  65.30%\n",
      "learning rate: [0.001]\n",
      "Epoch  43 | Train Loss: 0.852 | Train Acc:  66.27%\n",
      "Epoch  43 | Val Loss: 0.865 | Val Acc:  65.79%\n",
      "learning rate: [0.001]\n",
      "Epoch  44 | Train Loss: 0.838 | Train Acc:  67.06%\n",
      "Epoch  44 | Val Loss: 0.828 | Val Acc:  67.79%\n",
      "learning rate: [0.001]\n",
      "Epoch  45 | Train Loss: 0.831 | Train Acc:  67.49%\n",
      "Epoch  45 | Val Loss: 0.813 | Val Acc:  68.70%\n",
      "learning rate: [0.001]\n",
      "Epoch  46 | Train Loss: 0.823 | Train Acc:  67.98%\n",
      "Epoch  46 | Val Loss: 0.801 | Val Acc:  69.29%\n",
      "learning rate: [0.001]\n",
      "Epoch  47 | Train Loss: 0.820 | Train Acc:  68.25%\n",
      "Epoch  47 | Val Loss: 0.802 | Val Acc:  69.01%\n",
      "learning rate: [0.001]\n",
      "Epoch  48 | Train Loss: 0.810 | Train Acc:  68.74%\n",
      "Epoch  48 | Val Loss: 0.805 | Val Acc:  68.99%\n",
      "learning rate: [0.001]\n",
      "Epoch  49 | Train Loss: 0.795 | Train Acc:  69.51%\n",
      "Epoch  49 | Val Loss: 0.773 | Val Acc:  70.51%\n",
      "learning rate: [0.001]\n",
      "Epoch  50 | Train Loss: 0.794 | Train Acc:  69.48%\n",
      "Epoch  50 | Val Loss: 0.776 | Val Acc:  70.66%\n",
      "learning rate: [0.001]\n",
      "Epoch  51 | Train Loss: 0.792 | Train Acc:  69.18%\n",
      "Epoch  51 | Val Loss: 0.818 | Val Acc:  68.40%\n",
      "learning rate: [0.001]\n",
      "Epoch  52 | Train Loss: 0.780 | Train Acc:  70.23%\n",
      "Epoch  52 | Val Loss: 0.769 | Val Acc:  70.44%\n",
      "learning rate: [0.001]\n",
      "Epoch  53 | Train Loss: 0.791 | Train Acc:  69.52%\n",
      "Epoch  53 | Val Loss: 0.741 | Val Acc:  72.39%\n",
      "learning rate: [0.001]\n",
      "Epoch  54 | Train Loss: 0.765 | Train Acc:  70.37%\n",
      "Epoch  54 | Val Loss: 0.748 | Val Acc:  71.70%\n",
      "learning rate: [0.001]\n",
      "Epoch  55 | Train Loss: 0.754 | Train Acc:  71.39%\n",
      "Epoch  55 | Val Loss: 0.783 | Val Acc:  69.84%\n",
      "learning rate: [0.001]\n",
      "Epoch  56 | Train Loss: 0.756 | Train Acc:  71.17%\n",
      "Epoch  56 | Val Loss: 0.714 | Val Acc:  73.48%\n",
      "learning rate: [0.001]\n",
      "Epoch  57 | Train Loss: 0.738 | Train Acc:  72.14%\n",
      "Epoch  57 | Val Loss: 0.712 | Val Acc:  73.64%\n",
      "learning rate: [0.001]\n",
      "Epoch  58 | Train Loss: 0.731 | Train Acc:  72.50%\n",
      "Epoch  58 | Val Loss: 0.715 | Val Acc:  73.46%\n",
      "learning rate: [0.001]\n",
      "Epoch  59 | Train Loss: 0.741 | Train Acc:  71.90%\n",
      "Epoch  59 | Val Loss: 0.757 | Val Acc:  70.56%\n",
      "learning rate: [0.001]\n",
      "Epoch  60 | Train Loss: 0.730 | Train Acc:  72.55%\n",
      "Epoch  60 | Val Loss: 0.695 | Val Acc:  74.48%\n",
      "learning rate: [0.001]\n",
      "Epoch  61 | Train Loss: 0.710 | Train Acc:  73.47%\n",
      "Epoch  61 | Val Loss: 0.680 | Val Acc:  75.03%\n",
      "learning rate: [0.001]\n",
      "Epoch  62 | Train Loss: 0.705 | Train Acc:  73.56%\n",
      "Epoch  62 | Val Loss: 0.670 | Val Acc:  75.98%\n",
      "learning rate: [0.001]\n",
      "Epoch  63 | Train Loss: 0.704 | Train Acc:  73.87%\n",
      "Epoch  63 | Val Loss: 0.670 | Val Acc:  75.52%\n",
      "learning rate: [0.001]\n",
      "Epoch  64 | Train Loss: 0.694 | Train Acc:  74.27%\n",
      "Epoch  64 | Val Loss: 0.709 | Val Acc:  73.16%\n",
      "learning rate: [0.001]\n",
      "Epoch  65 | Train Loss: 0.709 | Train Acc:  73.33%\n",
      "Epoch  65 | Val Loss: 0.685 | Val Acc:  74.67%\n",
      "learning rate: [0.001]\n",
      "Epoch  66 | Train Loss: 0.678 | Train Acc:  74.83%\n",
      "Epoch  66 | Val Loss: 0.647 | Val Acc:  76.87%\n",
      "learning rate: [0.001]\n",
      "Epoch  67 | Train Loss: 0.676 | Train Acc:  75.33%\n",
      "Epoch  67 | Val Loss: 0.640 | Val Acc:  77.37%\n",
      "learning rate: [0.001]\n",
      "Epoch  68 | Train Loss: 0.661 | Train Acc:  75.84%\n",
      "Epoch  68 | Val Loss: 0.648 | Val Acc:  76.42%\n",
      "learning rate: [0.001]\n",
      "Epoch  69 | Train Loss: 0.655 | Train Acc:  76.02%\n",
      "Epoch  69 | Val Loss: 0.742 | Val Acc:  70.72%\n",
      "learning rate: [0.001]\n",
      "Epoch  70 | Train Loss: 0.652 | Train Acc:  76.21%\n",
      "Epoch  70 | Val Loss: 0.614 | Val Acc:  78.60%\n",
      "learning rate: [0.001]\n",
      "Epoch  71 | Train Loss: 0.635 | Train Acc:  77.34%\n",
      "Epoch  71 | Val Loss: 0.608 | Val Acc:  78.89%\n",
      "learning rate: [0.001]\n",
      "Epoch  72 | Train Loss: 0.641 | Train Acc:  76.72%\n",
      "Epoch  72 | Val Loss: 0.662 | Val Acc:  75.28%\n",
      "learning rate: [0.001]\n",
      "Epoch  73 | Train Loss: 0.646 | Train Acc:  76.33%\n",
      "Epoch  73 | Val Loss: 0.603 | Val Acc:  78.58%\n",
      "learning rate: [0.001]\n",
      "Epoch  74 | Train Loss: 0.627 | Train Acc:  77.45%\n",
      "Epoch  74 | Val Loss: 0.621 | Val Acc:  77.35%\n",
      "learning rate: [0.0005]\n",
      "Epoch  75 | Train Loss: 0.593 | Train Acc:  79.43%\n",
      "Epoch  75 | Val Loss: 0.580 | Val Acc:  80.37%\n",
      "learning rate: [0.0005]\n",
      "Epoch  76 | Train Loss: 0.592 | Train Acc:  79.31%\n",
      "Epoch  76 | Val Loss: 0.579 | Val Acc:  80.04%\n",
      "learning rate: [0.0005]\n",
      "Epoch  77 | Train Loss: 0.583 | Train Acc:  80.07%\n",
      "Epoch  77 | Val Loss: 0.568 | Val Acc:  80.86%\n",
      "learning rate: [0.0005]\n",
      "Epoch  78 | Train Loss: 0.578 | Train Acc:  80.28%\n",
      "Epoch  78 | Val Loss: 0.570 | Val Acc:  80.59%\n",
      "learning rate: [0.0005]\n",
      "Epoch  79 | Train Loss: 0.574 | Train Acc:  80.49%\n",
      "Epoch  79 | Val Loss: 0.557 | Val Acc:  81.47%\n",
      "learning rate: [0.0005]\n",
      "Epoch  80 | Train Loss: 0.569 | Train Acc:  80.64%\n",
      "Epoch  80 | Val Loss: 0.549 | Val Acc:  82.05%\n",
      "learning rate: [0.0005]\n",
      "Epoch  81 | Train Loss: 0.566 | Train Acc:  80.83%\n",
      "Epoch  81 | Val Loss: 0.547 | Val Acc:  81.82%\n",
      "learning rate: [0.0005]\n",
      "Epoch  82 | Train Loss: 0.562 | Train Acc:  80.98%\n",
      "Epoch  82 | Val Loss: 0.584 | Val Acc:  79.18%\n",
      "learning rate: [0.0005]\n",
      "Epoch  83 | Train Loss: 0.559 | Train Acc:  81.03%\n",
      "Epoch  83 | Val Loss: 0.541 | Val Acc:  81.88%\n",
      "learning rate: [0.0005]\n",
      "Epoch  84 | Train Loss: 0.562 | Train Acc:  80.65%\n",
      "Epoch  84 | Val Loss: 0.538 | Val Acc:  82.65%\n",
      "learning rate: [0.0005]\n",
      "Epoch  85 | Train Loss: 0.553 | Train Acc:  81.30%\n",
      "Epoch  85 | Val Loss: 0.534 | Val Acc:  82.64%\n",
      "learning rate: [0.0005]\n",
      "Epoch  86 | Train Loss: 0.545 | Train Acc:  81.84%\n",
      "Epoch  86 | Val Loss: 0.523 | Val Acc:  82.96%\n",
      "learning rate: [0.0005]\n",
      "Epoch  87 | Train Loss: 0.548 | Train Acc:  81.36%\n",
      "Epoch  87 | Val Loss: 0.529 | Val Acc:  82.87%\n",
      "learning rate: [0.0005]\n",
      "Epoch  88 | Train Loss: 0.538 | Train Acc:  81.95%\n",
      "Epoch  88 | Val Loss: 0.553 | Val Acc:  80.96%\n",
      "learning rate: [0.0005]\n",
      "Epoch  89 | Train Loss: 0.531 | Train Acc:  82.62%\n",
      "Epoch  89 | Val Loss: 0.527 | Val Acc:  82.75%\n",
      "learning rate: [0.0005]\n",
      "Epoch  90 | Train Loss: 0.538 | Train Acc:  82.04%\n",
      "Epoch  90 | Val Loss: 0.504 | Val Acc:  84.10%\n",
      "learning rate: [0.0005]\n",
      "Epoch  91 | Train Loss: 0.520 | Train Acc:  83.06%\n",
      "Epoch  91 | Val Loss: 0.541 | Val Acc:  81.20%\n",
      "learning rate: [0.0005]\n",
      "Epoch  92 | Train Loss: 0.525 | Train Acc:  82.64%\n",
      "Epoch  92 | Val Loss: 0.516 | Val Acc:  83.19%\n",
      "learning rate: [0.0005]\n",
      "Epoch  93 | Train Loss: 0.524 | Train Acc:  82.59%\n",
      "Epoch  93 | Val Loss: 0.515 | Val Acc:  83.07%\n",
      "learning rate: [0.0005]\n",
      "Epoch  94 | Train Loss: 0.526 | Train Acc:  82.40%\n",
      "Epoch  94 | Val Loss: 0.492 | Val Acc:  84.72%\n",
      "learning rate: [0.0005]\n",
      "Epoch  95 | Train Loss: 0.509 | Train Acc:  83.36%\n",
      "Epoch  95 | Val Loss: 0.528 | Val Acc:  81.75%\n",
      "learning rate: [0.0005]\n",
      "Epoch  96 | Train Loss: 0.509 | Train Acc:  83.38%\n",
      "Epoch  96 | Val Loss: 0.509 | Val Acc:  83.51%\n",
      "learning rate: [0.0005]\n",
      "Epoch  97 | Train Loss: 0.505 | Train Acc:  83.65%\n",
      "Epoch  97 | Val Loss: 0.484 | Val Acc:  85.10%\n",
      "learning rate: [0.0005]\n",
      "Epoch  98 | Train Loss: 0.507 | Train Acc:  83.32%\n",
      "Epoch  98 | Val Loss: 0.481 | Val Acc:  84.89%\n",
      "learning rate: [0.0005]\n",
      "Epoch  99 | Train Loss: 0.494 | Train Acc:  84.38%\n",
      "Epoch  99 | Val Loss: 0.476 | Val Acc:  85.49%\n",
      "learning rate: [0.0005]\n",
      "Epoch 100 | Train Loss: 0.491 | Train Acc:  84.50%\n",
      "Epoch 100 | Val Loss: 0.479 | Val Acc:  84.77%\n",
      "learning rate: [0.0005]\n",
      "Epoch 101 | Train Loss: 0.485 | Train Acc:  84.89%\n",
      "Epoch 101 | Val Loss: 0.476 | Val Acc:  85.44%\n",
      "learning rate: [0.0005]\n",
      "Epoch 102 | Train Loss: 0.497 | Train Acc:  84.04%\n",
      "Epoch 102 | Val Loss: 0.494 | Val Acc:  83.91%\n",
      "learning rate: [0.0005]\n",
      "Epoch 103 | Train Loss: 0.484 | Train Acc:  84.81%\n",
      "Epoch 103 | Val Loss: 0.476 | Val Acc:  85.12%\n",
      "learning rate: [0.0005]\n",
      "Epoch 104 | Train Loss: 0.479 | Train Acc:  84.82%\n",
      "Epoch 104 | Val Loss: 0.500 | Val Acc:  83.64%\n",
      "learning rate: [0.0005]\n",
      "Epoch 105 | Train Loss: 0.482 | Train Acc:  84.72%\n",
      "Epoch 105 | Val Loss: 0.456 | Val Acc:  86.41%\n",
      "learning rate: [0.0005]\n",
      "Epoch 106 | Train Loss: 0.485 | Train Acc:  84.38%\n",
      "Epoch 106 | Val Loss: 0.452 | Val Acc:  86.27%\n",
      "learning rate: [0.0005]\n",
      "Epoch 107 | Train Loss: 0.470 | Train Acc:  85.41%\n",
      "Epoch 107 | Val Loss: 0.464 | Val Acc:  85.70%\n",
      "learning rate: [0.0005]\n",
      "Epoch 108 | Train Loss: 0.469 | Train Acc:  85.23%\n",
      "Epoch 108 | Val Loss: 0.452 | Val Acc:  86.65%\n",
      "learning rate: [0.0005]\n",
      "Epoch 109 | Train Loss: 0.456 | Train Acc:  86.27%\n",
      "Epoch 109 | Val Loss: 0.437 | Val Acc:  87.47%\n",
      "learning rate: [0.0005]\n",
      "Epoch 110 | Train Loss: 0.458 | Train Acc:  86.11%\n",
      "Epoch 110 | Val Loss: 0.438 | Val Acc:  87.26%\n",
      "learning rate: [0.0005]\n",
      "Epoch 111 | Train Loss: 0.446 | Train Acc:  86.81%\n",
      "Epoch 111 | Val Loss: 0.436 | Val Acc:  87.46%\n",
      "learning rate: [0.0005]\n",
      "Epoch 112 | Train Loss: 0.444 | Train Acc:  86.96%\n",
      "Epoch 112 | Val Loss: 0.425 | Val Acc:  88.08%\n",
      "learning rate: [0.0005]\n",
      "Epoch 113 | Train Loss: 0.442 | Train Acc:  86.74%\n",
      "Epoch 113 | Val Loss: 0.419 | Val Acc:  88.19%\n",
      "learning rate: [0.0005]\n",
      "Epoch 114 | Train Loss: 0.441 | Train Acc:  87.00%\n",
      "Epoch 114 | Val Loss: 0.417 | Val Acc:  88.43%\n",
      "learning rate: [0.0005]\n",
      "Epoch 115 | Train Loss: 0.433 | Train Acc:  87.46%\n",
      "Epoch 115 | Val Loss: 0.429 | Val Acc:  87.57%\n",
      "learning rate: [0.0005]\n",
      "Epoch 116 | Train Loss: 0.438 | Train Acc:  86.89%\n",
      "Epoch 116 | Val Loss: 0.418 | Val Acc:  87.97%\n",
      "learning rate: [0.0005]\n",
      "Epoch 117 | Train Loss: 0.426 | Train Acc:  87.48%\n",
      "Epoch 117 | Val Loss: 0.404 | Val Acc:  89.28%\n",
      "learning rate: [0.0005]\n",
      "Epoch 118 | Train Loss: 0.433 | Train Acc:  87.28%\n",
      "Epoch 118 | Val Loss: 0.415 | Val Acc:  88.02%\n",
      "learning rate: [0.0005]\n",
      "Epoch 119 | Train Loss: 0.427 | Train Acc:  87.52%\n",
      "Epoch 119 | Val Loss: 0.399 | Val Acc:  89.42%\n",
      "learning rate: [0.0005]\n",
      "Epoch 120 | Train Loss: 0.428 | Train Acc:  87.31%\n",
      "Epoch 120 | Val Loss: 0.453 | Val Acc:  85.35%\n",
      "learning rate: [0.0005]\n",
      "Epoch 121 | Train Loss: 0.431 | Train Acc:  86.85%\n",
      "Epoch 121 | Val Loss: 0.415 | Val Acc:  88.05%\n",
      "learning rate: [0.0005]\n",
      "Epoch 122 | Train Loss: 0.415 | Train Acc:  88.17%\n",
      "Epoch 122 | Val Loss: 0.448 | Val Acc:  85.64%\n",
      "learning rate: [0.0005]\n",
      "Epoch 123 | Train Loss: 0.411 | Train Acc:  88.44%\n",
      "Epoch 123 | Val Loss: 0.406 | Val Acc:  88.63%\n",
      "learning rate: [0.0005]\n",
      "Epoch 124 | Train Loss: 0.405 | Train Acc:  88.79%\n",
      "Epoch 124 | Val Loss: 0.382 | Val Acc:  90.43%\n",
      "learning rate: [0.0005]\n",
      "Epoch 125 | Train Loss: 0.407 | Train Acc:  88.53%\n",
      "Epoch 125 | Val Loss: 0.403 | Val Acc:  88.52%\n",
      "learning rate: [0.0005]\n",
      "Epoch 126 | Train Loss: 0.409 | Train Acc:  88.25%\n",
      "Epoch 126 | Val Loss: 0.404 | Val Acc:  88.80%\n",
      "learning rate: [0.0005]\n",
      "Epoch 127 | Train Loss: 0.396 | Train Acc:  89.21%\n",
      "Epoch 127 | Val Loss: 0.379 | Val Acc:  90.31%\n",
      "learning rate: [0.0005]\n",
      "Epoch 128 | Train Loss: 0.389 | Train Acc:  89.51%\n",
      "Epoch 128 | Val Loss: 0.409 | Val Acc:  87.86%\n",
      "learning rate: [0.0005]\n",
      "Epoch 129 | Train Loss: 0.394 | Train Acc:  89.23%\n",
      "Epoch 129 | Val Loss: 0.363 | Val Acc:  91.40%\n",
      "learning rate: [0.0005]\n",
      "Epoch 130 | Train Loss: 0.383 | Train Acc:  89.87%\n",
      "Epoch 130 | Val Loss: 0.359 | Val Acc:  91.74%\n",
      "learning rate: [0.0005]\n",
      "Epoch 131 | Train Loss: 0.380 | Train Acc:  90.24%\n",
      "Epoch 131 | Val Loss: 0.361 | Val Acc:  91.29%\n",
      "learning rate: [0.0005]\n",
      "Epoch 132 | Train Loss: 0.381 | Train Acc:  90.05%\n",
      "Epoch 132 | Val Loss: 0.449 | Val Acc:  84.81%\n",
      "learning rate: [0.0005]\n",
      "Epoch 133 | Train Loss: 0.376 | Train Acc:  90.10%\n",
      "Epoch 133 | Val Loss: 0.366 | Val Acc:  90.89%\n",
      "learning rate: [0.0005]\n",
      "Epoch 134 | Train Loss: 0.369 | Train Acc:  90.70%\n",
      "Epoch 134 | Val Loss: 0.357 | Val Acc:  91.50%\n",
      "learning rate: [0.0005]\n",
      "Epoch 135 | Train Loss: 0.376 | Train Acc:  90.12%\n",
      "Epoch 135 | Val Loss: 0.351 | Val Acc:  91.60%\n",
      "learning rate: [0.0005]\n",
      "Epoch 136 | Train Loss: 0.366 | Train Acc:  90.82%\n",
      "Epoch 136 | Val Loss: 0.346 | Val Acc:  92.32%\n",
      "learning rate: [0.0005]\n",
      "Epoch 137 | Train Loss: 0.359 | Train Acc:  91.20%\n",
      "Epoch 137 | Val Loss: 0.352 | Val Acc:  91.40%\n",
      "learning rate: [0.0005]\n",
      "Epoch 138 | Train Loss: 0.362 | Train Acc:  90.82%\n",
      "Epoch 138 | Val Loss: 0.347 | Val Acc:  91.82%\n",
      "learning rate: [0.0005]\n",
      "Epoch 139 | Train Loss: 0.365 | Train Acc:  90.74%\n",
      "Epoch 139 | Val Loss: 0.382 | Val Acc:  89.15%\n",
      "learning rate: [0.0005]\n",
      "Epoch 140 | Train Loss: 0.360 | Train Acc:  91.12%\n",
      "Epoch 140 | Val Loss: 0.337 | Val Acc:  92.30%\n",
      "learning rate: [0.0005]\n",
      "Epoch 141 | Train Loss: 0.357 | Train Acc:  90.92%\n",
      "Epoch 141 | Val Loss: 0.396 | Val Acc:  88.09%\n",
      "learning rate: [0.0005]\n",
      "Epoch 142 | Train Loss: 0.349 | Train Acc:  91.60%\n",
      "Epoch 142 | Val Loss: 0.326 | Val Acc:  93.47%\n",
      "learning rate: [0.0005]\n",
      "Epoch 143 | Train Loss: 0.340 | Train Acc:  92.15%\n",
      "Epoch 143 | Val Loss: 0.327 | Val Acc:  93.39%\n",
      "learning rate: [0.0005]\n",
      "Epoch 144 | Train Loss: 0.345 | Train Acc:  91.90%\n",
      "Epoch 144 | Val Loss: 0.374 | Val Acc:  89.64%\n",
      "learning rate: [0.0005]\n",
      "Epoch 145 | Train Loss: 0.341 | Train Acc:  92.05%\n",
      "Epoch 145 | Val Loss: 0.318 | Val Acc:  93.63%\n",
      "learning rate: [0.0005]\n",
      "Epoch 146 | Train Loss: 0.330 | Train Acc:  92.90%\n",
      "Epoch 146 | Val Loss: 0.355 | Val Acc:  90.66%\n",
      "learning rate: [0.0005]\n",
      "Epoch 147 | Train Loss: 0.335 | Train Acc:  92.34%\n",
      "Epoch 147 | Val Loss: 0.322 | Val Acc:  93.25%\n",
      "learning rate: [0.0005]\n",
      "Epoch 148 | Train Loss: 0.341 | Train Acc:  92.02%\n",
      "Epoch 148 | Val Loss: 0.331 | Val Acc:  92.21%\n",
      "learning rate: [0.0005]\n",
      "Epoch 149 | Train Loss: 0.330 | Train Acc:  92.55%\n",
      "Epoch 149 | Val Loss: 0.351 | Val Acc:  90.66%\n",
      "learning rate: [0.00025]\n",
      "Epoch 150 | Train Loss: 0.311 | Train Acc:  94.02%\n",
      "Epoch 150 | Val Loss: 0.300 | Val Acc:  94.66%\n",
      "learning rate: [0.00025]\n",
      "Epoch 151 | Train Loss: 0.306 | Train Acc:  94.33%\n",
      "Epoch 151 | Val Loss: 0.297 | Val Acc:  94.94%\n",
      "learning rate: [0.00025]\n",
      "Epoch 152 | Train Loss: 0.306 | Train Acc:  94.50%\n",
      "Epoch 152 | Val Loss: 0.299 | Val Acc:  94.57%\n",
      "learning rate: [0.00025]\n",
      "Epoch 153 | Train Loss: 0.303 | Train Acc:  94.46%\n",
      "Epoch 153 | Val Loss: 0.298 | Val Acc:  94.94%\n",
      "learning rate: [0.00025]\n",
      "Epoch 154 | Train Loss: 0.304 | Train Acc:  94.37%\n",
      "Epoch 154 | Val Loss: 0.294 | Val Acc:  95.14%\n",
      "learning rate: [0.00025]\n",
      "Epoch 155 | Train Loss: 0.302 | Train Acc:  94.57%\n",
      "Epoch 155 | Val Loss: 0.303 | Val Acc:  94.55%\n",
      "learning rate: [0.00025]\n",
      "Epoch 156 | Train Loss: 0.299 | Train Acc:  94.58%\n",
      "Epoch 156 | Val Loss: 0.302 | Val Acc:  94.38%\n",
      "learning rate: [0.00025]\n",
      "Epoch 157 | Train Loss: 0.298 | Train Acc:  94.73%\n",
      "Epoch 157 | Val Loss: 0.287 | Val Acc:  95.54%\n",
      "learning rate: [0.00025]\n",
      "Epoch 158 | Train Loss: 0.296 | Train Acc:  94.75%\n",
      "Epoch 158 | Val Loss: 0.285 | Val Acc:  95.51%\n",
      "learning rate: [0.00025]\n",
      "Epoch 159 | Train Loss: 0.293 | Train Acc:  95.01%\n",
      "Epoch 159 | Val Loss: 0.290 | Val Acc:  94.86%\n",
      "learning rate: [0.00025]\n",
      "Epoch 160 | Train Loss: 0.294 | Train Acc:  94.84%\n",
      "Epoch 160 | Val Loss: 0.302 | Val Acc:  94.05%\n",
      "learning rate: [0.00025]\n",
      "Epoch 161 | Train Loss: 0.295 | Train Acc:  94.74%\n",
      "Epoch 161 | Val Loss: 0.292 | Val Acc:  95.06%\n",
      "learning rate: [0.00025]\n",
      "Epoch 162 | Train Loss: 0.290 | Train Acc:  95.10%\n",
      "Epoch 162 | Val Loss: 0.279 | Val Acc:  95.77%\n",
      "learning rate: [0.00025]\n",
      "Epoch 163 | Train Loss: 0.291 | Train Acc:  94.98%\n",
      "Epoch 163 | Val Loss: 0.280 | Val Acc:  95.80%\n",
      "learning rate: [0.00025]\n",
      "Epoch 164 | Train Loss: 0.292 | Train Acc:  94.85%\n",
      "Epoch 164 | Val Loss: 0.303 | Val Acc:  93.92%\n",
      "learning rate: [0.00025]\n",
      "Epoch 165 | Train Loss: 0.290 | Train Acc:  95.12%\n",
      "Epoch 165 | Val Loss: 0.285 | Val Acc:  95.28%\n",
      "learning rate: [0.00025]\n",
      "Epoch 166 | Train Loss: 0.290 | Train Acc:  94.98%\n",
      "Epoch 166 | Val Loss: 0.286 | Val Acc:  95.29%\n",
      "learning rate: [0.00025]\n",
      "Epoch 167 | Train Loss: 0.281 | Train Acc:  95.64%\n",
      "Epoch 167 | Val Loss: 0.277 | Val Acc:  95.95%\n",
      "learning rate: [0.00025]\n",
      "Epoch 168 | Train Loss: 0.283 | Train Acc:  95.47%\n",
      "Epoch 168 | Val Loss: 0.287 | Val Acc:  95.07%\n",
      "learning rate: [0.00025]\n",
      "Epoch 169 | Train Loss: 0.282 | Train Acc:  95.58%\n",
      "Epoch 169 | Val Loss: 0.269 | Val Acc:  96.47%\n",
      "learning rate: [0.00025]\n",
      "Epoch 170 | Train Loss: 0.279 | Train Acc:  95.66%\n",
      "Epoch 170 | Val Loss: 0.278 | Val Acc:  95.70%\n",
      "learning rate: [0.00025]\n",
      "Epoch 171 | Train Loss: 0.278 | Train Acc:  95.72%\n",
      "Epoch 171 | Val Loss: 0.266 | Val Acc:  96.36%\n",
      "learning rate: [0.00025]\n",
      "Epoch 172 | Train Loss: 0.274 | Train Acc:  96.01%\n",
      "Epoch 172 | Val Loss: 0.266 | Val Acc:  96.59%\n",
      "learning rate: [0.00025]\n",
      "Epoch 173 | Train Loss: 0.275 | Train Acc:  95.80%\n",
      "Epoch 173 | Val Loss: 0.271 | Val Acc:  95.97%\n",
      "learning rate: [0.00025]\n",
      "Epoch 174 | Train Loss: 0.275 | Train Acc:  95.97%\n",
      "Epoch 174 | Val Loss: 0.276 | Val Acc:  95.84%\n",
      "learning rate: [0.00025]\n",
      "Epoch 175 | Train Loss: 0.273 | Train Acc:  95.93%\n",
      "Epoch 175 | Val Loss: 0.266 | Val Acc:  96.50%\n",
      "learning rate: [0.00025]\n",
      "Epoch 176 | Train Loss: 0.269 | Train Acc:  96.25%\n",
      "Epoch 176 | Val Loss: 0.266 | Val Acc:  96.40%\n",
      "learning rate: [0.00025]\n",
      "Epoch 177 | Train Loss: 0.267 | Train Acc:  96.32%\n",
      "Epoch 177 | Val Loss: 0.265 | Val Acc:  96.53%\n",
      "learning rate: [0.00025]\n",
      "Epoch 178 | Train Loss: 0.267 | Train Acc:  96.35%\n",
      "Epoch 178 | Val Loss: 0.274 | Val Acc:  95.72%\n",
      "learning rate: [0.00025]\n",
      "Epoch 179 | Train Loss: 0.265 | Train Acc:  96.40%\n",
      "Epoch 179 | Val Loss: 0.257 | Val Acc:  97.03%\n",
      "learning rate: [0.00025]\n",
      "Epoch 180 | Train Loss: 0.265 | Train Acc:  96.34%\n",
      "Epoch 180 | Val Loss: 0.256 | Val Acc:  96.97%\n",
      "learning rate: [0.00025]\n",
      "Epoch 181 | Train Loss: 0.264 | Train Acc:  96.48%\n",
      "Epoch 181 | Val Loss: 0.252 | Val Acc:  97.09%\n",
      "learning rate: [0.00025]\n",
      "Epoch 182 | Train Loss: 0.264 | Train Acc:  96.40%\n",
      "Epoch 182 | Val Loss: 0.256 | Val Acc:  96.89%\n",
      "learning rate: [0.00025]\n",
      "Epoch 183 | Train Loss: 0.262 | Train Acc:  96.60%\n",
      "Epoch 183 | Val Loss: 0.264 | Val Acc:  96.34%\n",
      "learning rate: [0.00025]\n",
      "Epoch 184 | Train Loss: 0.261 | Train Acc:  96.58%\n",
      "Epoch 184 | Val Loss: 0.251 | Val Acc:  97.23%\n",
      "learning rate: [0.00025]\n",
      "Epoch 185 | Train Loss: 0.259 | Train Acc:  96.62%\n",
      "Epoch 185 | Val Loss: 0.267 | Val Acc:  95.92%\n",
      "learning rate: [0.00025]\n",
      "Epoch 186 | Train Loss: 0.257 | Train Acc:  96.89%\n",
      "Epoch 186 | Val Loss: 0.262 | Val Acc:  96.63%\n",
      "learning rate: [0.00025]\n",
      "Epoch 187 | Train Loss: 0.255 | Train Acc:  96.99%\n",
      "Epoch 187 | Val Loss: 0.252 | Val Acc:  97.19%\n",
      "learning rate: [0.00025]\n",
      "Epoch 188 | Train Loss: 0.257 | Train Acc:  96.67%\n",
      "Epoch 188 | Val Loss: 0.244 | Val Acc:  97.62%\n",
      "learning rate: [0.00025]\n",
      "Epoch 189 | Train Loss: 0.252 | Train Acc:  97.07%\n",
      "Epoch 189 | Val Loss: 0.267 | Val Acc:  95.88%\n",
      "learning rate: [0.00025]\n",
      "Epoch 190 | Train Loss: 0.255 | Train Acc:  96.96%\n",
      "Epoch 190 | Val Loss: 0.240 | Val Acc:  97.87%\n",
      "learning rate: [0.00025]\n",
      "Epoch 191 | Train Loss: 0.249 | Train Acc:  97.35%\n",
      "Epoch 191 | Val Loss: 0.243 | Val Acc:  97.66%\n",
      "learning rate: [0.00025]\n",
      "Epoch 192 | Train Loss: 0.250 | Train Acc:  97.03%\n",
      "Epoch 192 | Val Loss: 0.238 | Val Acc:  98.00%\n",
      "learning rate: [0.00025]\n",
      "Epoch 193 | Train Loss: 0.246 | Train Acc:  97.44%\n",
      "Epoch 193 | Val Loss: 0.238 | Val Acc:  97.84%\n",
      "learning rate: [0.00025]\n",
      "Epoch 194 | Train Loss: 0.248 | Train Acc:  97.40%\n",
      "Epoch 194 | Val Loss: 0.263 | Val Acc:  96.05%\n",
      "learning rate: [0.00025]\n",
      "Epoch 195 | Train Loss: 0.252 | Train Acc:  97.04%\n",
      "Epoch 195 | Val Loss: 0.258 | Val Acc:  96.60%\n",
      "learning rate: [0.00025]\n",
      "Epoch 196 | Train Loss: 0.249 | Train Acc:  97.23%\n",
      "Epoch 196 | Val Loss: 0.252 | Val Acc:  96.84%\n",
      "learning rate: [0.00025]\n",
      "Epoch 197 | Train Loss: 0.245 | Train Acc:  97.51%\n",
      "Epoch 197 | Val Loss: 0.251 | Val Acc:  96.92%\n",
      "learning rate: [0.00025]\n",
      "Epoch 198 | Train Loss: 0.243 | Train Acc:  97.43%\n",
      "Epoch 198 | Val Loss: 0.240 | Val Acc:  97.44%\n",
      "learning rate: [0.00025]\n",
      "Epoch 199 | Train Loss: 0.243 | Train Acc:  97.49%\n",
      "Epoch 199 | Val Loss: 0.231 | Val Acc:  98.25%\n",
      "learning rate: [0.00025]\n",
      "Epoch 200 | Train Loss: 0.237 | Train Acc:  97.90%\n",
      "Epoch 200 | Val Loss: 0.231 | Val Acc:  98.16%\n",
      "learning rate: [0.00025]\n",
      "Epoch 201 | Train Loss: 0.237 | Train Acc:  97.88%\n",
      "Epoch 201 | Val Loss: 0.241 | Val Acc:  97.75%\n",
      "learning rate: [0.00025]\n",
      "Epoch 202 | Train Loss: 0.236 | Train Acc:  97.97%\n",
      "Epoch 202 | Val Loss: 0.231 | Val Acc:  98.27%\n",
      "learning rate: [0.00025]\n",
      "Epoch 203 | Train Loss: 0.236 | Train Acc:  97.97%\n",
      "Epoch 203 | Val Loss: 0.231 | Val Acc:  98.03%\n",
      "learning rate: [0.00025]\n",
      "Epoch 204 | Train Loss: 0.240 | Train Acc:  97.63%\n",
      "Epoch 204 | Val Loss: 0.246 | Val Acc:  97.36%\n",
      "learning rate: [0.00025]\n",
      "Epoch 205 | Train Loss: 0.236 | Train Acc:  97.97%\n",
      "Epoch 205 | Val Loss: 0.230 | Val Acc:  98.10%\n",
      "learning rate: [0.00025]\n",
      "Epoch 206 | Train Loss: 0.233 | Train Acc:  98.05%\n",
      "Epoch 206 | Val Loss: 0.230 | Val Acc:  98.20%\n",
      "learning rate: [0.00025]\n",
      "Epoch 207 | Train Loss: 0.232 | Train Acc:  98.14%\n",
      "Epoch 207 | Val Loss: 0.223 | Val Acc:  98.72%\n",
      "learning rate: [0.00025]\n",
      "Epoch 208 | Train Loss: 0.230 | Train Acc:  98.28%\n",
      "Epoch 208 | Val Loss: 0.225 | Val Acc:  98.34%\n",
      "learning rate: [0.00025]\n",
      "Epoch 209 | Train Loss: 0.229 | Train Acc:  98.29%\n",
      "Epoch 209 | Val Loss: 0.223 | Val Acc:  98.62%\n",
      "learning rate: [0.00025]\n",
      "Epoch 210 | Train Loss: 0.234 | Train Acc:  97.88%\n",
      "Epoch 210 | Val Loss: 0.222 | Val Acc:  98.72%\n",
      "learning rate: [0.00025]\n",
      "Epoch 211 | Train Loss: 0.228 | Train Acc:  98.28%\n",
      "Epoch 211 | Val Loss: 0.229 | Val Acc:  98.25%\n",
      "learning rate: [0.00025]\n",
      "Epoch 212 | Train Loss: 0.227 | Train Acc:  98.38%\n",
      "Epoch 212 | Val Loss: 0.227 | Val Acc:  98.26%\n",
      "learning rate: [0.00025]\n",
      "Epoch 213 | Train Loss: 0.226 | Train Acc:  98.49%\n",
      "Epoch 213 | Val Loss: 0.217 | Val Acc:  98.75%\n",
      "learning rate: [0.00025]\n",
      "Epoch 214 | Train Loss: 0.224 | Train Acc:  98.59%\n",
      "Epoch 214 | Val Loss: 0.217 | Val Acc:  98.82%\n",
      "learning rate: [0.00025]\n",
      "Epoch 215 | Train Loss: 0.224 | Train Acc:  98.49%\n",
      "Epoch 215 | Val Loss: 0.220 | Val Acc:  98.62%\n",
      "learning rate: [0.00025]\n",
      "Epoch 216 | Train Loss: 0.224 | Train Acc:  98.48%\n",
      "Epoch 216 | Val Loss: 0.237 | Val Acc:  97.72%\n",
      "learning rate: [0.00025]\n",
      "Epoch 217 | Train Loss: 0.222 | Train Acc:  98.63%\n",
      "Epoch 217 | Val Loss: 0.216 | Val Acc:  98.90%\n",
      "learning rate: [0.00025]\n",
      "Epoch 218 | Train Loss: 0.221 | Train Acc:  98.69%\n",
      "Epoch 218 | Val Loss: 0.231 | Val Acc:  97.69%\n",
      "learning rate: [0.00025]\n",
      "Epoch 219 | Train Loss: 0.224 | Train Acc:  98.43%\n",
      "Epoch 219 | Val Loss: 0.216 | Val Acc:  98.85%\n",
      "learning rate: [0.00025]\n",
      "Epoch 220 | Train Loss: 0.221 | Train Acc:  98.60%\n",
      "Epoch 220 | Val Loss: 0.217 | Val Acc:  98.68%\n",
      "learning rate: [0.00025]\n",
      "Epoch 221 | Train Loss: 0.220 | Train Acc:  98.66%\n",
      "Epoch 221 | Val Loss: 0.210 | Val Acc:  99.19%\n",
      "learning rate: [0.00025]\n",
      "Epoch 222 | Train Loss: 0.218 | Train Acc:  98.74%\n",
      "Epoch 222 | Val Loss: 0.211 | Val Acc:  99.13%\n",
      "learning rate: [0.00025]\n",
      "Epoch 223 | Train Loss: 0.217 | Train Acc:  98.87%\n",
      "Epoch 223 | Val Loss: 0.208 | Val Acc:  99.30%\n",
      "learning rate: [0.00025]\n",
      "Epoch 224 | Train Loss: 0.216 | Train Acc:  98.90%\n",
      "Epoch 224 | Val Loss: 0.220 | Val Acc:  98.65%\n",
      "learning rate: [0.000125]\n",
      "Epoch 225 | Train Loss: 0.211 | Train Acc:  99.13%\n",
      "Epoch 225 | Val Loss: 0.206 | Val Acc:  99.31%\n",
      "learning rate: [0.000125]\n",
      "Epoch 226 | Train Loss: 0.209 | Train Acc:  99.19%\n",
      "Epoch 226 | Val Loss: 0.208 | Val Acc:  99.20%\n",
      "learning rate: [0.000125]\n",
      "Epoch 227 | Train Loss: 0.208 | Train Acc:  99.23%\n",
      "Epoch 227 | Val Loss: 0.206 | Val Acc:  99.30%\n",
      "learning rate: [0.000125]\n",
      "Epoch 228 | Train Loss: 0.207 | Train Acc:  99.22%\n",
      "Epoch 228 | Val Loss: 0.205 | Val Acc:  99.35%\n",
      "learning rate: [0.000125]\n",
      "Epoch 229 | Train Loss: 0.207 | Train Acc:  99.25%\n",
      "Epoch 229 | Val Loss: 0.206 | Val Acc:  99.35%\n",
      "learning rate: [0.000125]\n",
      "Epoch 230 | Train Loss: 0.207 | Train Acc:  99.28%\n",
      "Epoch 230 | Val Loss: 0.207 | Val Acc:  99.25%\n",
      "learning rate: [0.000125]\n",
      "Epoch 231 | Train Loss: 0.206 | Train Acc:  99.31%\n",
      "Epoch 231 | Val Loss: 0.209 | Val Acc:  99.07%\n",
      "learning rate: [0.000125]\n",
      "Epoch 232 | Train Loss: 0.206 | Train Acc:  99.33%\n",
      "Epoch 232 | Val Loss: 0.203 | Val Acc:  99.34%\n",
      "learning rate: [0.000125]\n",
      "Epoch 233 | Train Loss: 0.206 | Train Acc:  99.28%\n",
      "Epoch 233 | Val Loss: 0.202 | Val Acc:  99.46%\n",
      "learning rate: [0.000125]\n",
      "Epoch 234 | Train Loss: 0.207 | Train Acc:  99.23%\n",
      "Epoch 234 | Val Loss: 0.208 | Val Acc:  99.21%\n",
      "learning rate: [0.000125]\n",
      "Epoch 235 | Train Loss: 0.207 | Train Acc:  99.27%\n",
      "Epoch 235 | Val Loss: 0.203 | Val Acc:  99.31%\n",
      "learning rate: [0.000125]\n",
      "Epoch 236 | Train Loss: 0.205 | Train Acc:  99.33%\n",
      "Epoch 236 | Val Loss: 0.209 | Val Acc:  99.02%\n",
      "learning rate: [0.000125]\n",
      "Epoch 237 | Train Loss: 0.204 | Train Acc:  99.39%\n",
      "Epoch 237 | Val Loss: 0.209 | Val Acc:  99.01%\n",
      "learning rate: [0.000125]\n",
      "Epoch 238 | Train Loss: 0.206 | Train Acc:  99.27%\n",
      "Epoch 238 | Val Loss: 0.203 | Val Acc:  99.41%\n",
      "learning rate: [0.000125]\n",
      "Epoch 239 | Train Loss: 0.206 | Train Acc:  99.28%\n",
      "Epoch 239 | Val Loss: 0.206 | Val Acc:  99.29%\n",
      "learning rate: [0.000125]\n",
      "Epoch 240 | Train Loss: 0.203 | Train Acc:  99.38%\n",
      "Epoch 240 | Val Loss: 0.200 | Val Acc:  99.48%\n",
      "learning rate: [0.000125]\n",
      "Epoch 241 | Train Loss: 0.203 | Train Acc:  99.40%\n",
      "Epoch 241 | Val Loss: 0.199 | Val Acc:  99.52%\n",
      "learning rate: [0.000125]\n",
      "Epoch 242 | Train Loss: 0.203 | Train Acc:  99.40%\n",
      "Epoch 242 | Val Loss: 0.201 | Val Acc:  99.46%\n",
      "learning rate: [0.000125]\n",
      "Epoch 243 | Train Loss: 0.201 | Train Acc:  99.46%\n",
      "Epoch 243 | Val Loss: 0.199 | Val Acc:  99.54%\n",
      "learning rate: [0.000125]\n",
      "Epoch 244 | Train Loss: 0.203 | Train Acc:  99.36%\n",
      "Epoch 244 | Val Loss: 0.198 | Val Acc:  99.55%\n",
      "learning rate: [0.000125]\n",
      "Epoch 245 | Train Loss: 0.202 | Train Acc:  99.44%\n",
      "Epoch 245 | Val Loss: 0.200 | Val Acc:  99.47%\n",
      "learning rate: [0.000125]\n",
      "Epoch 246 | Train Loss: 0.201 | Train Acc:  99.44%\n",
      "Epoch 246 | Val Loss: 0.198 | Val Acc:  99.54%\n",
      "learning rate: [0.000125]\n",
      "Epoch 247 | Train Loss: 0.200 | Train Acc:  99.51%\n",
      "Epoch 247 | Val Loss: 0.199 | Val Acc:  99.43%\n",
      "learning rate: [0.000125]\n",
      "Epoch 248 | Train Loss: 0.200 | Train Acc:  99.49%\n",
      "Epoch 248 | Val Loss: 0.198 | Val Acc:  99.56%\n",
      "learning rate: [0.000125]\n",
      "Epoch 249 | Train Loss: 0.199 | Train Acc:  99.55%\n",
      "Epoch 249 | Val Loss: 0.197 | Val Acc:  99.57%\n",
      "learning rate: [0.000125]\n",
      "Epoch 250 | Train Loss: 0.200 | Train Acc:  99.49%\n",
      "Epoch 250 | Val Loss: 0.196 | Val Acc:  99.62%\n",
      "learning rate: [0.000125]\n",
      "Epoch 251 | Train Loss: 0.199 | Train Acc:  99.59%\n",
      "Epoch 251 | Val Loss: 0.200 | Val Acc:  99.39%\n",
      "learning rate: [0.000125]\n",
      "Epoch 252 | Train Loss: 0.199 | Train Acc:  99.56%\n",
      "Epoch 252 | Val Loss: 0.198 | Val Acc:  99.53%\n",
      "learning rate: [0.000125]\n",
      "Epoch 253 | Train Loss: 0.199 | Train Acc:  99.50%\n",
      "Epoch 253 | Val Loss: 0.195 | Val Acc:  99.56%\n",
      "learning rate: [0.000125]\n",
      "Epoch 254 | Train Loss: 0.198 | Train Acc:  99.57%\n",
      "Epoch 254 | Val Loss: 0.194 | Val Acc:  99.66%\n",
      "learning rate: [0.000125]\n",
      "Epoch 255 | Train Loss: 0.198 | Train Acc:  99.54%\n",
      "Epoch 255 | Val Loss: 0.198 | Val Acc:  99.58%\n",
      "learning rate: [0.000125]\n",
      "Epoch 256 | Train Loss: 0.200 | Train Acc:  99.46%\n",
      "Epoch 256 | Val Loss: 0.203 | Val Acc:  99.42%\n",
      "learning rate: [0.000125]\n",
      "Epoch 257 | Train Loss: 0.197 | Train Acc:  99.59%\n",
      "Epoch 257 | Val Loss: 0.201 | Val Acc:  99.42%\n",
      "learning rate: [0.000125]\n",
      "Epoch 258 | Train Loss: 0.197 | Train Acc:  99.61%\n",
      "Epoch 258 | Val Loss: 0.194 | Val Acc:  99.64%\n",
      "learning rate: [0.000125]\n",
      "Epoch 259 | Train Loss: 0.195 | Train Acc:  99.59%\n",
      "Epoch 259 | Val Loss: 0.193 | Val Acc:  99.64%\n",
      "learning rate: [0.000125]\n",
      "Epoch 260 | Train Loss: 0.197 | Train Acc:  99.54%\n",
      "Epoch 260 | Val Loss: 0.193 | Val Acc:  99.67%\n",
      "learning rate: [0.000125]\n",
      "Epoch 261 | Train Loss: 0.196 | Train Acc:  99.61%\n",
      "Epoch 261 | Val Loss: 0.194 | Val Acc:  99.65%\n",
      "learning rate: [0.000125]\n",
      "Epoch 262 | Train Loss: 0.195 | Train Acc:  99.64%\n",
      "Epoch 262 | Val Loss: 0.191 | Val Acc:  99.67%\n",
      "learning rate: [0.000125]\n",
      "Epoch 263 | Train Loss: 0.195 | Train Acc:  99.66%\n",
      "Epoch 263 | Val Loss: 0.191 | Val Acc:  99.71%\n",
      "learning rate: [0.000125]\n",
      "Epoch 264 | Train Loss: 0.195 | Train Acc:  99.61%\n",
      "Epoch 264 | Val Loss: 0.192 | Val Acc:  99.67%\n",
      "learning rate: [0.000125]\n",
      "Epoch 265 | Train Loss: 0.194 | Train Acc:  99.65%\n",
      "Epoch 265 | Val Loss: 0.191 | Val Acc:  99.72%\n",
      "learning rate: [0.000125]\n",
      "Epoch 266 | Train Loss: 0.194 | Train Acc:  99.69%\n",
      "Epoch 266 | Val Loss: 0.192 | Val Acc:  99.72%\n",
      "learning rate: [0.000125]\n",
      "Epoch 267 | Train Loss: 0.193 | Train Acc:  99.62%\n",
      "Epoch 267 | Val Loss: 0.191 | Val Acc:  99.69%\n",
      "learning rate: [0.000125]\n",
      "Epoch 268 | Train Loss: 0.193 | Train Acc:  99.69%\n",
      "Epoch 268 | Val Loss: 0.192 | Val Acc:  99.67%\n",
      "learning rate: [0.000125]\n",
      "Epoch 269 | Train Loss: 0.194 | Train Acc:  99.64%\n",
      "Epoch 269 | Val Loss: 0.193 | Val Acc:  99.69%\n",
      "learning rate: [0.000125]\n",
      "Epoch 270 | Train Loss: 0.194 | Train Acc:  99.61%\n",
      "Epoch 270 | Val Loss: 0.190 | Val Acc:  99.71%\n",
      "learning rate: [0.000125]\n",
      "Epoch 271 | Train Loss: 0.192 | Train Acc:  99.65%\n",
      "Epoch 271 | Val Loss: 0.189 | Val Acc:  99.77%\n",
      "learning rate: [0.000125]\n",
      "Epoch 272 | Train Loss: 0.192 | Train Acc:  99.67%\n",
      "Epoch 272 | Val Loss: 0.188 | Val Acc:  99.78%\n",
      "learning rate: [0.000125]\n",
      "Epoch 273 | Train Loss: 0.192 | Train Acc:  99.65%\n",
      "Epoch 273 | Val Loss: 0.196 | Val Acc:  99.56%\n",
      "learning rate: [0.000125]\n",
      "Epoch 274 | Train Loss: 0.191 | Train Acc:  99.74%\n",
      "Epoch 274 | Val Loss: 0.196 | Val Acc:  99.38%\n",
      "learning rate: [0.000125]\n",
      "Epoch 275 | Train Loss: 0.191 | Train Acc:  99.73%\n",
      "Epoch 275 | Val Loss: 0.189 | Val Acc:  99.71%\n",
      "learning rate: [0.000125]\n",
      "Epoch 276 | Train Loss: 0.191 | Train Acc:  99.72%\n",
      "Epoch 276 | Val Loss: 0.192 | Val Acc:  99.78%\n",
      "learning rate: [0.000125]\n",
      "Epoch 277 | Train Loss: 0.190 | Train Acc:  99.72%\n",
      "Epoch 277 | Val Loss: 0.187 | Val Acc:  99.76%\n",
      "learning rate: [0.000125]\n",
      "Epoch 278 | Train Loss: 0.190 | Train Acc:  99.75%\n",
      "Epoch 278 | Val Loss: 0.189 | Val Acc:  99.72%\n",
      "learning rate: [0.000125]\n",
      "Epoch 279 | Train Loss: 0.190 | Train Acc:  99.71%\n",
      "Epoch 279 | Val Loss: 0.186 | Val Acc:  99.79%\n",
      "learning rate: [0.000125]\n",
      "Epoch 280 | Train Loss: 0.190 | Train Acc:  99.75%\n",
      "Epoch 280 | Val Loss: 0.186 | Val Acc:  99.81%\n",
      "learning rate: [0.000125]\n",
      "Epoch 281 | Train Loss: 0.189 | Train Acc:  99.75%\n",
      "Epoch 281 | Val Loss: 0.186 | Val Acc:  99.84%\n",
      "learning rate: [0.000125]\n",
      "Epoch 282 | Train Loss: 0.189 | Train Acc:  99.74%\n",
      "Epoch 282 | Val Loss: 0.186 | Val Acc:  99.83%\n",
      "learning rate: [0.000125]\n",
      "Epoch 283 | Train Loss: 0.189 | Train Acc:  99.75%\n",
      "Epoch 283 | Val Loss: 0.196 | Val Acc:  99.56%\n",
      "learning rate: [0.000125]\n",
      "Epoch 284 | Train Loss: 0.188 | Train Acc:  99.76%\n",
      "Epoch 284 | Val Loss: 0.185 | Val Acc:  99.79%\n",
      "learning rate: [0.000125]\n",
      "Epoch 285 | Train Loss: 0.188 | Train Acc:  99.78%\n",
      "Epoch 285 | Val Loss: 0.190 | Val Acc:  99.69%\n",
      "learning rate: [0.000125]\n",
      "Epoch 286 | Train Loss: 0.188 | Train Acc:  99.78%\n",
      "Epoch 286 | Val Loss: 0.187 | Val Acc:  99.79%\n",
      "learning rate: [0.000125]\n",
      "Epoch 287 | Train Loss: 0.187 | Train Acc:  99.81%\n",
      "Epoch 287 | Val Loss: 0.186 | Val Acc:  99.82%\n",
      "learning rate: [0.000125]\n",
      "Epoch 288 | Train Loss: 0.187 | Train Acc:  99.80%\n",
      "Epoch 288 | Val Loss: 0.185 | Val Acc:  99.83%\n",
      "learning rate: [0.000125]\n",
      "Epoch 289 | Train Loss: 0.186 | Train Acc:  99.80%\n",
      "Epoch 289 | Val Loss: 0.186 | Val Acc:  99.80%\n",
      "learning rate: [0.000125]\n",
      "Epoch 290 | Train Loss: 0.187 | Train Acc:  99.80%\n",
      "Epoch 290 | Val Loss: 0.189 | Val Acc:  99.69%\n",
      "learning rate: [0.000125]\n",
      "Epoch 291 | Train Loss: 0.186 | Train Acc:  99.82%\n",
      "Epoch 291 | Val Loss: 0.184 | Val Acc:  99.79%\n",
      "learning rate: [0.000125]\n",
      "Epoch 292 | Train Loss: 0.186 | Train Acc:  99.83%\n",
      "Epoch 292 | Val Loss: 0.183 | Val Acc:  99.87%\n",
      "learning rate: [0.000125]\n",
      "Epoch 293 | Train Loss: 0.185 | Train Acc:  99.84%\n",
      "Epoch 293 | Val Loss: 0.186 | Val Acc:  99.82%\n",
      "learning rate: [0.000125]\n",
      "Epoch 294 | Train Loss: 0.185 | Train Acc:  99.82%\n",
      "Epoch 294 | Val Loss: 0.182 | Val Acc:  99.89%\n",
      "learning rate: [0.000125]\n",
      "Epoch 295 | Train Loss: 0.185 | Train Acc:  99.85%\n",
      "Epoch 295 | Val Loss: 0.184 | Val Acc:  99.85%\n",
      "learning rate: [0.000125]\n",
      "Epoch 296 | Train Loss: 0.185 | Train Acc:  99.83%\n",
      "Epoch 296 | Val Loss: 0.183 | Val Acc:  99.81%\n",
      "learning rate: [0.000125]\n",
      "Epoch 297 | Train Loss: 0.184 | Train Acc:  99.83%\n",
      "Epoch 297 | Val Loss: 0.183 | Val Acc:  99.84%\n",
      "learning rate: [0.000125]\n",
      "Epoch 298 | Train Loss: 0.184 | Train Acc:  99.87%\n",
      "Epoch 298 | Val Loss: 0.182 | Val Acc:  99.88%\n",
      "learning rate: [0.000125]\n",
      "Epoch 299 | Train Loss: 0.184 | Train Acc:  99.83%\n",
      "Epoch 299 | Val Loss: 0.182 | Val Acc:  99.83%\n",
      "learning rate: [6.25e-05]\n",
      "Epoch 300 | Train Loss: 0.182 | Train Acc:  99.86%\n",
      "Epoch 300 | Val Loss: 0.180 | Val Acc:  99.89%\n",
      "learning rate: [6.25e-05]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.optim.lr_scheduler.CosineAnnealingLR'>\n",
      "Epoch   0 | Train Loss: 1.476 | Train Acc:  33.53%\n",
      "Epoch   0 | Val Loss: 1.383 | Val Acc:  38.92%\n",
      "learning rate: [0.0009999726120980734]\n",
      "Epoch   1 | Train Loss: 1.357 | Train Acc:  40.22%\n",
      "Epoch   1 | Val Loss: 1.323 | Val Acc:  42.20%\n",
      "learning rate: [0.0009998904513956854]\n",
      "Epoch   2 | Train Loss: 1.310 | Train Acc:  42.74%\n",
      "Epoch   2 | Val Loss: 1.286 | Val Acc:  43.94%\n",
      "learning rate: [0.0009997535269026829]\n",
      "Epoch   3 | Train Loss: 1.277 | Train Acc:  44.47%\n",
      "Epoch   3 | Val Loss: 1.261 | Val Acc:  45.32%\n",
      "learning rate: [0.0009995618536343797]\n",
      "Epoch   4 | Train Loss: 1.258 | Train Acc:  44.99%\n",
      "Epoch   4 | Val Loss: 1.234 | Val Acc:  46.86%\n",
      "learning rate: [0.0009993154526099096]\n",
      "Epoch   5 | Train Loss: 1.232 | Train Acc:  46.88%\n",
      "Epoch   5 | Val Loss: 1.213 | Val Acc:  48.00%\n",
      "learning rate: [0.0009990143508499217]\n",
      "Epoch   6 | Train Loss: 1.212 | Train Acc:  48.10%\n",
      "Epoch   6 | Val Loss: 1.197 | Val Acc:  48.77%\n",
      "learning rate: [0.0009986585813736167]\n",
      "Epoch   7 | Train Loss: 1.189 | Train Acc:  49.24%\n",
      "Epoch   7 | Val Loss: 1.167 | Val Acc:  50.21%\n",
      "learning rate: [0.0009982481831951274]\n"
     ]
    }
   ],
   "source": [
    "# training information for polynomialLR to stepLR\n",
    "epochs = 300\n",
    "print(get_lr(model_gat.optimizer))\n",
    "scheduler_list = build_scheduler_list(epochs=epochs)\n",
    "print(scheduler_list)\n",
    "trained_gat = hyperparameter_tuning(model_gat, strat_train, strat_val, scheduler_list, batch_size = 256, epochs = epochs)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "002b91e340bb4f67a661a75a18d70716": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "08a83cfdb3e14b7fa0d9550d5157757f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bae4ff94e05b49f492940b780b06902b",
       "IPY_MODEL_eebcdac8356643e287857bb64a437311",
       "IPY_MODEL_f994056b677040abbe02b78d29657b13"
      ],
      "layout": "IPY_MODEL_bf2b1d7e2fe1456983417b452916e6f7"
     }
    },
    "0db679c436c2424d8ed70154a98c0d4f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fc138ff2b0c5475e9ed1ab89a3071208",
      "max": 30101,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5cdc78a581c240929f68ff98ddf0855e",
      "value": 30101
     }
    },
    "2153f77ceb624e61bf026fbff6401558": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2566161e57eb40798dbca65324ae1d87": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2d102cd39a9044db827334f508896608": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "30a50f3a69674d528ffe4dd348d1bfc9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8bd326c21c804168af3b6d42027de27a",
      "max": 594107770,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_31c64c73024e455ab0d46de7e501262b",
      "value": 594107770
     }
    },
    "31c64c73024e455ab0d46de7e501262b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3611d41b65524ac9be27926d32bcd8f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3c2686398da2437fa24952c53e7a8590": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f8ce672c8784180bc7192caf85a1c9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3c2686398da2437fa24952c53e7a8590",
      "placeholder": "​",
      "style": "IPY_MODEL_e7a834ab5906438b890eca384580b00e",
      "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json: "
     }
    },
    "54d11f0e363843b2b93aa46d91a75ecd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a2460b93db0e421981ed71e57e5afd14",
      "placeholder": "​",
      "style": "IPY_MODEL_002b91e340bb4f67a661a75a18d70716",
      "value": " 594M/594M [00:01&lt;00:00, 298MB/s]"
     }
    },
    "5cdc78a581c240929f68ff98ddf0855e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "831e50de14314050b9a568c248561039": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8bd326c21c804168af3b6d42027de27a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8f4cf33b2e4f4c29805578124f31715c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "956e93be5fbd41eb91fd48aaf359d0db": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b2ff8d09b494f80b0880abd06e901bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9ba649205fba4ab9b32117351252702e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c35c428319ec49debec137185718f8df",
       "IPY_MODEL_30a50f3a69674d528ffe4dd348d1bfc9",
       "IPY_MODEL_54d11f0e363843b2b93aa46d91a75ecd"
      ],
      "layout": "IPY_MODEL_af347f2a8e0a4544afba843f28c46de7"
     }
    },
    "a2460b93db0e421981ed71e57e5afd14": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af347f2a8e0a4544afba843f28c46de7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bae4ff94e05b49f492940b780b06902b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dca734e705be4e6baf26830734f19e5d",
      "placeholder": "​",
      "style": "IPY_MODEL_3611d41b65524ac9be27926d32bcd8f8",
      "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json: "
     }
    },
    "bf2b1d7e2fe1456983417b452916e6f7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c35c428319ec49debec137185718f8df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dddd7fb1534c47baada9a154c17d54c2",
      "placeholder": "​",
      "style": "IPY_MODEL_2d102cd39a9044db827334f508896608",
      "value": "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.5.0/models/default.zip: 100%"
     }
    },
    "dca734e705be4e6baf26830734f19e5d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dddd7fb1534c47baada9a154c17d54c2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e7a834ab5906438b890eca384580b00e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e9341dbf06664cb1b3d0f337989b65b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4f8ce672c8784180bc7192caf85a1c9e",
       "IPY_MODEL_0db679c436c2424d8ed70154a98c0d4f",
       "IPY_MODEL_fbbcff1a383e46e1bce17a06a2a20d50"
      ],
      "layout": "IPY_MODEL_f1c424dcc40645aa81f2f2df7c3e117c"
     }
    },
    "eebcdac8356643e287857bb64a437311": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_956e93be5fbd41eb91fd48aaf359d0db",
      "max": 30101,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2153f77ceb624e61bf026fbff6401558",
      "value": 30101
     }
    },
    "f1c424dcc40645aa81f2f2df7c3e117c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f994056b677040abbe02b78d29657b13": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8f4cf33b2e4f4c29805578124f31715c",
      "placeholder": "​",
      "style": "IPY_MODEL_9b2ff8d09b494f80b0880abd06e901bc",
      "value": " 216k/? [00:00&lt;00:00, 8.33MB/s]"
     }
    },
    "fbbcff1a383e46e1bce17a06a2a20d50": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_831e50de14314050b9a568c248561039",
      "placeholder": "​",
      "style": "IPY_MODEL_2566161e57eb40798dbca65324ae1d87",
      "value": " 216k/? [00:00&lt;00:00, 7.84MB/s]"
     }
    },
    "fc138ff2b0c5475e9ed1ab89a3071208": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
