{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install stanza\n",
        "!pip install torch-geometric"
      ],
      "metadata": {
        "id": "O65H_39pjzll",
        "outputId": "99f2759f-b010-43ba-a416-070b98c8072a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "O65H_39pjzll",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stanza\n",
            "  Downloading stanza-1.5.0-py3-none-any.whl (802 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.5/802.5 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting emoji (from stanza)\n",
            "  Downloading emoji-2.8.0-py2.py3-none-any.whl (358 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m358.9/358.9 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from stanza) (1.23.5)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from stanza) (3.20.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from stanza) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from stanza) (1.16.0)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from stanza) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stanza) (4.66.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.3.0->stanza) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.3.0->stanza) (16.0.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3.0->stanza) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3.0->stanza) (1.3.0)\n",
            "Installing collected packages: emoji, stanza\n",
            "Successfully installed emoji-2.8.0 stanza-1.5.0\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.3.1.tar.gz (661 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.6/661.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2023.7.22)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.2.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.3.1-py3-none-any.whl size=910454 sha256=e59f5aa2ee5f44d6f392a671b4a0483e0a13e71d80c55bd2c543d84fa58747f4\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/dc/30/e2874821ff308ee67dcd7a66dbde912411e19e35a1addda028\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "src = list(files.upload().values())[0]\n",
        "open('utils.py','wb').write(src)\n",
        "import utils"
      ],
      "metadata": {
        "id": "6yqdrQQljb7U",
        "outputId": "71df638f-0980-4823-e2d7-8716657eaa77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "id": "6yqdrQQljb7U",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-51723b4b-cacd-4451-820d-eec5b581a332\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-51723b4b-cacd-4451-820d-eec5b581a332\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving utils.py to utils (4).py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "6820bb71",
      "metadata": {
        "id": "6820bb71"
      },
      "outputs": [],
      "source": [
        "#import utils\n",
        "import copy\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import save, load\n",
        "import torch.nn as nn\n",
        "\n",
        "from torch_geometric.data import Data, Batch\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.data import Dataset, InMemoryDataset\n",
        "from torch_geometric.utils import scatter\n",
        "from torch_geometric.data import download_url\n",
        "\n",
        "from torch_geometric.nn import GCNConv, GATv2Conv, global_mean_pool\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Linear, Dropout\n",
        "\n",
        "from functools import partial\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from torch.optim.lr_scheduler import PolynomialLR\n",
        "from torch_geometric.nn.pool import global_max_pool\n",
        "from torch.optim.lr_scheduler import OneCycleLR"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "K3zT6rr_jAhv",
        "outputId": "04f9b4a7-0a88-4058-9a0b-927a08d2427e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "K3zT6rr_jAhv",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "00150981",
      "metadata": {
        "id": "00150981",
        "outputId": "957d2d59-5a5b-42b5-9c62-d56bb6aabc26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "4463a9d3",
      "metadata": {
        "id": "4463a9d3",
        "outputId": "881614e8-13cf-4c59-df5d-1a87cc4e1906",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/processed_train//train.pt']\n",
            "['/content/processed_test//test.pt']\n",
            "Loaded training dataset:\n",
            "Dataset_from_sentences(25948)\n",
            "Loaded test dataset:\n",
            "Dataset_from_sentences(6487)\n",
            "Loaded training and validation sets as result of stratified k-fold:\n",
            "Dataset_from_sentences(22704)\n",
            "Dataset_from_sentences(3244)\n"
          ]
        }
      ],
      "source": [
        "tweet_list_train = []\n",
        "sentiment_list_train = []\n",
        "tweet_list_test = []\n",
        "sentiment_list_test = []\n",
        "cv19_graph_data_train = utils.Dataset_from_sentences(\"train\", \"/content/processed_train/\",\n",
        "                                                     \"/content/drive/MyDrive/GraphDataset/train/\",\n",
        "                                                     tweet_list_train, sentiment_list_train)\n",
        "cv19_graph_data_test = utils.Dataset_from_sentences(\"test\", \"/content/processed_test/\",\n",
        "                                                    \"/content/drive/MyDrive/GraphDataset/test/\",\n",
        "                                                    tweet_list_test, sentiment_list_test)\n",
        "strat_train = load(\"/content/drive/MyDrive/StratifiedSplit/strat_train.pt\")\n",
        "strat_val = load(\"/content/drive/MyDrive/StratifiedSplit/strat_val.pt\")\n",
        "print(\"Loaded training dataset:\")\n",
        "print(cv19_graph_data_train)\n",
        "print(\"Loaded test dataset:\")\n",
        "print(cv19_graph_data_test)\n",
        "print(\"Loaded training and validation sets as result of stratified k-fold:\")\n",
        "print(strat_train)\n",
        "print(strat_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "3f8e0549",
      "metadata": {
        "id": "3f8e0549"
      },
      "outputs": [],
      "source": [
        "# GCN definition\n",
        "class GCN(torch.nn.Module):\n",
        "  \"\"\"Graph Convolutional Network\"\"\"\n",
        "  def __init__(self, dim_in, n_filters, dim_out):\n",
        "    super().__init__()\n",
        "\n",
        "    self.first_linear = Linear(dim_in, dim_in)\n",
        "\n",
        "    self.gcn_list_1 = torch.nn.ModuleList([GCNConv(dim_in, dim_in, add_self_loops = True)\n",
        "                                         for i in range(0, n_filters)])\n",
        "    self.gcn_list_2 = torch.nn.ModuleList([GCNConv(dim_in, dim_in, add_self_loops = True)\n",
        "                                         for i in range(0, n_filters)])\n",
        "    self.gcn_list_3 = torch.nn.ModuleList([GCNConv(dim_in, dim_in, add_self_loops = True)\n",
        "                                         for i in range(0, n_filters)])\n",
        "\n",
        "    #self.gcn_1 = GCNConv(dim_in, dim_in, add_self_loops = True)\n",
        "    #self.gcn_2 = GCNConv(dim_in, dim_in, add_self_loops = True)\n",
        "    #self.gcn_3 = GCNConv(dim_in, dim_in, add_self_loops = True)\n",
        "    self.l_list = torch.nn.ModuleList([Linear(dim_in, 1)\n",
        "                                      for i in range(0, n_filters)])\n",
        "    self.classifier = Linear(n_filters, dim_out)\n",
        "    self.optimizer = torch.optim.Adam(self.parameters(),\n",
        "                                      lr=1e-3,\n",
        "                                      weight_decay=5e-5)\n",
        "\n",
        "  def forward(self, x, edge_index, batch, enable_log = False):\n",
        "    # the parameters of the forward correspond to data.x and data.edge_index\n",
        "    # where data is a Data object like those described above;\n",
        "    if enable_log:\n",
        "        utils.visualize_hidden_graph(x, edge_index)\n",
        "\n",
        "    #h = self.first_linear(x)\n",
        "\n",
        "    h_list = []\n",
        "    for i, gcn_l in enumerate(self.gcn_list_1):\n",
        "        h = x + gcn_l(x, edge_index)\n",
        "        h = h.tanh()\n",
        "        h = h + self.gcn_list_2[i](h, edge_index)\n",
        "        h = h.tanh()\n",
        "        h = h + self.gcn_list_3[i](h, edge_index)\n",
        "        if enable_log:\n",
        "            print(\"h shape: \" + str(h.shape))\n",
        "            utils.visualize_hidden_graph(h, edge_index)\n",
        "        h = global_mean_pool(h, batch)\n",
        "        h = self.l_list[i](h)\n",
        "        h_list.append(h)\n",
        "\n",
        "    h_layers = torch.hstack(h_list)\n",
        "    #print(h_layers.shape)\n",
        "    h_layers = self.classifier(h_layers)\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    h = self.first_linear(x)\n",
        "    h = h + self.gcn_1(h, edge_index)\n",
        "    h = h + self.gcn_2(h, edge_index)\n",
        "    h = h + self.gcn_3(h, edge_index)\n",
        "    if enable_log:\n",
        "        visualize_hidden_graph(x, edge_index)\n",
        "    h = global_mean_pool(h, batch)\n",
        "    h = self.classifier(h)\n",
        "    \"\"\"\n",
        "\n",
        "    return h_layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "5faf4690",
      "metadata": {
        "id": "5faf4690"
      },
      "outputs": [],
      "source": [
        "# actual GAT class\n",
        "# this must be modified\n",
        "class GAT(torch.nn.Module):\n",
        "  \"\"\"Graph Attention Network\"\"\"\n",
        "  def __init__(self, dim_in, n_filters, dim_out, heads= 8):\n",
        "    super().__init__()\n",
        "    # dim_in is the number of node features, dim_h is the dimension\n",
        "    # of the hidden layer, dim_out is the dimension of the output\n",
        "    # feature vector\n",
        "    self.first_linear = Linear(dim_in, dim_in)\n",
        "\n",
        "    self.gat_list_1 = torch.nn.ModuleList([GATv2Conv(dim_in, dim_in // 2, heads = heads)\n",
        "                                         for i in range(0, n_filters)])\n",
        "    self.gat_list_2 = torch.nn.ModuleList([GATv2Conv(dim_in, dim_in // 2, heads = heads)\n",
        "                                         for i in range(0, n_filters)])\n",
        "    self.gat_list_3 = torch.nn.ModuleList([GATv2Conv(dim_in, dim_in // 2, heads = heads)\n",
        "                                         for i in range(0, n_filters)])\n",
        "\n",
        "    self.l_list = torch.nn.ModuleList([Linear(dim_in, 1)\n",
        "                                      for i in range(0, n_filters)])\n",
        "    self.classifier = Linear(n_filters, dim_out)\n",
        "    self.optimizer = torch.optim.Adam(self.parameters(),\n",
        "                                      lr=1e-3,\n",
        "                                      weight_decay=5e-5)\n",
        "\n",
        "  def forward(self, x, edge_index, batch, enable_log = False):\n",
        "    # the parameters of the forward correspond to data.x and data.edge_index\n",
        "    # where data is a Data object like those described above;\n",
        "    if enable_log:\n",
        "        utils.visualize_hidden_graph(x, edge_index)\n",
        "\n",
        "    #h = self.first_linear(x)\n",
        "\n",
        "    h_list = []\n",
        "    for i, gat_l in enumerate(self.gat_list_1):\n",
        "        h = x + gat_l(x, edge_index)\n",
        "        h = h.tanh()\n",
        "        h = h + self.gat_list_2[i](h, edge_index)\n",
        "        h = h.tanh()\n",
        "        h = h + self.gat_list_3[i](h, edge_index)\n",
        "        if enable_log:\n",
        "            print(\"h shape: \" + str(h.shape))\n",
        "            utils.visualize_hidden_graph(h, edge_index)\n",
        "        h = global_mean_pool(h, batch)\n",
        "        h = self.l_list[i](h)\n",
        "        h_list.append(h)\n",
        "\n",
        "    h_layers = torch.hstack(h_list)\n",
        "    #print(h_layers.shape)\n",
        "    h_layers = self.classifier(h_layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "ec6fa11f",
      "metadata": {
        "id": "ec6fa11f"
      },
      "outputs": [],
      "source": [
        "class EarlyStopper:\n",
        "  def __init__(self, patience=1, min_delta=0):\n",
        "      self.patience = patience\n",
        "      self.min_delta = min_delta\n",
        "      self.counter = 0\n",
        "      self.min_validation_loss = np.inf\n",
        "\n",
        "  def early_stop(self, validation_loss):\n",
        "      if validation_loss < self.min_validation_loss:\n",
        "          self.min_validation_loss = validation_loss\n",
        "          self.counter = 0\n",
        "      elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
        "          self.counter += 1\n",
        "          if self.counter >= self.patience:\n",
        "              return True\n",
        "      return False\n",
        "\n",
        "def plot_losses(train_losses, val_losses):\n",
        "    \"\"\"\n",
        "    Plots the training and validation losses over the course of training.\n",
        "    Args:\n",
        "        train_losses: A list of training losses.\n",
        "        val_losses: A list of validation losses.\n",
        "    \"\"\"\n",
        "    plt.plot(train_losses, label='Train Loss')\n",
        "    plt.plot(val_losses, label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def accuracy(pred_y, y):\n",
        "    \"\"\"Calculate accuracy.\"\"\"\n",
        "    return ((pred_y == y).sum() / len(y)).item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "6f38b1c3",
      "metadata": {
        "id": "6f38b1c3"
      },
      "outputs": [],
      "source": [
        "def train(model, strat_train, strat_val, partial_scheduler, epochs = 30, batch_size = 30, print_every = 1):\n",
        "    \"\"\"Train a GNN model and return the trained model.\"\"\"\n",
        "    batch_size = batch_size\n",
        "    criterion = torch.nn.CrossEntropyLoss(label_smoothing = 0.01)\n",
        "    optimizer = model.optimizer\n",
        "    scheduler = partial_scheduler(optimizer)\n",
        "    print(type(scheduler))\n",
        "    loader_train =  DataLoader(strat_train.data_list, batch_size=batch_size, shuffle=True)\n",
        "    loader_val = DataLoader(strat_val.data_list, batch_size=batch_size, shuffle=True)\n",
        "    model.train()\n",
        "    early_stopper = EarlyStopper(patience=10, min_delta=0.2)\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    best_model = []\n",
        "    best_acc_val = 0\n",
        "    epochs_to_return = 0\n",
        "\n",
        "    #scheduler.step()\n",
        "    for epoch in range(epochs+1):\n",
        "      mean_loss_train = 0\n",
        "      mean_acc_train = 0\n",
        "      for i, batch in enumerate(loader_train):\n",
        "        # Training\n",
        "\n",
        "        out = model(batch.x, batch.edge_index, batch.batch)\n",
        "        loss_train = criterion(out, batch.y.long())\n",
        "        mean_loss_train += loss_train.item()\n",
        "\n",
        "        acc_train = accuracy(out.argmax(dim=1), batch.y)\n",
        "        mean_acc_train += acc_train\n",
        "        loss_train.backward()\n",
        "        with torch.no_grad():\n",
        "            optimizer.step()\n",
        "            if type(scheduler) == OneCycleLR:\n",
        "                scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "      mean_loss_train /= i\n",
        "      mean_acc_train /= i\n",
        "      train_losses.append(mean_loss_train)\n",
        "      if type(scheduler) != OneCycleLR:\n",
        "          scheduler.step()\n",
        "\n",
        "      mean_loss_val = 0\n",
        "      mean_acc_val = 0\n",
        "      with torch.no_grad():\n",
        "          for i, batch in enumerate(loader_val):\n",
        "            out = model(batch.x, batch.edge_index, batch.batch)\n",
        "            loss_val = criterion(out, batch.y.long())\n",
        "            mean_loss_val += loss_val.item()\n",
        "            acc_val = accuracy(out.argmax(dim=1), batch.y)\n",
        "            mean_acc_val += acc_val\n",
        "            #visualize_embedding(embed, batch.y, epoch, loss_val)\n",
        "          mean_loss_val /= i\n",
        "          mean_acc_val /= i\n",
        "          val_losses.append(mean_loss_val)\n",
        "          if mean_acc_val > best_acc_val:\n",
        "                best_acc_val = mean_acc_val\n",
        "                best_model = copy.deepcopy(model)\n",
        "                epochs_to_return = epoch\n",
        "\n",
        "      if(epoch % print_every == 0):\n",
        "        print(f'Epoch {epoch:>3} | Train Loss: {mean_loss_train:.3f} | Train Acc: '\n",
        "              f'{mean_acc_train*100:>6.2f}%')\n",
        "        print(f'Epoch {epoch:>3} | Val Loss: {mean_loss_val:.3f} | Val Acc: '\n",
        "              f'{mean_acc_val*100:>6.2f}%')\n",
        "        print(\"learning rate: \" + str(scheduler.get_last_lr()))\n",
        "      if early_stopper.early_stop(mean_loss_val):\n",
        "        print(\"early stopping was triggered, final loss:\" + str(mean_loss_val))\n",
        "        break\n",
        "    plot_losses(train_losses, val_losses)\n",
        "    return best_model, best_acc_val, epochs_to_return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "a89b74e7",
      "metadata": {
        "id": "a89b74e7"
      },
      "outputs": [],
      "source": [
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "def build_scheduler_list(epochs = 30, max_lr = 1e-3):\n",
        "    schedulers = []\n",
        "    schedulers += [partial(PolynomialLR,\n",
        "                         total_iters = epochs, # The number of steps that the scheduler decays the learning rate.\n",
        "                         power = i) for i in range(1, 3)] # The power of the polynomial.\n",
        "    schedulers += [partial(StepLR,\n",
        "                                  step_size=epochs//i, gamma=0.5) for i in range(3, 5)]\n",
        "    schedulers += [partial(CosineAnnealingLR,\n",
        "                              T_max = epochs, # Maximum number of iterations.\n",
        "                              eta_min = min_lr) for min_lr in [1e-6, 1e-7, 1e-8]]# Minimum learning rate\n",
        "\n",
        "    schedulers += [partial(OneCycleLR,\n",
        "                       max_lr = max_lr, # Upper learning rate boundaries in the cycle for each parameter group\n",
        "                       steps_per_epoch = i, # The number of steps per epoch to train for.\n",
        "                       epochs = epochs, # The number of epochs to train for.\n",
        "                       anneal_strategy = 'cos') for i in [10, 50, 100]] # Specifies the annealing strategy\n",
        "    return schedulers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "941dee58",
      "metadata": {
        "id": "941dee58"
      },
      "outputs": [],
      "source": [
        "def hyperparameter_tuning(model, strat_train, strat_val, scheduler_list, batch_size = 30, epochs = 30):\n",
        "    print(f\"batch size: {batch_size}\")\n",
        "    best_valid_acc = 0\n",
        "    best_model = []\n",
        "    best_hyper_params = []\n",
        "    best_val_acc = 0\n",
        "    for partial_scheduler in scheduler_list:\n",
        "        model_out, mean_acc_val, epoch = train(copy.deepcopy(model), strat_train, strat_val,\n",
        "                                               partial_scheduler, epochs, batch_size = batch_size, print_every=1)\n",
        "        if mean_acc_val > best_val_acc:\n",
        "            best_val_acc = mean_acc_val\n",
        "            best_model = model_out\n",
        "            best_hyper_params = [partial_scheduler, epoch]\n",
        "            print(f\"Improved result: acc {best_val_acc:.3f}, scheduler:\\n {partial_scheduler}\\nepoch: {epoch}\")\n",
        "    return best_hyper_params, best_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "a7faa84c",
      "metadata": {
        "id": "a7faa84c"
      },
      "outputs": [],
      "source": [
        "strat_train = strat_train.to(device)\n",
        "strat_val = strat_val.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "234a2ed8",
      "metadata": {
        "id": "234a2ed8",
        "outputId": "8242e153-e2ea-4c13-cae4-377a735102c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GCN(\n",
            "  (first_linear): Linear(in_features=50, out_features=50, bias=True)\n",
            "  (gcn_list_1): ModuleList(\n",
            "    (0-9): 10 x GCNConv(50, 50)\n",
            "  )\n",
            "  (gcn_list_2): ModuleList(\n",
            "    (0-9): 10 x GCNConv(50, 50)\n",
            "  )\n",
            "  (gcn_list_3): ModuleList(\n",
            "    (0-9): 10 x GCNConv(50, 50)\n",
            "  )\n",
            "  (l_list): ModuleList(\n",
            "    (0-9): 10 x Linear(in_features=50, out_features=1, bias=True)\n",
            "  )\n",
            "  (classifier): Linear(in_features=10, out_features=5, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model_gcn = GCN(cv19_graph_data_train.num_node_features,\n",
        "                cv19_graph_data_train.num_classes*2,\n",
        "                cv19_graph_data_train.num_classes).to(device)\n",
        "print(model_gcn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "770d5afc",
      "metadata": {
        "id": "770d5afc",
        "outputId": "c852bcbb-ebdb-4db6-8372-640b13324fcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.001\n",
            "[functools.partial(<class 'torch.optim.lr_scheduler.PolynomialLR'>, total_iters=30, power=1), functools.partial(<class 'torch.optim.lr_scheduler.PolynomialLR'>, total_iters=30, power=2), functools.partial(<class 'torch.optim.lr_scheduler.StepLR'>, step_size=10, gamma=0.5), functools.partial(<class 'torch.optim.lr_scheduler.StepLR'>, step_size=7, gamma=0.5), functools.partial(<class 'torch.optim.lr_scheduler.CosineAnnealingLR'>, T_max=30, eta_min=1e-06), functools.partial(<class 'torch.optim.lr_scheduler.CosineAnnealingLR'>, T_max=30, eta_min=1e-07), functools.partial(<class 'torch.optim.lr_scheduler.CosineAnnealingLR'>, T_max=30, eta_min=1e-08), functools.partial(<class 'torch.optim.lr_scheduler.OneCycleLR'>, max_lr=0.001, steps_per_epoch=10, epochs=30, anneal_strategy='cos'), functools.partial(<class 'torch.optim.lr_scheduler.OneCycleLR'>, max_lr=0.001, steps_per_epoch=50, epochs=30, anneal_strategy='cos'), functools.partial(<class 'torch.optim.lr_scheduler.OneCycleLR'>, max_lr=0.001, steps_per_epoch=100, epochs=30, anneal_strategy='cos')]\n"
          ]
        }
      ],
      "source": [
        "print(get_lr(model_gcn.optimizer))\n",
        "scheduler_list = build_scheduler_list()\n",
        "print(scheduler_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "804b3a57",
      "metadata": {
        "id": "804b3a57",
        "outputId": "1b62fbb4-991c-4a21-bb2d-989b1e67bb9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch size: 128\n",
            "<class 'torch.optim.lr_scheduler.PolynomialLR'>\n",
            "Epoch   0 | Train Loss: 1.474 | Train Acc:  33.77%\n",
            "Epoch   0 | Val Loss: 1.408 | Val Acc:  38.31%\n",
            "learning rate: [0.0009666666666666667]\n",
            "Epoch   1 | Train Loss: 1.401 | Train Acc:  38.34%\n",
            "Epoch   1 | Val Loss: 1.382 | Val Acc:  39.78%\n",
            "learning rate: [0.0009333333333333334]\n",
            "Epoch   2 | Train Loss: 1.386 | Train Acc:  39.53%\n",
            "Epoch   2 | Val Loss: 1.381 | Val Acc:  39.57%\n",
            "learning rate: [0.0009000000000000001]\n",
            "Epoch   3 | Train Loss: 1.376 | Train Acc:  40.00%\n",
            "Epoch   3 | Val Loss: 1.371 | Val Acc:  40.19%\n",
            "learning rate: [0.0008666666666666668]\n",
            "Epoch   4 | Train Loss: 1.368 | Train Acc:  40.52%\n",
            "Epoch   4 | Val Loss: 1.356 | Val Acc:  40.78%\n",
            "learning rate: [0.0008333333333333335]\n",
            "Epoch   5 | Train Loss: 1.360 | Train Acc:  40.90%\n",
            "Epoch   5 | Val Loss: 1.374 | Val Acc:  39.70%\n",
            "learning rate: [0.0008000000000000001]\n",
            "Epoch   6 | Train Loss: 1.354 | Train Acc:  41.15%\n",
            "Epoch   6 | Val Loss: 1.349 | Val Acc:  41.65%\n",
            "learning rate: [0.0007666666666666668]\n",
            "Epoch   7 | Train Loss: 1.345 | Train Acc:  41.72%\n",
            "Epoch   7 | Val Loss: 1.335 | Val Acc:  42.30%\n",
            "learning rate: [0.0007333333333333336]\n",
            "Epoch   8 | Train Loss: 1.339 | Train Acc:  42.07%\n",
            "Epoch   8 | Val Loss: 1.331 | Val Acc:  42.35%\n",
            "learning rate: [0.0007000000000000001]\n",
            "Epoch   9 | Train Loss: 1.333 | Train Acc:  42.06%\n",
            "Epoch   9 | Val Loss: 1.321 | Val Acc:  43.05%\n",
            "learning rate: [0.0006666666666666669]\n",
            "Epoch  10 | Train Loss: 1.325 | Train Acc:  42.76%\n",
            "Epoch  10 | Val Loss: 1.315 | Val Acc:  42.97%\n",
            "learning rate: [0.0006333333333333334]\n",
            "Epoch  11 | Train Loss: 1.321 | Train Acc:  42.99%\n",
            "Epoch  11 | Val Loss: 1.308 | Val Acc:  43.46%\n",
            "learning rate: [0.0006000000000000001]\n",
            "Epoch  12 | Train Loss: 1.312 | Train Acc:  43.44%\n",
            "Epoch  12 | Val Loss: 1.315 | Val Acc:  43.53%\n",
            "learning rate: [0.0005666666666666667]\n",
            "Epoch  13 | Train Loss: 1.308 | Train Acc:  43.58%\n",
            "Epoch  13 | Val Loss: 1.297 | Val Acc:  44.27%\n",
            "learning rate: [0.0005333333333333334]\n",
            "Epoch  14 | Train Loss: 1.303 | Train Acc:  43.87%\n",
            "Epoch  14 | Val Loss: 1.293 | Val Acc:  44.71%\n",
            "learning rate: [0.0005]\n",
            "Epoch  15 | Train Loss: 1.295 | Train Acc:  44.12%\n",
            "Epoch  15 | Val Loss: 1.288 | Val Acc:  44.38%\n",
            "learning rate: [0.00046666666666666666]\n",
            "Epoch  16 | Train Loss: 1.290 | Train Acc:  44.50%\n",
            "Epoch  16 | Val Loss: 1.284 | Val Acc:  44.62%\n",
            "learning rate: [0.00043333333333333337]\n",
            "Epoch  17 | Train Loss: 1.285 | Train Acc:  44.95%\n",
            "Epoch  17 | Val Loss: 1.273 | Val Acc:  45.71%\n",
            "learning rate: [0.0004000000000000001]\n",
            "Epoch  18 | Train Loss: 1.280 | Train Acc:  45.07%\n",
            "Epoch  18 | Val Loss: 1.271 | Val Acc:  45.72%\n",
            "learning rate: [0.0003666666666666668]\n",
            "Epoch  19 | Train Loss: 1.276 | Train Acc:  45.30%\n",
            "Epoch  19 | Val Loss: 1.268 | Val Acc:  45.86%\n",
            "learning rate: [0.0003333333333333335]\n",
            "Epoch  20 | Train Loss: 1.270 | Train Acc:  45.44%\n",
            "Epoch  20 | Val Loss: 1.265 | Val Acc:  46.23%\n",
            "learning rate: [0.00030000000000000014]\n",
            "Epoch  21 | Train Loss: 1.268 | Train Acc:  46.05%\n",
            "Epoch  21 | Val Loss: 1.261 | Val Acc:  46.39%\n",
            "learning rate: [0.0002666666666666668]\n",
            "Epoch  22 | Train Loss: 1.262 | Train Acc:  46.07%\n",
            "Epoch  22 | Val Loss: 1.260 | Val Acc:  46.24%\n",
            "learning rate: [0.00023333333333333336]\n",
            "Epoch  23 | Train Loss: 1.260 | Train Acc:  46.22%\n",
            "Epoch  23 | Val Loss: 1.251 | Val Acc:  46.62%\n",
            "learning rate: [0.0002]\n",
            "Epoch  24 | Train Loss: 1.256 | Train Acc:  46.47%\n",
            "Epoch  24 | Val Loss: 1.250 | Val Acc:  46.84%\n",
            "learning rate: [0.0001666666666666667]\n",
            "Epoch  25 | Train Loss: 1.251 | Train Acc:  46.77%\n",
            "Epoch  25 | Val Loss: 1.250 | Val Acc:  46.87%\n",
            "learning rate: [0.00013333333333333337]\n",
            "Epoch  26 | Train Loss: 1.250 | Train Acc:  46.81%\n",
            "Epoch  26 | Val Loss: 1.245 | Val Acc:  46.96%\n",
            "learning rate: [0.00010000000000000002]\n",
            "Epoch  27 | Train Loss: 1.246 | Train Acc:  46.90%\n",
            "Epoch  27 | Val Loss: 1.244 | Val Acc:  46.84%\n",
            "learning rate: [6.666666666666667e-05]\n",
            "Epoch  28 | Train Loss: 1.245 | Train Acc:  46.94%\n",
            "Epoch  28 | Val Loss: 1.243 | Val Acc:  46.96%\n",
            "learning rate: [3.3333333333333335e-05]\n",
            "Epoch  29 | Train Loss: 1.243 | Train Acc:  47.19%\n",
            "Epoch  29 | Val Loss: 1.242 | Val Acc:  47.01%\n",
            "learning rate: [0.0]\n",
            "Epoch  30 | Train Loss: 1.242 | Train Acc:  47.02%\n",
            "Epoch  30 | Val Loss: 1.242 | Val Acc:  47.02%\n",
            "learning rate: [0.0]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Improved result: acc 0.470, scheduler:\n",
            " functools.partial(<class 'torch.optim.lr_scheduler.PolynomialLR'>, total_iters=30, power=1)\n",
            "epoch: 30\n",
            "<class 'torch.optim.lr_scheduler.PolynomialLR'>\n",
            "Epoch   0 | Train Loss: 1.480 | Train Acc:  33.53%\n",
            "Epoch   0 | Val Loss: 1.422 | Val Acc:  37.10%\n",
            "learning rate: [0.0009344444444444444]\n",
            "Epoch   1 | Train Loss: 1.403 | Train Acc:  38.18%\n",
            "Epoch   1 | Val Loss: 1.388 | Val Acc:  38.92%\n",
            "learning rate: [0.0008711111111111112]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-3f2017b8fd4a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrained_gcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhyperparameter_tuning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_gcn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrat_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrat_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-45-57ce15107480>\u001b[0m in \u001b[0;36mhyperparameter_tuning\u001b[0;34m(model, strat_train, strat_val, scheduler_list, batch_size, epochs)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mbest_val_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpartial_scheduler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscheduler_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         model_out, mean_acc_val, epoch = train(copy.deepcopy(model), strat_train, strat_val, \n\u001b[0m\u001b[1;32m      9\u001b[0m                                                partial_scheduler, epochs, batch_size = batch_size, print_every=1)\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmean_acc_val\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_val_acc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-42e113b44416>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, strat_train, strat_val, partial_scheduler, epochs, batch_size, print_every)\u001b[0m\n\u001b[1;32m     46\u001b[0m       \u001b[0mmean_acc_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/data/batch.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                 or (isinstance(idx, np.ndarray) and np.isscalar(idx))):\n\u001b[0;32m--> 154\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m         elif isinstance(idx, str) or (isinstance(idx, tuple)\n\u001b[1;32m    156\u001b[0m                                       and isinstance(idx[0], str)):\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/data/batch.py\u001b[0m in \u001b[0;36mget_example\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    101\u001b[0m                  \"'Batch' was not created via 'Batch.from_data_list()'\"))\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         data = separate(\n\u001b[0m\u001b[1;32m    104\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__bases__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/data/separate.py\u001b[0m in \u001b[0;36mseparate\u001b[0;34m(cls, batch, idx, slice_dict, inc_dict, decrement)\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mslices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mincs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minc_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdecrement\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             data_store[attr] = _separate(attr, batch_store[attr], idx, slices,\n\u001b[0m\u001b[1;32m     38\u001b[0m                                          incs, batch, batch_store, decrement)\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "trained_gcn = hyperparameter_tuning(model_gcn, strat_train, strat_val, scheduler_list, batch_size = 128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "7dc5ee6a",
      "metadata": {
        "id": "7dc5ee6a",
        "outputId": "5b5b4294-3b84-4a51-88df-339cb4677e25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GAT(\n",
            "  (gat_list): ModuleList(\n",
            "    (0-9): 10 x GATv2Conv(50, 25, heads=8)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            "  (l_list): ModuleList(\n",
            "    (0-9): 10 x Linear(in_features=200, out_features=1, bias=True)\n",
            "  )\n",
            "  (classifier): Linear(in_features=10, out_features=5, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model_gat = GAT(cv19_graph_data_train.num_node_features,\n",
        "                cv19_graph_data_train.num_classes*2,\n",
        "                cv19_graph_data_train.num_classes).to(device)\n",
        "print(model_gat)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "print(get_lr(model_gat.optimizer))\n",
        "scheduler_list = build_scheduler_list(epochs=epochs)\n",
        "print(scheduler_list)\n",
        "trained_gat = hyperparameter_tuning(model_gat, strat_train, strat_val, scheduler_list, batch_size = 128, epochs = epochs)"
      ],
      "metadata": {
        "id": "U-t1hntA7WC0",
        "outputId": "8a9c6d8f-eb9f-456d-9575-e9a57de69b3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "id": "U-t1hntA7WC0",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.001\n",
            "[functools.partial(<class 'torch.optim.lr_scheduler.PolynomialLR'>, total_iters=100, power=1), functools.partial(<class 'torch.optim.lr_scheduler.PolynomialLR'>, total_iters=100, power=2), functools.partial(<class 'torch.optim.lr_scheduler.StepLR'>, step_size=33, gamma=0.5), functools.partial(<class 'torch.optim.lr_scheduler.StepLR'>, step_size=25, gamma=0.5), functools.partial(<class 'torch.optim.lr_scheduler.CosineAnnealingLR'>, T_max=100, eta_min=1e-06), functools.partial(<class 'torch.optim.lr_scheduler.CosineAnnealingLR'>, T_max=100, eta_min=1e-07), functools.partial(<class 'torch.optim.lr_scheduler.CosineAnnealingLR'>, T_max=100, eta_min=1e-08), functools.partial(<class 'torch.optim.lr_scheduler.OneCycleLR'>, max_lr=0.001, steps_per_epoch=10, epochs=100, anneal_strategy='cos'), functools.partial(<class 'torch.optim.lr_scheduler.OneCycleLR'>, max_lr=0.001, steps_per_epoch=50, epochs=100, anneal_strategy='cos'), functools.partial(<class 'torch.optim.lr_scheduler.OneCycleLR'>, max_lr=0.001, steps_per_epoch=100, epochs=100, anneal_strategy='cos')]\n",
            "batch size: 128\n",
            "<class 'torch.optim.lr_scheduler.PolynomialLR'>\n",
            "Epoch   0 | Train Loss: 1.547 | Train Acc:  31.90%\n",
            "Epoch   0 | Val Loss: 1.500 | Val Acc:  34.59%\n",
            "learning rate: [0.00099]\n",
            "Epoch   1 | Train Loss: 1.475 | Train Acc:  35.04%\n",
            "Epoch   1 | Val Loss: 1.448 | Val Acc:  36.02%\n",
            "learning rate: [0.00098]\n",
            "Epoch   2 | Train Loss: 1.430 | Train Acc:  35.95%\n",
            "Epoch   2 | Val Loss: 1.406 | Val Acc:  36.63%\n",
            "learning rate: [0.0009699999999999999]\n",
            "Epoch   3 | Train Loss: 1.396 | Train Acc:  36.47%\n",
            "Epoch   3 | Val Loss: 1.373 | Val Acc:  37.08%\n",
            "learning rate: [0.00096]\n",
            "Epoch   4 | Train Loss: 1.366 | Train Acc:  38.37%\n",
            "Epoch   4 | Val Loss: 1.349 | Val Acc:  40.84%\n",
            "learning rate: [0.0009500000000000001]\n",
            "Epoch   5 | Train Loss: 1.342 | Train Acc:  42.91%\n",
            "Epoch   5 | Val Loss: 1.326 | Val Acc:  45.27%\n",
            "learning rate: [0.0009400000000000001]\n",
            "Epoch   6 | Train Loss: 1.323 | Train Acc:  45.16%\n",
            "Epoch   6 | Val Loss: 1.313 | Val Acc:  45.06%\n",
            "learning rate: [0.0009300000000000002]\n",
            "Epoch   7 | Train Loss: 1.306 | Train Acc:  45.46%\n",
            "Epoch   7 | Val Loss: 1.296 | Val Acc:  46.53%\n",
            "learning rate: [0.0009200000000000002]\n",
            "Epoch   8 | Train Loss: 1.287 | Train Acc:  46.39%\n",
            "Epoch   8 | Val Loss: 1.275 | Val Acc:  46.80%\n",
            "learning rate: [0.0009100000000000002]\n",
            "Epoch   9 | Train Loss: 1.272 | Train Acc:  46.97%\n",
            "Epoch   9 | Val Loss: 1.257 | Val Acc:  47.90%\n",
            "learning rate: [0.0009000000000000003]\n",
            "Epoch  10 | Train Loss: 1.256 | Train Acc:  47.71%\n",
            "Epoch  10 | Val Loss: 1.243 | Val Acc:  48.41%\n",
            "learning rate: [0.0008900000000000004]\n",
            "Epoch  11 | Train Loss: 1.241 | Train Acc:  48.14%\n",
            "Epoch  11 | Val Loss: 1.226 | Val Acc:  49.17%\n",
            "learning rate: [0.0008800000000000004]\n",
            "Epoch  12 | Train Loss: 1.225 | Train Acc:  49.15%\n",
            "Epoch  12 | Val Loss: 1.207 | Val Acc:  50.18%\n",
            "learning rate: [0.0008700000000000003]\n",
            "Epoch  13 | Train Loss: 1.212 | Train Acc:  49.93%\n",
            "Epoch  13 | Val Loss: 1.193 | Val Acc:  51.09%\n",
            "learning rate: [0.0008600000000000003]\n",
            "Epoch  14 | Train Loss: 1.198 | Train Acc:  50.59%\n",
            "Epoch  14 | Val Loss: 1.186 | Val Acc:  51.39%\n",
            "learning rate: [0.0008500000000000003]\n",
            "Epoch  15 | Train Loss: 1.185 | Train Acc:  51.55%\n",
            "Epoch  15 | Val Loss: 1.168 | Val Acc:  52.21%\n",
            "learning rate: [0.0008400000000000004]\n",
            "Epoch  16 | Train Loss: 1.173 | Train Acc:  51.60%\n",
            "Epoch  16 | Val Loss: 1.168 | Val Acc:  51.52%\n",
            "learning rate: [0.0008300000000000004]\n",
            "Epoch  17 | Train Loss: 1.162 | Train Acc:  52.40%\n",
            "Epoch  17 | Val Loss: 1.157 | Val Acc:  51.59%\n",
            "learning rate: [0.0008200000000000005]\n",
            "Epoch  18 | Train Loss: 1.153 | Train Acc:  52.62%\n",
            "Epoch  18 | Val Loss: 1.137 | Val Acc:  53.70%\n",
            "learning rate: [0.0008100000000000005]\n",
            "Epoch  19 | Train Loss: 1.140 | Train Acc:  53.52%\n",
            "Epoch  19 | Val Loss: 1.127 | Val Acc:  54.78%\n",
            "learning rate: [0.0008000000000000005]\n",
            "Epoch  20 | Train Loss: 1.130 | Train Acc:  54.10%\n",
            "Epoch  20 | Val Loss: 1.124 | Val Acc:  54.62%\n",
            "learning rate: [0.0007900000000000006]\n",
            "Epoch  21 | Train Loss: 1.120 | Train Acc:  54.42%\n",
            "Epoch  21 | Val Loss: 1.101 | Val Acc:  56.30%\n",
            "learning rate: [0.0007800000000000005]\n",
            "Epoch  22 | Train Loss: 1.110 | Train Acc:  54.98%\n",
            "Epoch  22 | Val Loss: 1.101 | Val Acc:  56.08%\n",
            "learning rate: [0.0007700000000000005]\n",
            "Epoch  23 | Train Loss: 1.101 | Train Acc:  55.67%\n",
            "Epoch  23 | Val Loss: 1.107 | Val Acc:  55.01%\n",
            "learning rate: [0.0007600000000000005]\n",
            "Epoch  24 | Train Loss: 1.092 | Train Acc:  56.34%\n",
            "Epoch  24 | Val Loss: 1.096 | Val Acc:  56.47%\n",
            "learning rate: [0.0007500000000000004]\n",
            "Epoch  25 | Train Loss: 1.090 | Train Acc:  56.03%\n",
            "Epoch  25 | Val Loss: 1.077 | Val Acc:  57.07%\n",
            "learning rate: [0.0007400000000000004]\n",
            "Epoch  26 | Train Loss: 1.076 | Train Acc:  57.05%\n",
            "Epoch  26 | Val Loss: 1.063 | Val Acc:  58.01%\n",
            "learning rate: [0.0007300000000000004]\n",
            "Epoch  27 | Train Loss: 1.068 | Train Acc:  57.17%\n",
            "Epoch  27 | Val Loss: 1.051 | Val Acc:  58.56%\n",
            "learning rate: [0.0007200000000000004]\n",
            "Epoch  28 | Train Loss: 1.060 | Train Acc:  57.97%\n",
            "Epoch  28 | Val Loss: 1.047 | Val Acc:  58.45%\n",
            "learning rate: [0.0007100000000000003]\n",
            "Epoch  29 | Train Loss: 1.055 | Train Acc:  57.89%\n",
            "Epoch  29 | Val Loss: 1.042 | Val Acc:  58.77%\n",
            "learning rate: [0.0007000000000000003]\n",
            "Epoch  30 | Train Loss: 1.050 | Train Acc:  58.38%\n",
            "Epoch  30 | Val Loss: 1.033 | Val Acc:  59.32%\n",
            "learning rate: [0.0006900000000000003]\n",
            "Epoch  31 | Train Loss: 1.041 | Train Acc:  58.81%\n",
            "Epoch  31 | Val Loss: 1.044 | Val Acc:  57.43%\n",
            "learning rate: [0.0006800000000000003]\n",
            "Epoch  32 | Train Loss: 1.037 | Train Acc:  58.91%\n",
            "Epoch  32 | Val Loss: 1.020 | Val Acc:  60.11%\n",
            "learning rate: [0.0006700000000000002]\n",
            "Epoch  33 | Train Loss: 1.031 | Train Acc:  59.02%\n",
            "Epoch  33 | Val Loss: 1.055 | Val Acc:  57.26%\n",
            "learning rate: [0.0006600000000000002]\n",
            "Epoch  34 | Train Loss: 1.024 | Train Acc:  59.43%\n",
            "Epoch  34 | Val Loss: 1.028 | Val Acc:  58.64%\n",
            "learning rate: [0.0006500000000000003]\n",
            "Epoch  35 | Train Loss: 1.018 | Train Acc:  60.01%\n",
            "Epoch  35 | Val Loss: 1.019 | Val Acc:  59.91%\n",
            "learning rate: [0.0006400000000000003]\n",
            "Epoch  36 | Train Loss: 1.012 | Train Acc:  60.35%\n",
            "Epoch  36 | Val Loss: 0.997 | Val Acc:  61.28%\n",
            "learning rate: [0.0006300000000000002]\n",
            "Epoch  37 | Train Loss: 1.006 | Train Acc:  60.49%\n",
            "Epoch  37 | Val Loss: 0.989 | Val Acc:  61.83%\n",
            "learning rate: [0.0006200000000000002]\n",
            "Epoch  38 | Train Loss: 1.006 | Train Acc:  60.62%\n",
            "Epoch  38 | Val Loss: 0.992 | Val Acc:  61.88%\n",
            "learning rate: [0.0006100000000000002]\n",
            "Epoch  39 | Train Loss: 0.995 | Train Acc:  61.05%\n",
            "Epoch  39 | Val Loss: 0.980 | Val Acc:  62.46%\n",
            "learning rate: [0.0006000000000000002]\n",
            "Epoch  40 | Train Loss: 0.991 | Train Acc:  61.50%\n",
            "Epoch  40 | Val Loss: 0.985 | Val Acc:  61.54%\n",
            "learning rate: [0.0005900000000000002]\n",
            "Epoch  41 | Train Loss: 0.985 | Train Acc:  61.53%\n",
            "Epoch  41 | Val Loss: 0.968 | Val Acc:  62.81%\n",
            "learning rate: [0.0005800000000000002]\n",
            "Epoch  42 | Train Loss: 0.982 | Train Acc:  61.85%\n",
            "Epoch  42 | Val Loss: 0.965 | Val Acc:  62.95%\n",
            "learning rate: [0.0005700000000000002]\n",
            "Epoch  43 | Train Loss: 0.976 | Train Acc:  62.10%\n",
            "Epoch  43 | Val Loss: 0.961 | Val Acc:  63.47%\n",
            "learning rate: [0.0005600000000000002]\n",
            "Epoch  44 | Train Loss: 0.972 | Train Acc:  62.35%\n",
            "Epoch  44 | Val Loss: 0.967 | Val Acc:  62.40%\n",
            "learning rate: [0.0005500000000000001]\n",
            "Epoch  45 | Train Loss: 0.967 | Train Acc:  63.01%\n",
            "Epoch  45 | Val Loss: 0.953 | Val Acc:  63.52%\n",
            "learning rate: [0.0005400000000000001]\n",
            "Epoch  46 | Train Loss: 0.964 | Train Acc:  62.81%\n",
            "Epoch  46 | Val Loss: 0.961 | Val Acc:  63.43%\n",
            "learning rate: [0.0005300000000000001]\n",
            "Epoch  47 | Train Loss: 0.957 | Train Acc:  63.40%\n",
            "Epoch  47 | Val Loss: 0.953 | Val Acc:  63.15%\n",
            "learning rate: [0.0005200000000000001]\n",
            "Epoch  48 | Train Loss: 0.953 | Train Acc:  63.55%\n",
            "Epoch  48 | Val Loss: 0.944 | Val Acc:  64.12%\n",
            "learning rate: [0.00051]\n",
            "Epoch  49 | Train Loss: 0.950 | Train Acc:  63.86%\n",
            "Epoch  49 | Val Loss: 0.941 | Val Acc:  64.05%\n",
            "learning rate: [0.0005]\n",
            "Epoch  50 | Train Loss: 0.946 | Train Acc:  63.93%\n",
            "Epoch  50 | Val Loss: 0.955 | Val Acc:  62.47%\n",
            "learning rate: [0.00049]\n",
            "Epoch  51 | Train Loss: 0.943 | Train Acc:  63.97%\n",
            "Epoch  51 | Val Loss: 0.932 | Val Acc:  64.99%\n",
            "learning rate: [0.00047999999999999996]\n",
            "Epoch  52 | Train Loss: 0.940 | Train Acc:  64.20%\n",
            "Epoch  52 | Val Loss: 0.922 | Val Acc:  65.41%\n",
            "learning rate: [0.00046999999999999993]\n",
            "Epoch  53 | Train Loss: 0.935 | Train Acc:  64.30%\n",
            "Epoch  53 | Val Loss: 0.924 | Val Acc:  65.52%\n",
            "learning rate: [0.0004599999999999999]\n",
            "Epoch  54 | Train Loss: 0.928 | Train Acc:  65.11%\n",
            "Epoch  54 | Val Loss: 0.919 | Val Acc:  65.61%\n",
            "learning rate: [0.00044999999999999993]\n",
            "Epoch  55 | Train Loss: 0.927 | Train Acc:  64.99%\n",
            "Epoch  55 | Val Loss: 0.930 | Val Acc:  64.24%\n",
            "learning rate: [0.0004399999999999999]\n",
            "Epoch  56 | Train Loss: 0.922 | Train Acc:  65.18%\n",
            "Epoch  56 | Val Loss: 0.914 | Val Acc:  65.55%\n",
            "learning rate: [0.00043]\n",
            "Epoch  57 | Train Loss: 0.919 | Train Acc:  65.58%\n",
            "Epoch  57 | Val Loss: 0.905 | Val Acc:  66.50%\n",
            "learning rate: [0.00041999999999999996]\n",
            "Epoch  58 | Train Loss: 0.917 | Train Acc:  65.44%\n",
            "Epoch  58 | Val Loss: 0.904 | Val Acc:  66.47%\n",
            "learning rate: [0.00040999999999999994]\n",
            "Epoch  59 | Train Loss: 0.914 | Train Acc:  65.59%\n",
            "Epoch  59 | Val Loss: 0.911 | Val Acc:  66.09%\n",
            "learning rate: [0.0003999999999999999]\n",
            "Epoch  60 | Train Loss: 0.911 | Train Acc:  65.81%\n",
            "Epoch  60 | Val Loss: 0.898 | Val Acc:  66.69%\n",
            "learning rate: [0.0003899999999999999]\n",
            "Epoch  61 | Train Loss: 0.905 | Train Acc:  66.22%\n",
            "Epoch  61 | Val Loss: 0.902 | Val Acc:  66.45%\n",
            "learning rate: [0.00037999999999999986]\n",
            "Epoch  62 | Train Loss: 0.904 | Train Acc:  66.02%\n",
            "Epoch  62 | Val Loss: 0.902 | Val Acc:  66.61%\n",
            "learning rate: [0.0003699999999999999]\n",
            "Epoch  63 | Train Loss: 0.898 | Train Acc:  66.57%\n",
            "Epoch  63 | Val Loss: 0.897 | Val Acc:  66.77%\n",
            "learning rate: [0.00035999999999999986]\n",
            "Epoch  64 | Train Loss: 0.896 | Train Acc:  66.53%\n",
            "Epoch  64 | Val Loss: 0.885 | Val Acc:  67.46%\n",
            "learning rate: [0.00034999999999999983]\n",
            "Epoch  65 | Train Loss: 0.893 | Train Acc:  66.65%\n",
            "Epoch  65 | Val Loss: 0.882 | Val Acc:  67.76%\n",
            "learning rate: [0.00033999999999999986]\n",
            "Epoch  66 | Train Loss: 0.890 | Train Acc:  67.07%\n",
            "Epoch  66 | Val Loss: 0.877 | Val Acc:  68.06%\n",
            "learning rate: [0.0003299999999999999]\n",
            "Epoch  67 | Train Loss: 0.887 | Train Acc:  67.34%\n",
            "Epoch  67 | Val Loss: 0.874 | Val Acc:  68.19%\n",
            "learning rate: [0.00031999999999999986]\n",
            "Epoch  68 | Train Loss: 0.887 | Train Acc:  67.19%\n",
            "Epoch  68 | Val Loss: 0.872 | Val Acc:  68.36%\n",
            "learning rate: [0.00031]\n",
            "Epoch  69 | Train Loss: 0.883 | Train Acc:  67.52%\n",
            "Epoch  69 | Val Loss: 0.872 | Val Acc:  68.03%\n",
            "learning rate: [0.00030000000000000003]\n",
            "Epoch  70 | Train Loss: 0.881 | Train Acc:  67.49%\n",
            "Epoch  70 | Val Loss: 0.871 | Val Acc:  67.92%\n",
            "learning rate: [0.00029000000000000006]\n",
            "Epoch  71 | Train Loss: 0.877 | Train Acc:  67.93%\n",
            "Epoch  71 | Val Loss: 0.865 | Val Acc:  68.76%\n",
            "learning rate: [0.00028000000000000003]\n",
            "Epoch  72 | Train Loss: 0.875 | Train Acc:  68.24%\n",
            "Epoch  72 | Val Loss: 0.865 | Val Acc:  68.68%\n",
            "learning rate: [0.00027000000000000006]\n",
            "Epoch  73 | Train Loss: 0.872 | Train Acc:  68.08%\n",
            "Epoch  73 | Val Loss: 0.864 | Val Acc:  68.47%\n",
            "learning rate: [0.00026000000000000003]\n",
            "Epoch  74 | Train Loss: 0.868 | Train Acc:  68.37%\n",
            "Epoch  74 | Val Loss: 0.864 | Val Acc:  68.61%\n",
            "learning rate: [0.00025]\n",
            "Epoch  75 | Train Loss: 0.867 | Train Acc:  68.34%\n",
            "Epoch  75 | Val Loss: 0.870 | Val Acc:  68.32%\n",
            "learning rate: [0.00024]\n",
            "Epoch  76 | Train Loss: 0.864 | Train Acc:  68.43%\n",
            "Epoch  76 | Val Loss: 0.855 | Val Acc:  69.17%\n",
            "learning rate: [0.00022999999999999998]\n",
            "Epoch  77 | Train Loss: 0.866 | Train Acc:  68.45%\n",
            "Epoch  77 | Val Loss: 0.854 | Val Acc:  69.46%\n",
            "learning rate: [0.00021999999999999995]\n",
            "Epoch  78 | Train Loss: 0.860 | Train Acc:  68.72%\n",
            "Epoch  78 | Val Loss: 0.855 | Val Acc:  69.07%\n",
            "learning rate: [0.00020999999999999993]\n",
            "Epoch  79 | Train Loss: 0.858 | Train Acc:  68.69%\n",
            "Epoch  79 | Val Loss: 0.851 | Val Acc:  69.43%\n",
            "learning rate: [0.00019999999999999993]\n",
            "Epoch  80 | Train Loss: 0.857 | Train Acc:  68.83%\n",
            "Epoch  80 | Val Loss: 0.860 | Val Acc:  68.89%\n",
            "learning rate: [0.00018999999999999993]\n",
            "Epoch  81 | Train Loss: 0.856 | Train Acc:  69.17%\n",
            "Epoch  81 | Val Loss: 0.848 | Val Acc:  69.60%\n",
            "learning rate: [0.00018000000000000004]\n",
            "Epoch  82 | Train Loss: 0.854 | Train Acc:  68.95%\n",
            "Epoch  82 | Val Loss: 0.846 | Val Acc:  69.61%\n",
            "learning rate: [0.00017000000000000004]\n",
            "Epoch  83 | Train Loss: 0.851 | Train Acc:  69.18%\n",
            "Epoch  83 | Val Loss: 0.847 | Val Acc:  69.39%\n",
            "learning rate: [0.00016000000000000004]\n",
            "Epoch  84 | Train Loss: 0.849 | Train Acc:  69.15%\n",
            "Epoch  84 | Val Loss: 0.846 | Val Acc:  69.54%\n",
            "learning rate: [0.00015000000000000004]\n",
            "Epoch  85 | Train Loss: 0.848 | Train Acc:  69.51%\n",
            "Epoch  85 | Val Loss: 0.843 | Val Acc:  69.78%\n",
            "learning rate: [0.00014000000000000001]\n",
            "Epoch  86 | Train Loss: 0.847 | Train Acc:  69.51%\n",
            "Epoch  86 | Val Loss: 0.842 | Val Acc:  69.97%\n",
            "learning rate: [0.00013000000000000002]\n",
            "Epoch  87 | Train Loss: 0.845 | Train Acc:  69.57%\n",
            "Epoch  87 | Val Loss: 0.840 | Val Acc:  69.89%\n",
            "learning rate: [0.00012]\n",
            "Epoch  88 | Train Loss: 0.843 | Train Acc:  69.85%\n",
            "Epoch  88 | Val Loss: 0.838 | Val Acc:  70.11%\n",
            "learning rate: [0.00011]\n",
            "Epoch  89 | Train Loss: 0.842 | Train Acc:  69.68%\n",
            "Epoch  89 | Val Loss: 0.837 | Val Acc:  70.17%\n",
            "learning rate: [9.999999999999999e-05]\n",
            "Epoch  90 | Train Loss: 0.841 | Train Acc:  69.96%\n",
            "Epoch  90 | Val Loss: 0.841 | Val Acc:  69.67%\n",
            "learning rate: [8.999999999999998e-05]\n",
            "Epoch  91 | Train Loss: 0.840 | Train Acc:  69.74%\n",
            "Epoch  91 | Val Loss: 0.839 | Val Acc:  70.15%\n",
            "learning rate: [7.999999999999997e-05]\n",
            "Epoch  92 | Train Loss: 0.839 | Train Acc:  70.00%\n",
            "Epoch  92 | Val Loss: 0.834 | Val Acc:  70.23%\n",
            "learning rate: [6.999999999999995e-05]\n",
            "Epoch  93 | Train Loss: 0.837 | Train Acc:  70.12%\n",
            "Epoch  93 | Val Loss: 0.837 | Val Acc:  69.98%\n",
            "learning rate: [6.0000000000000056e-05]\n",
            "Epoch  94 | Train Loss: 0.836 | Train Acc:  69.92%\n",
            "Epoch  94 | Val Loss: 0.833 | Val Acc:  70.35%\n",
            "learning rate: [5.000000000000005e-05]\n",
            "Epoch  95 | Train Loss: 0.835 | Train Acc:  70.35%\n",
            "Epoch  95 | Val Loss: 0.833 | Val Acc:  70.39%\n",
            "learning rate: [4.0000000000000044e-05]\n",
            "Epoch  96 | Train Loss: 0.834 | Train Acc:  70.25%\n",
            "Epoch  96 | Val Loss: 0.834 | Val Acc:  70.36%\n",
            "learning rate: [3.000000000000003e-05]\n",
            "Epoch  97 | Train Loss: 0.834 | Train Acc:  70.18%\n",
            "Epoch  97 | Val Loss: 0.832 | Val Acc:  70.49%\n",
            "learning rate: [2.000000000000002e-05]\n",
            "Epoch  98 | Train Loss: 0.833 | Train Acc:  70.42%\n",
            "Epoch  98 | Val Loss: 0.832 | Val Acc:  70.48%\n",
            "learning rate: [1.000000000000001e-05]\n",
            "Epoch  99 | Train Loss: 0.832 | Train Acc:  70.37%\n",
            "Epoch  99 | Val Loss: 0.832 | Val Acc:  70.52%\n",
            "learning rate: [0.0]\n",
            "Epoch 100 | Train Loss: 0.832 | Train Acc:  70.53%\n",
            "Epoch 100 | Val Loss: 0.832 | Val Acc:  70.52%\n",
            "learning rate: [0.0]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Improved result: acc 0.705, scheduler:\n",
            " functools.partial(<class 'torch.optim.lr_scheduler.PolynomialLR'>, total_iters=100, power=1)\n",
            "epoch: 99\n",
            "<class 'torch.optim.lr_scheduler.PolynomialLR'>\n",
            "Epoch   0 | Train Loss: 1.552 | Train Acc:  31.34%\n",
            "Epoch   0 | Val Loss: 1.504 | Val Acc:  34.55%\n",
            "learning rate: [0.0009801]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-d81bd9bcf143>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mscheduler_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_scheduler_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscheduler_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrained_gat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhyperparameter_tuning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_gat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrat_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrat_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-45-57ce15107480>\u001b[0m in \u001b[0;36mhyperparameter_tuning\u001b[0;34m(model, strat_train, strat_val, scheduler_list, batch_size, epochs)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mbest_val_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpartial_scheduler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscheduler_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         model_out, mean_acc_val, epoch = train(copy.deepcopy(model), strat_train, strat_val, \n\u001b[0m\u001b[1;32m      9\u001b[0m                                                partial_scheduler, epochs, batch_size = batch_size, print_every=1)\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmean_acc_val\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_val_acc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-42e113b44416>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, strat_train, strat_val, partial_scheduler, epochs, batch_size, print_every)\u001b[0m\n\u001b[1;32m     46\u001b[0m       \u001b[0mmean_acc_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/data/batch.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                 or (isinstance(idx, np.ndarray) and np.isscalar(idx))):\n\u001b[0;32m--> 154\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m         elif isinstance(idx, str) or (isinstance(idx, tuple)\n\u001b[1;32m    156\u001b[0m                                       and isinstance(idx[0], str)):\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/data/batch.py\u001b[0m in \u001b[0;36mget_example\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    101\u001b[0m                  \"'Batch' was not created via 'Batch.from_data_list()'\"))\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         data = separate(\n\u001b[0m\u001b[1;32m    104\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__bases__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/data/separate.py\u001b[0m in \u001b[0;36mseparate\u001b[0;34m(cls, batch, idx, slice_dict, inc_dict, decrement)\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mslices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mincs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minc_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdecrement\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             data_store[attr] = _separate(attr, batch_store[attr], idx, slices,\n\u001b[0m\u001b[1;32m     38\u001b[0m                                          incs, batch, batch_store, decrement)\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/data/separate.py\u001b[0m in \u001b[0;36m_separate\u001b[0;34m(key, value, idx, slices, incs, batch, store, decrement)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mcat_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__cat_dim__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnarrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_dim\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcat_dim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}